<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Paper-TotalText | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="数据集,Python,论文,">
<meta name="description" content="论文阅读。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/数据集"><span>数据集</span></a></li>
						
							<li><a href="/tags/Python"><span>Python</span></a></li>
						
							<li><a href="/tags/论文"><span>论文</span></a></li>
						
					
				</ul>
				
				<h1>Paper-TotalText</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>论文阅读。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2023/07/07 15:47:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="%E8%B5%84%E6%BA%90" tabindex="-1">资源</h1>
<ul>
<li>PaperWithCode：<a target="_blank" rel="noopener" href="https://paperswithcode.com/dataset/total-text">Total-Text Dataset | Papers With Code</a></li>
<li>Arxiv：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.10400v1">[1710.10400v1] Total-Text: A Comprehensive Dataset for Scene Text Detection and Recognition (arxiv.org)</a></li>
<li>GitHub：<a target="_blank" rel="noopener" href="https://github.com/cs-chan/Total-Text-Dataset">cs-chan/Total-Text-Dataset: Total Text Dataset. It consists of 1555 images with more than 3 different text orientations: Horizontal, Multi-Oriented, and Curved, one of a kind. (github.com)</a></li>
<li>文中附带的 Text Detection 的方法：<a target="_blank" rel="noopener" href="http://cs-chan.com/doc/IJDAR2019.pdf">Total-Text: toward orientation robustness in scene text detection (cs-chan.com)</a></li>
</ul>
<p>包含两个任务：</p>
<ul>
<li>Text Spotting：<a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/text-spotting-on-total-text">Total-Text Benchmark (Text Spotting) | Papers With Code</a></li>
<li>Scene Text Detection on Total-Text：<a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/scene-text-detection-on-total-text">Total-Text Benchmark (Scene Text Detection) | Papers With Code</a></li>
</ul>
<h1 id="total-text%3A-a-comprehensive-dataset-for-scene-text-detection-and-recognition" tabindex="-1">Total-Text: A Comprehensive Dataset for Scene Text Detection and Recognition</h1>
<h2 id="abstract" tabindex="-1" id="Abstract">Abstract</h2>
<p>​    <strong>弯曲文本</strong>在常见的文本数据集中（<strong>ICDAR’13</strong> 和 <strong>MSRA-TD500</strong>）几乎不存在，<strong>TotalText</strong> 数据集则有。最近，一种将文本检测作为分割问题的新解决方案已经证明了它们对多方向文本的有效性。</p>
<h2 id="1-introduction" tabindex="-1" id="1-INTRODUCTION">1 INTRODUCTION</h2>
<p>​    市面上几乎没有弯曲文本的数据集，<strong>CUTE80</strong> 是唯一可用的，然而它只有 80 张，不好使。</p>
<p>​    如果没有合适的数据集，解决弯曲文本检测问题的努力就很少出现。</p>
<p><strong>Total Text</strong>：</p>
<ul>
<li>一个考虑到弯曲文本的场景文本数据集，填补了场景文本数据集中文本方向的空白</li>
<li>1555 幅场景图像，4265 个文本实例，9330 个注释单词</li>
<li>三种不同的文本方向，包括<strong>水平 horizontal</strong>、<strong>多向 multi-oriented</strong> 和<strong>弯曲 curved</strong>。</li>
</ul>
<p><img src="P3.png" alt="png"></p>
<center>第一行是分别是 ICDAR 2013，ICDAR 2015 和 MSRA-TD500（几乎没有弯曲文本）<br/>第二行是 Total-Text，具有弯曲文本</center>
<p><img src="P4.png" alt="png"></p>
<center>现有的 Text Detection 对弯曲文本都不好使</center>
<h2 id="2-related-works" tabindex="-1" id="2-RELATED-WORKS">2 RELATED WORKS</h2>
<h3 id="a.-scene-text-datasets" tabindex="-1" id="A-Scene-Text-Datasets">A. Scene Text Datasets</h3>
<ul>
<li>
<p><strong>ICDARs</strong> 系列，几百到几千张图像数量不等，文本质量模糊。</p>
</li>
<li>
<p><strong>MSRA-TD500</strong> 于 2012 年推出，旨在解决场景文本数据集中缺乏任意定向文本的问题。它有 300 个训练图像和 200 个测试图像；用最小面积矩形标注。</p>
</li>
<li>
<p><strong>COCO-Text</strong> 于 2016 年推出，数据量大（63686 张图像和 173589 个文本标记区域），也包含水平 horizontal、多向 multi-oriented 和弯曲 curved，然而它的 Ground Truth 只有 bbox，这只对水平和垂直文本有效。</p>
</li>
<li>
<p><strong>CUTE80</strong> 只有 80 张，数据量太小了。</p>
</li>
</ul>
<h3 id="b.-scene-text-detection" tabindex="-1" id="B-Scene-Text-Detection">B. Scene Text Detection</h3>
<p>​    介绍各种 Scene Text Detection 的模型，略。</p>
<h2 id="3-total-text-dataset" tabindex="-1" id="3-TOTAL-TEXT-DATASET">3 TOTAL-TEXT DATASET</h2>
<h3 id="a.-dataset-attributes" tabindex="-1" id="A-Dataset-Attributes">A. Dataset Attributes</h3>
<ul>
<li>
<p><strong>弯曲文本是一个被忽视的问题 Curved text is an overlooked problem</strong> 在水平文本 ICDAR 中，性能几乎已达饱和（f-score 达到 0.9）</p>
</li>
<li>
<p><strong>弯曲文本观察 Curved text observation</strong> 从几何角度讲，直线沿着直线没有角度变化，因此可以描述为线性函数，y=mx+c。而曲线不是直线。它在整个线路上不受角度变化的限制。</p>
</li>
<li>
<p>**方向假设 Orientation assumption ** 目前很多 Text Detection 模型都具有方向假设，这种方式估计放到弯曲文本就寄了。</p>
</li>
<li>
<p><strong>以聚焦的场景文本为起点 Focused scene text as a start</strong>  ICDAR 系列的文本显示质量差，作者认为文本质量稍微好一点更适合启动相关研究工作。</p>
</li>
<li>
<p><strong>GT 越完备越好 Tighter groundtruth is better</strong> ICDAR 2015 使用四边形（四个点），COCO 使用 bbox（两个点）。在 Total Text 中，我们用紧密贴合的多边形对文本区域进行了注释。</p>
</li>
<li>
<p><strong>评估协议 Evaluation Protocol</strong> 与 ICDAR 数据集一样，TotalText 使用 DetEval。</p>
</li>
<li>
<p><strong>注释详细信息 Annotation Details</strong> 仍然保留了 bbox 的注释。Total Text 只考虑自然图像中的英文字符；其他语言、数字水印和无法阅读的文本被贴上了 “do not care” 的标签。</p>
</li>
</ul>
<h3 id="b.-dataset-statstics" tabindex="-1" id="B-Dataset-Statstics">B. Dataset Statstics</h3>
<ul>
<li><strong>数量优势 Strength in numbers</strong> 它总共有 9330 个注释文本，平均每个图像有 6 个实例。Total Text 中超过一半的图像具有 2 个不同的方向及以上，平均每个图像产生 1.8 个方向。数据集的收集也考虑了</li>
</ul>
<p><img src="P7.png" alt="png"></p>
<ul>
<li>
<p><strong>方向多样性 Orientation diversity</strong> 大约一半的是弯曲的：</p>
<ul>
<li>Horizontal Curve 水平弯曲 57.1%</li>
<li>Vertical Curve 垂直弯曲 23.5%</li>
<li>Circular 圆形 17.3%</li>
<li>Wavy 波浪形 2%</li>
</ul>
</li>
</ul>
<p>​    弯曲文本通常与水平文本或多方向文本一起出现。图像中方向的混合对文本检测算法在文本方向方面实现鲁棒性和泛化提出了挑战。</p>
<ul>
<li><strong>场景多样性 Scene diversity</strong> 弯曲文本出现的场景多样性好。</li>
</ul>
<h2 id="4-semantic-segmentation-for-text-detection-%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2" tabindex="-1" id="4-SEMANTIC-SEGMENTATION-FOR-TEXT-DETECTION-用于文本检测的语义分割">4 SEMANTIC SEGMENTATION FOR TEXT DETECTION 用于文本检测的语义分割</h2>
<h3 id="a.-deconvnet" tabindex="-1" id="A-DeconvNet">A. DeconvNet</h3>
<p>​    介绍他们提出的 DecovNet。使用最大的场景文本数据集 COCO-text 对其进行了预训练。COCO-text 中的图像被分为可阅读和难以阅读的文本，我们只在可阅读的文本上训练我们的网络，因为它与我们的数据集非常相似。</p>
<h3 id="b.-experiments" tabindex="-1" id="B-Experiments">B. Experiments</h3>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Recall</th>
<th>Precision</th>
<th>F-score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Total-Text</td>
<td>0.33</td>
<td>0.40</td>
<td>0.36</td>
</tr>
</tbody>
</table>
<h1 id="total-text%3A-toward-orientation-robustness-in-scene-text-detection" tabindex="-1">Total-Text: toward orientation robustness in scene text detection</h1>
<h2 id="abstract-1" tabindex="-1" id="Abstract-2">Abstract</h2>
<p>​    目前场景文本数据集中的文本方向还不够多样化。</p>
<p>​    提出的 Total-Text 具有三种不同的文本方向：</p>
<ul>
<li>水平 horizontal</li>
<li>多方向 multi-oriented</li>
<li>曲线方向 curve-oriented</li>
</ul>
<p>​    研究了其他几个重要因素：</p>
<ul>
<li>ground truth 的 practicality（实用性）和 quality（质量）</li>
<li>evaluation protocol 评估协议</li>
<li>annotation process 注释过程</li>
</ul>
<p>​    提出了一个新的场景文本检测模型作为 Total text 基线，称为 Polygon-Faster-RCNN</p>
<h2 id="1-introduction-1" tabindex="-1" id="1-Introduction">1 Introduction</h2>
<p><img src="P2_2.png" alt="png"></p>
<center>Total Text 的注释详细信息。<b>a</b> 总文本的图像，<b>b</b> 文本区域二进制掩码，<b>c</b> 字符级二进制掩码，<b>d</b> 固定长度多边形顶点，转录（区分大小写）和方向注释（'c'：弯曲，'m'：多方向）</center>
<p>​    提出的 Total-Text 包含：</p>
<ul>
<li>1555 幅场景图像，11459 个注释单词</li>
<li>GT 包括：
<ul>
<li>spatial location 空间位置</li>
<li>transcription 标注</li>
<li>pixel level for text detection, recognition and segmentation task 像素级的用于文本检测、识别和分割任务</li>
</ul>
</li>
</ul>
<hr>
<p>​    提出了新的场景文本模型：Polygon Faster RCNN（Poly FRCNN）。用于回归多边形而不是长方体参数。它能够检测所有方向的文本，并以精确的方式将其绑定。我们提出的模型在 ICDAR2013、ICDAR2015 和 Total Text 上的 F 测度分别达到 0.85、0.72 和 0.7；证明了其在具有不同属性的数据集上的有效性。</p>
<h3 id="1.1-improved-ground-truth" tabindex="-1" id="1-1-Improved-ground-truth">1.1 Improved ground truth</h3>
<p>​    多边形顶点的数量因文本实例的不同而不同。这给 Faster RCNN、SSD 和 YOLO 等检测框架带来了一个实际问题（所有这些都激发了许多场景文本检测工作），它们需要在回归目标中有固定数量的顶点。</p>
<h3 id="1.2-optimized-evaluation-protocol-for-total-text" tabindex="-1" id="1-2-Optimized-evaluation-protocol-for-Total-Text">1.2 Optimized evaluation protocol for Total-Text</h3>
<p>​    DetEval 中当前推荐的阈值没有通过包含弯曲文本进行优化。进行了一系列实验，以确定一组新的更公平评估阈值。</p>
<h3 id="1.3-scene-text-detection-annotation-tool" tabindex="-1" id="1-3-Scene-text-detection-annotation-tool">1.3 Scene text detection annotation tool</h3>
<p>​    在扩展数据集时，地面实况注释是最大的瓶颈。Karatzas 等人介绍了一个注重质量控制和数据库管理的在线注释平台。然而，仅仅是平凡而艰苦的注释任务就有很大的改进空间。因此，我们在第节中介绍了全文工具（T3）。5、一种辅助注释框架，该辅助注释框架能够减少注释时间，同时获得高质量的基本事实。</p>
<h3 id="1.4-cross-dataset-experiment" tabindex="-1" id="1-4-Cross-dataset-experiment">1.4 Cross dataset experiment</h3>
<p>​    在 Total Text 上训练的模型在其他场景文本数据集上表现出良好的泛化能力</p>
<h3 id="1.5-state-of-the-art-analysis" tabindex="-1" id="1-5-State-of-the-art-analysis">1.5 State-of-the-art analysis</h3>
<p>​    自 TotalText 出现以来，许多工作开始解决弯曲文本检测问题。</p>
<h2 id="2-related-works-1" tabindex="-1" id="2-Related-works">2 Related works</h2>
<h3 id="2.1-scene-text-datasets" tabindex="-1" id="2-1-Scene-text-datasets">2.1 Scene text datasets</h3>
<h4 id="2.1.1-icdar2003-icdar2015" tabindex="-1" id="2-1-1-ICDAR2003-ICDAR2015">2.1.1 ICDAR2003-ICDAR2015</h4>
<table>
<thead>
<tr>
<th>系列</th>
<th>数量</th>
<th>注释</th>
<th>特性</th>
</tr>
</thead>
<tbody>
<tr>
<td>2003</td>
<td>509</td>
<td>bbox</td>
<td></td>
</tr>
<tr>
<td>2011</td>
<td>484</td>
<td>bbox</td>
<td></td>
</tr>
<tr>
<td>2013</td>
<td>462</td>
<td>bbox</td>
<td></td>
</tr>
<tr>
<td>2015</td>
<td>1670</td>
<td>四边形</td>
<td>包含任意方向，失焦</td>
</tr>
</tbody>
</table>
<h4 id="2.1.2-msra-td500" tabindex="-1" id="2-1-2-MSRA-TD500">2.1.2 MSRA-TD500</h4>
<p>​    2012，包含任意定向文本，300 训练图像，200 测试图像，使用旋转的边界框进行注释。</p>
<h4 id="2.1.3-ustb-sv1k" tabindex="-1" id="2-1-3-USTB-SV1K">2.1.3 USTB-SV1K</h4>
<p>​    从美国六个城市的街道上收集了 1000 张图像，以多方向文本为特色，用旋转的边界框进行注释。</p>
<h4 id="2.1.4-coco-text" tabindex="-1" id="2-1-4-COCO-text">2.1.4 COCO-text</h4>
<p>​    2016，迄今为止最大的场景文本数据集，拥有 63686 幅图像和 173589 个标记文本区域。它主要由横向和多向文本以及少量弯曲文本组成，bbox。</p>
<h4 id="2.1.5-mlt" tabindex="-1" id="2-1-5-MLT">2.1.5 MLT</h4>
<p>​    MLT 数据集，这是为场景文本检测、识别和脚本识别任务收集的最新多脚本数据集之一。它由 18000 个图像组成，用于训练和验证，以 9 种语言和 6 种不同的脚本为特色。</p>
<h4 id="2.1.6-ctw-12k" tabindex="-1" id="2-1-6-CTW-12k">2.1.6 CTW-12k</h4>
<p>​    2017，12000 多张，中英文。</p>
<h4 id="2.1.7-mtwi" tabindex="-1" id="2-1-7-MTWI">2.1.7 MTWI</h4>
<p>​    迄今为止最大的多语言数据集之一，拥有 20000 张图像。</p>
<h4 id="2.1.8-synthtext" tabindex="-1" id="2-1-8-SynthText">2.1.8 SynthText</h4>
<p>​    包含 80 万个场景文本图像。它的注释由单词级和字符级轴对齐的边界框及其转录组成。它的缺点是，它使用了与 COCO 文本类似的轴对齐的边界框，这不适合多方向的文本。</p>
<h4 id="2.1.9-cute80" tabindex="-1" id="2-1-9-CUTE80">2.1.9 CUTE80</h4>
<p>​    第一个突出弯曲文本的场景文本数据集，可惜只有 80 张。</p>
<h4 id="2.1.10-ctw1500" tabindex="-1" id="2-1-10-CTW1500">2.1.10 CTW1500</h4>
<p>​    原则上是最接近 Total Text 的数据集。Total Text 的文本实例在单词级别进行注释，而 CTW1500 的文本实例则在行级别进行注释。</p>
<h3 id="2.2-scene-text-detection" tabindex="-1" id="2-2-Scene-text-detection">2.2 Scene text detection</h3>
<h4 id="2.2.1-scene-text-inspired-handcrafted-feature-era" tabindex="-1" id="2-2-1-Scene-text-inspired-handcrafted-feature-era">2.2.1 Scene text inspired handcrafted feature era</h4>
<p>​    场景文本的手工特征时代。</p>
<h4 id="2.2.2-the-emergence-of-cnn" tabindex="-1" id="2-2-2-The-emergence-of-CNN">2.2.2 The emergence of CNN</h4>
<p>​    CNN 的出现。</p>
<h4 id="2.2.3-segmentation-based-scene-text-detection" tabindex="-1" id="2-2-3-Segmentation-based-scene-text-detection">2.2.3 Segmentation-based scene text detection</h4>
<p>​    基于分割的场景文本检测。</p>
<h4 id="2.2.4-proposal-based-scene-text-detection" tabindex="-1" id="2-2-4-Proposal-based-scene-text-detection">2.2.4 Proposal-based scene text detection</h4>
<p>​    基于提示的场景文本检测。</p>
<h4 id="2.2.5-single-network-scene-text-detection" tabindex="-1" id="2-2-5-Single-network-scene-text-detection">2.2.5 Single network scene text detection</h4>
<p>​    单网络场景文本检测。</p>
<h4 id="2.2.6-curved-text-detection" tabindex="-1" id="2-2-6-Curved-text-detection">2.2.6 Curved text detection</h4>
<p>​    曲线文本检测。</p>
<h2 id="3-the-total-text-dataset" tabindex="-1" id="3-The-Total-Text-dataset">3 The Total-Text dataset</h2>
<h3 id="3.1-dataset-attributes" tabindex="-1" id="3-1-Dataset-attributes">3.1 Dataset attributes</h3>
<h4 id="3.1.1-curved-text-is-an-overlooked-problem" tabindex="-1" id="3-1-1-Curved-text-is-an-overlooked-problem">3.1.1 Curved text is an overlooked problem</h4>
<p>​    水平文本的检测性能几乎达到饱和（F-score 为 0.9），但是缺乏弯曲文本。</p>
<h4 id="3.1.2-curved-text-observation" tabindex="-1" id="3-1-2-Curved-text-observation">3.1.2 Curved text observation</h4>
<p>​    曲线不是直线。它在整个线路上不受角度变化的限制。</p>
<h4 id="3.1.3-detection-ground-truth-annotation" tabindex="-1" id="3-1-3-Detection-ground-truth-annotation">3.1.3 Detection ground truth annotation</h4>
<p>​    Total Text 中的文本实例是以单词级别的粒度进行注释的。</p>
<h4 id="3.1.4-recognition-ground-truth-annotation" tabindex="-1" id="3-1-4-Recognition-ground-truth-annotation">3.1.4 Recognition ground truth annotation</h4>
<p>​    提供了单词 recognition 挑战的 GT。</p>
<h4 id="3.1.5-segmentation-ground-truth-annotation" tabindex="-1" id="3-1-5-Segmentation-ground-truth-annotation">3.1.5 Segmentation ground truth annotation</h4>
<p>​    像素级的 GT 标注是最耗时的过程，我们提供了多种预处理方案。</p>
<p><img src="P2_5.png" alt="png"></p>
<center>像素级注释过程。<b>a</b> 输入图像补丁。<b>b</b>、 <b>c</b> 调整颜色阈值，使文本与背景区域分离。<b>d–f</b> 删除“非文本”区域。<b>g</b> 最终结果</center>
<h4 id="3.1.6-orientation-annotation" tabindex="-1" id="3-1-6-Orientation-annotation">3.1.6 Orientation annotation</h4>
<p>具体来说，注释是这样表示的：</p>
<ul>
<li>‘h’ 表示水平文本</li>
<li>‘m’ 表示多向文本</li>
<li>‘c’ 表示弯曲文本</li>
</ul>
<h4 id="3.1.7-regulated-polygon-ground-truth" tabindex="-1" id="3-1-7-Regulated-polygon-ground-truth">3.1.7 Regulated polygon ground truth</h4>
<p>​    在本文中，我们使用以下方案对全文注释进行了改进。除了将多边形顶点的数量设置为 10（根据经验，10 个顶点足以紧密覆盖我们数据集中的所有单词级文本实例）</p>
<p>​    新的多边形地面实况注释步骤如图 7 所示。首先，需要人工注释器手动选择四个不同的顶点，作为单词实例的开始和结束顶点。单词“MARLEY”（红点和绿点）上角的两个顶点将用于生成三条等距的黄色引导线。生成引导线的算法在算法 1 中进行了说明。然后，人类注释者将沿着每条黄色引导线选择一个截取点（表示为“*”），该点最能绑定单词的顶部边界。</p>
<hr>
<p><strong>算法 1</strong>  在调节多边形注释过程中生成引导线的算法，emmmm 就是给个上界和下界生成三等分的点，这样文字的四个角和三条三等分的线就可以形成 10 个顶点。</p>
<p><img src="P2A_1.png" alt="png"></p>
<hr>
<h3 id="3.2-dataset-statistics" tabindex="-1" id="3-2-Dataset-statistics">3.2 Dataset statistics</h3>
<h4 id="3.2.1-strength-in-numbers" tabindex="-1" id="3-2-1-Strength-in-numbers">3.2.1 Strength in numbers</h4>
<p>​    Total Text 分为两组：训练集和测试集，分别有 1255 张和 300 张图像。图 10 显示了 Total Text 的一系列统计信息。它总共有 11459 个带注释的文本实例，平均每个图像有7.37个实例。Total Text 中超过一半的图像具有两个不同的方向及以上，平均每个图像产生1.8个方向。</p>
<p>​    数据集的收集也考虑到了质量，包括场景复杂性。例如类似文本和低对比度背景，不同的字体类型和大小。</p>
<h4 id="3.2.2-orientation-diversity" tabindex="-1" id="3-2-2-Orientation-diversity">3.2.2 Orientation diversity</h4>
<p>​    大约一半的文本实例是弯曲的，另一半在水平和多向之间几乎相等地划分。尽管所有图像都是在考虑弯曲文本的情况下收集的，但其他方向仍然占据了总实例的一半。仔细观察 Total Text 可以发现，弯曲文本通常与水平文本或多方向文本一起出现。图像中文本方向的混合对文本检测算法在文本方向方面实现鲁棒性和泛化提出了挑战。</p>
<h4 id="3.2.3-scenery-diversity" tabindex="-1" id="3-2-3-Scenery-diversity">3.2.3 Scenery diversity</h4>
<p>​    Total Text 图像中的风景也很多样化。</p>
<h2 id="4-evaluation-protocol" tabindex="-1" id="4-Evaluation-protocol">4 Evaluation protocol</h2>
<h3 id="4.1-deteval" tabindex="-1" id="4-1-DetEval">4.1 DetEval</h3>
<p>​    Total Text 首次引入 DetEval 评估协议。然而，我们意识到，建议的 tp 和 tr 阈值，分别为 0.4 和 0.8，并没有通过在 Total text 中包含弯曲文本和多边形地面实况进行优化。</p>
<h3 id="4.2-pascal-voc" tabindex="-1" id="4-2-PASCAL-VOC">4.2 PASCAL VOC</h3>
<p>​    与 CTW1500 和 ICDAR2015 类似，PASCAL VOC 评估方法也适用于 Total Text。</p>
<h3 id="4.3-intersection-area-between-polygons" tabindex="-1" id="4-3-Intersection-area-between-polygons">4.3 Intersection area between polygons</h3>
<p>​    预测区域和地面实况区域之间的交集计算是 DetEval 和 Pascal VOC 评估协议的核心。</p>
<h2 id="5-scene-text-detection-annotation-tool" tabindex="-1" id="5-Scene-text-detection-annotation-tool">5 Scene text detection annotation tool</h2>
<p>​    提出了一个注释工具：<strong>Total Text tool（T3）</strong>，能够将注释时间减少 25%，与人类注释者的一致率为 84%。</p>
<h3 id="5.1-total-text-tool" tabindex="-1" id="5-1-Total-Text-Tool">5.1 Total-Text-Tool</h3>
<h3 id="5.2-experiment-setup" tabindex="-1" id="5-2-Experiment-setup">5.2 Experiment setup</h3>
<h3 id="5.3-performance-analysis" tabindex="-1" id="5-3-Performance-analysis">5.3 Performance analysis</h3>
<h2 id="6-polygon-faster-rcnn" tabindex="-1" id="6-Polygon-faster-RCNN">6 Polygon-faster-RCNN</h2>
<h3 id="6.1-text-line-encoding-method" tabindex="-1" id="6-1-Text-line-encoding-method">6.1  Text line encoding method</h3>
<p>​    Faster RCNN、SSD和YOLO中使用的传统回归目标 (x_m，y_m，w，h) 只能用于轴对称矩形框，而不能用于多边形。</p>
<h4 id="6.1.1-variants-of-poly-frcnn" tabindex="-1" id="6-1-1-Variants-of-Poly-FRCNN">6.1.1 Variants of Poly-FRCNN</h4>
<p>​    Poly-FRCNN-5 是 3 的放大版，它在回归头中又有 10 个参数</p>
<h4 id="6.1.2-encode" tabindex="-1" id="6-1-2-Encode">6.1.2 Encode</h4>
<h4 id="6.1.3-decode" tabindex="-1" id="6-1-3-Decode">6.1.3 Decode</h4>
<h3 id="6.2-anchor-polygons-parameterization" tabindex="-1" id="6-2-Anchor-polygons-parameterization">6.2 Anchor polygons parameterization</h3>
<h3 id="6.3-implementation-details" tabindex="-1" id="6-3-Implementation-details">6.3 Implementation details</h3>
<h4 id="6.3.1-feature-extractor" tabindex="-1" id="6-3-1-Feature-extractor">6.3.1 Feature extractor</h4>
<p>​    模型采用 Inception-Resnet-V2 作为特征提取器。</p>
<h4 id="6.3.2-anchor-boxes" tabindex="-1" id="6-3-2-Anchor-boxes">6.3.2 Anchor boxes</h4>
<h4 id="6.3.3-loss-function" tabindex="-1" id="6-3-3-Loss-function">6.3.3 Loss function</h4>
<h4 id="6.3.4-training" tabindex="-1" id="6-3-4-Training">6.3.4 Training</h4>
<p>​    所有的 models 都经过了相同的训练计划。</p>
<ul>
<li>
<p>它们首先使用 <strong>ImageNet</strong> <strong>pre-trained</strong> 的权重进行初始化。</p>
</li>
<li>
<p>然后，训练计划从 <strong>SynthText</strong> 上的 100 K 次迭代开始，然后是来自 <strong>COCO Text</strong> 的真实世界数据上的另外 100 K 次重复。最后，我们使用目标训练集对它们进行了 <strong>fine tune</strong>，以进行另外 50 K 次迭代。</p>
</li>
</ul>
<p>​    该训练计划中最大数据集（SynthText）的初始学习率设置为0.003，然后自COCO Text训练开始以来降低了0.0003，并在其余训练中保持不变。</p>
<p>​    来自 <strong>SynthText</strong> 的 <strong>100K</strong> 图像被随机选择用于训练的第一阶段。</p>
<p>​    然后，在第二训练阶段期间使用来自具有至少一个可阅读文本实例的 <strong>COCO-Text</strong> 的大约 <strong>13K</strong> 个训练图像。</p>
<p>​    最后，来自总文本训练集的 1255 幅图像被用于 <strong>fine-tuning</strong> 阶段。</p>
<h4 id="6.3.5-testing" tabindex="-1" id="6-3-5-Testing">6.3.5 Testing</h4>
<p>​    这个过程尽可能简单。除了标准的非最大值抑制（NMS）外，没有使用后处理或多尺度。</p>
<h3 id="6.4-evaluation" tabindex="-1" id="6-4-Evaluation">6.4 Evaluation</h3>
<h4 id="6.4.1-dataset" tabindex="-1" id="6-4-1-Dataset">6.4.1 Dataset</h4>
<p>​    我们评估了 Poly FRCNN 在 ICDAR2013、ICDAR2015 和 Total Text 上的性能。选择 ICDAR2013 和 ICDAR2015 分别演示了 PolyFRCNN 在水平文本和多方向文本上的性能。</p>
<h4 id="6.4.2-evaluation-protocol" tabindex="-1" id="6-4-2-Evaluation-Protocol">6.4.2 Evaluation Protocol</h4>
<p>​    使用 DetEval 方案中的建议（即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>p</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>4</mn></mrow><annotation encoding="application/x-tex">tp=0.4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit">p</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">4</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">tr=0.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span></span></span></span>）对 ICDAR2013 报告的性能进行评估，以便与现有技术的解决方案进行公平比较。对于 Total-Text ，我们使用了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>p</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">tp=0.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit">p</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn></mrow><annotation encoding="application/x-tex">tr=0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">7</span></span></span></span>，同时，对 ICDAR2015 和 Total Text 的结果使用了 Pascal VOC 评估方法的标准<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">U</mi></mrow></mrow><annotation encoding="application/x-tex">0.5\mathrm{IoU}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span><span class="mord textstyle uncramped"><span class="mord mathrm">I</span><span class="mord mathrm">o</span><span class="mord mathrm">U</span></span></span></span></span> 阈值。</p>
<h4 id="6.4.3-performance-analysis" tabindex="-1" id="6-4-3-Performance-analysis">6.4.3 Performance analysis</h4>
<h4 id="6.4.4-box-frcnn-versus-poly-frcnn-3" tabindex="-1" id="6-4-4-Box-FRCNN-versus-Poly-FRCNN-3">6.4.4 Box-FRCNN versus Poly-FRCNN-3</h4>
<h4 id="6.4.5-poly-baseline-versus-poly-frcnn-3" tabindex="-1" id="6-4-5-Poly-Baseline-versus-Poly-FRCNN-3">6.4.5 Poly-Baseline versus Poly-FRCNN-3</h4>
<h4 id="6.4.6-poly-frcnn-5" tabindex="-1" id="6-4-6-Poly-FRCNN-5">6.4.6 Poly-FRCNN-5</h4>
<h4 id="6.4.7-inference-time" tabindex="-1" id="6-4-7-Inference-time">6.4.7 Inference time</h4>
<h4 id="6.4.8-performance-on-other-curved-text-datasets" tabindex="-1" id="6-4-8-Performance-on-other-curved-text-datasets">6.4.8 Performance on other curved text datasets</h4>
<p>​    除了Total Text，我们还在其他曲线文本数据集 CUTE-80 和 CTW1500 上评估了我们提出的模型。Poly-FRCNN-3 在上述数据集上的 F-Score 分别达到 0.65 和 0.72（表5）。请注意，CUTE80 中的注释粒度不一致（即单词级别和行级别的混合），因此我们在评估之前将它们重新标记。</p>
<h3 id="6.5-cross-datasets-experiment" tabindex="-1" id="6-5-Cross-datasets-experiment">6.5 Cross datasets experiment</h3>
<p><img src="P2T_6.png" alt="png"></p>
<h4 id="6.5.1-pretraining-on-synthtext-and-coco-text-only" tabindex="-1" id="6-5-1-Pretraining-on-SynthText-and-COCO-Text-only">6.5.1 Pretraining on SynthText and COCO-Text only</h4>
<p>​    仅在 SynthText 和 COCO Text 上训练的模型（表 6 中的第一行）通常比在相应数据集上进行微调的其他模型表现更差。尽管该模型的性能在 ICDAR2013 和 ICDAR2015 上仍然具有竞争力，即使没有对其进行微调；它在 Total Text 上的性能最差，与性能最好的模型（第四排）相比，在 F-Score 方面有 0.24 的大差距。</p>
<h4 id="6.5.2-fine-tuning-on-icdar2013-and-icdar2015" tabindex="-1" id="6-5-2-Fine-tuning-on-ICDAR2013-and-ICDAR2015">6.5.2 Fine-tuning on ICDAR2013 and ICDAR2015</h4>
<p>​    ICDAR2013 主要由水平文本组成，并使用轴对称框作为基本事实，因此，对其进行微调无助于提高其在 Total text 上的性能也就不足为奇了</p>
<h4 id="6.5.3-fine-tuning-on-total-text" tabindex="-1" id="6-5-3-Fine-tuning-on-Total-Text">6.5.3 Fine-tuning on Total-Text</h4>
<p>​    虽然该模型仅在 Total-Text 上进行了微调，但在其他两个数据集上取得了良好的结果，这表明 Total Text 的数据足够多样化，可以用于模型的泛化。</p>
<h3 id="6.6-state-of-the-art-analysis" tabindex="-1" id="6-6-State-of-the-art-analysis">6.6 State-of-the-art analysis</h3>
<p>​    其他工作balabala……</p>
<h2 id="7-conclusion" tabindex="-1" id="7-Conclusion">7 Conclusion</h2>
<h1 id="%E4%BB%93%E5%BA%93" tabindex="-1">仓库</h1>
<p>​    从 GitHub <a target="_blank" rel="noopener" href="https://github.com/cs-chan/Total-Text-Dataset">cs-chan/Total-Text-Dataset: Total Text Dataset. It consists of 1555 images with more than 3 different text orientations: Horizontal, Multi-Oriented, and Curved, one of a kind. (github.com)</a> 里下载代码：</p>
<p><img src="C1.png" alt="png"></p>
<h2 id="annotation_tools" tabindex="-1" id="Annotation-tools">Annotation_tools</h2>
<p><img src="CA1.png" alt="png"></p>
<p>​    他们提供的一个标注工具，看样子使用 Objective-C 写的。</p>
<p>​    Total-Text-Tool (T3) is a guided annotation framework that is designed to reduce annotation time. In our experiment, T3 reduces annotation time by 25%. For more details of T3 and all related experiments, please refer to our <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10032-019-00334-z">IJDAR journal publication</a>.</p>
<p>​    We make all three variants of T3 available.</p>
<ol>
<li>T3_v1 - the baseline version, <strong>the suggestion mechanism is not incorporated</strong>. 不带提示，完全手工</li>
<li>T3_v2 - the suggestion mechanism is incorporated, <strong>only suggest rectangle bounding box</strong>, polygon is not suggested. 只支持 bbox</li>
<li>T3_v3 - suggests <strong>both rectangle and polygon bounding box</strong>. 最后可以生成 bbox 和 多边形</li>
</ol>
<p>​    Kindly refer to ‘T3_use_cases’ for different use cases of T3_v3.</p>
<h2 id="baseline" tabindex="-1" id="Baseline">Baseline</h2>
<p>​    有两个模型：</p>
<ul>
<li>Polygon-Faster-RCNN-3 (P3)</li>
<li>Polygon-Faster-RCNN-5 (P5)</li>
</ul>
<p>​    要预训练模型啊……好像搞不到</p>
<h2 id="dataset" tabindex="-1" id="Dataset">Dataset</h2>
<p>​    The Total-Text dataset can be downloaded at <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1bC68CzsSVTusZVvOkk7imSZSbgD1MqK2/view?usp=sharing">this https URL</a> (size = 441Mb).</p>
<h2 id="evaluation_protocol" tabindex="-1" id="Evaluation-Protocol">Evaluation_Protocol</h2>
<p>​    这些代码是 Total Text 的官方评估协议实现。提供了两种方法：Deteval 和 Pascal VOC 协议。</p>
<h3 id="deteval" tabindex="-1" id="Deteval">Deteval</h3>
<p>​    我们建议 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>r</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn></mrow><annotation encoding="application/x-tex">tr=0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">7</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>p</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">tp=0.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit">p</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">6</span></span></span></span> 阈值，以便使用多边形地面实况和检测格式进行更公平的评估。</p>
<p><code>Deteval.py</code> 代码解析：</p>
<ul>
<li>定义</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> os <span class="hljs-keyword">import</span> listdir<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> io<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># mask counting version</span><br><span class="hljs-comment"># from polygon_wrapper import iod</span><br><span class="hljs-comment"># from polygon_wrapper import area_of_intersection</span><br><span class="hljs-comment"># from polygon_wrapper import area</span><br><br><span class="hljs-comment"># polygon based version</span><br><span class="hljs-keyword">from</span> polygon_fast <span class="hljs-keyword">import</span> iod<br><span class="hljs-keyword">from</span> polygon_fast <span class="hljs-keyword">import</span> area_of_intersection<br><span class="hljs-keyword">from</span> polygon_fast <span class="hljs-keyword">import</span> area<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">try</span>: <span class="hljs-comment"># python2</span><br>    <span class="hljs-built_in">range</span> = xrange<br>excerpt excerption:<br>    <span class="hljs-comment"># python3</span><br>    <span class="hljs-built_in">range</span> = <span class="hljs-built_in">range</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Input format: y0,x0, ..... yn,xn. Each detection is separated by the end of line token (&#x27;\n&#x27;)&#x27;</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>input_dir = <span class="hljs-string">&#x27;../Examples/Prediction/&#x27;</span> <span class="hljs-comment">#detection directory goes here</span><br>gt_dir = <span class="hljs-string">&#x27;../Examples/Groundtruth/&#x27;</span> <span class="hljs-comment">#gt directory goes here</span><br>fid_path = <span class="hljs-string">&#x27;../Examples/&#x27;</span> <span class="hljs-comment">#output text file directory goes here</span><br><br>allInputs = listdir(input_dir)<br></code></pre></td></tr></table></figure>
<ul>
<li><code>def input_reading_mod()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">input_reading_mod</span>(<span class="hljs-params">input_dir, <span class="hljs-built_in">input</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;This helper reads input from txt files&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;%s/%s&#x27;</span> % (input_dir, <span class="hljs-built_in">input</span>), <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;latin-1&#x27;</span>) <span class="hljs-keyword">as</span> input_fid:<br>        pred = input_fid.readlines()<br>    det = [x.strip(<span class="hljs-string">&#x27;\n&#x27;</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> pred]<br>    <span class="hljs-keyword">return</span> det<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这是一个名为 <code>input_reading_mod</code> 的函数定义，它用于从文本文件中读取输入。</p>
<p>函数的输入参数包括 <code>input_dir </code>和 <code>input</code>，分别表示输入目录和要读取的文件名。</p>
<p>函数的功能是打开指定路径下的文本文件，并按照每行的格式读取文件内容。使用<code>open</code>函数打开文件时，通过 <code>'%s/%s' % (input_dir, input)</code> 的方式构建了文件的完整路径，并且指定了使用 <code>'r'</code> 模式以只读方式打开文件。<code>encoding='latin-1'</code> 参数指定了文件的编码格式为 Latin-1。</p>
<p>接着，使用 <code>readlines</code> 方法将文件内容按行读取，并将结果存储在 <code>pred</code> 列表中。然后，使用列表推导式 <code>[x.strip('\n') for x in pred]</code> 去掉每行末尾的换行符，得到处理后的数据列表 <code>det</code>。</p>
<p>最后，函数返回 <code>det</code> 列表作为输出结果。</p>
</blockquote>
<ul>
<li><code>gt_reading_mod()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gt_reading_mod</span>(<span class="hljs-params">gt_dir, gt_id</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;This helper reads groundtruths from mat files&quot;&quot;&quot;</span><br>    gt_id = gt_id.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]<br>    gt = io.loadmat(<span class="hljs-string">&#x27;%s/poly_gt_%s.mat&#x27;</span> % (gt_dir, gt_id))<br>    gt = gt[<span class="hljs-string">&#x27;polygt&#x27;</span>]<br>    <span class="hljs-keyword">return</span> gt<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这是一个名为 <code>gt_reading_mod</code> 的函数定义，它用于从 <code>.mat</code> 文件中读取标注数据。</p>
<p>函数的输入参数包括 <code>gt_dir</code> 和 <code>gt_id</code>，分别表示标注目录和要读取的文件名。</p>
<p>函数的功能是首先对 <code>gt_id</code> 进行字符串处理，通过 <code>.split('.')[0]</code> 将文件名中的扩展名去除。</p>
<p>然后，使用 <code>io.loadmat</code> 函数读取指定路径下的 <code>.mat </code>文件，该文件的完整路径由<code>'%s/poly_gt_%s.mat' % (gt_dir, gt_id)</code>构建而成。<code>loadmat</code>函数将<code>.mat</code>文件中的数据读入到一个字典类型的变量<code>gt</code>中。</p>
<p>接着，从字典中获取名为<code>polygt</code>的键值对应的数据，并将其存储在变量<code>gt</code>中。</p>
<p>最后，函数返回<code>gt</code>作为输出结果。</p>
</blockquote>
<ul>
<li><code>detection_filtering()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">detection_filtering</span>(<span class="hljs-params">detections, groundtruths, threshold=<span class="hljs-number">0.5</span></span>):<br>    <span class="hljs-keyword">for</span> gt_id, gt <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(groundtruths):<br>        <span class="hljs-keyword">if</span> (gt[<span class="hljs-number">5</span>] == <span class="hljs-string">&#x27;#&#x27;</span>) <span class="hljs-keyword">and</span> (gt[<span class="hljs-number">1</span>].shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>):<br>            gt_x = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, np.squeeze(gt[<span class="hljs-number">1</span>])))<br>            gt_y = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, np.squeeze(gt[<span class="hljs-number">3</span>])))<br>            <span class="hljs-keyword">for</span> det_id, detection <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(detections):<br>                detection = detection.split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>                detection = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, detection))<br>                det_y = detection[<span class="hljs-number">0</span>::<span class="hljs-number">2</span>]<br>                det_x = detection[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>]<br>                det_gt_iou = iod(det_x, det_y, gt_x, gt_y)<br>                <span class="hljs-keyword">if</span> det_gt_iou &gt; threshold:<br>                    detections[det_id] = []<br><br>            detections[:] = [item <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> detections <span class="hljs-keyword">if</span> item != []]<br>    <span class="hljs-keyword">return</span> detections<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这是一个名为 <code>detection_filtering</code> 的函数定义，用于过滤掉与标注数据重叠度低的检测结果。</p>
<p>函数的输入参数包括 <code>detections</code> 和 <code>groundtruths</code>，分别表示检测结果和标注数据。另外还有一个可选参数 <code>threshold</code>，表示重叠度的阈值，默认为 0.5。</p>
<p>函数的功能是遍历所有的标注数据，对于每个标注数据，判断其是否为文字区域（<code>gt[5] == '#'</code>）并且有多个顶点（<code>gt[1].shape[1] &gt; 1</code>）。如果满足这两个条件，则将标注数据的顶点信息提取出来，分别存储在 <code>gt_x</code> 和 <code>gt_y</code> 列表中。</p>
<p>然后，遍历所有的检测结果，对于每个检测结果，先将其按逗号分隔，并将得到的字符串列表转换为整数列表。再根据坐标的奇偶性，将检测结果的 x 坐标和 y 坐标分别存储在 <code>det_x</code> 和 <code>det_y</code> 列表中。</p>
<p>接下来，使用 <code>iod</code> 函数计算检测结果与标注数据之间的重叠度（Intersection over Detection）。如果重叠度大于设定的阈值，则将该检测结果从 <code>detections</code> 列表中移除，即将其置为空列表 <code>[]</code>。</p>
<p>最后，使用列表推导式 <code>[item for item in detections if item != []]</code> 将不为空的检测结果重新存储到 <code>detections</code> 列表中。</p>
<p>函数返回经过过滤后的 <code>detections</code> 列表作为输出结果。</p>
</blockquote>
<ul>
<li><code>sigma_calculation()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigma_calculation</span>(<span class="hljs-params">det_x, det_y, gt_x, gt_y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    sigma = inter_area / gt_area</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># print(area_of_intersection(det_x, det_y, gt_x, gt_y))</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">round</span>((area_of_intersection(det_x, det_y, gt_x, gt_y) / area(gt_x, gt_y)), <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这是一个名为 <code>sigma_calculation</code> 的函数定义，用于计算检测结果与标注数据之间的重叠度。</p>
<p>函数的输入参数包括 <code>det_x</code>、<code>det_y</code>、<code>gt_x</code> 和 <code>gt_y</code>，分别表示检测结果和标注数据的顶点坐标。</p>
<p>函数的功能是根据以下公式计算重叠度（sigma）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">sigma = inter_area / gt_area<br></code></pre></td></tr></table></figure>
<p>其中，<code>inter_area</code> 表示检测结果与标注数据之间的交集区域面积，<code>gt_area</code> 表示标注数据的区域面积。</p>
<p>函数内部通过调用两个辅助函数 <code>area_of_intersection</code> 和 <code>area</code> 来计算交集区域面积和标注数据区域面积。然后将交集区域面积除以标注数据区域面积，并使用 <code>np.round</code> 函数将结果四舍五入到小数点后两位。</p>
<p>最后，函数返回计算得到的重叠度作为输出结果。</p>
</blockquote>
<ul>
<li><code>tau_calculation()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tau_calculation</span>(<span class="hljs-params">det_x, det_y, gt_x, gt_y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    tau = inter_area / det_area</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">round</span>((area_of_intersection(det_x, det_y, gt_x, gt_y) / area(det_x, det_y)), <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这是一个名为 <code>tau_calculation</code> 的函数定义，用于计算检测结果与标注数据之间的重叠度。</p>
<p>函数的输入参数包括 <code>det_x</code>、<code>det_y</code>、<code>gt_x</code> 和 <code>gt_y</code>，分别表示检测结果和标注数据的顶点坐标。</p>
<p>函数的功能是根据以下公式计算重叠度（tau）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">tau = inter_area / det_area<br></code></pre></td></tr></table></figure>
<p>其中，<code>inter_area </code> 表示检测结果与标注数据之间的交集区域面积，<code>det_area</code> 表示检测结果的区域面积。</p>
<p>函数内部通过调用两个辅助函数 <code>area_of_intersection</code> 和 <code>area </code>来计算交集区域面积和检测结果区域面积。然后将交集区域面积除以检测结果区域面积，并使用 <code>np.round</code> 函数将结果四舍五入到小数点后两位。</p>
<p>最后，函数返回计算得到的重叠度作为输出结果。</p>
</blockquote>
<ul>
<li>变量定义</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">global_tp = <span class="hljs-number">0</span><br>global_fp = <span class="hljs-number">0</span><br>global_fn = <span class="hljs-number">0</span><br>global_sigma = []<br>global_tau = []<br>tr = <span class="hljs-number">0.7</span><br>tp = <span class="hljs-number">0.6</span><br>fsc_k = <span class="hljs-number">0.8</span><br>k = <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码定义了一些全局变量 <code>global_tp</code>、<code>global_fp</code>、<code>global_fn</code>、<code>global_sigma</code> 和 <code>global_tau</code>，并给它们分别赋初值0和空列表。</p>
<p>其中，<code>global_tp </code>表示全局的真正例数量（True Positive），<code>global_fp</code> 表示全局的假正例数量（False Positive），<code>global_fn</code> 表示全局的假负例数量（False Negative），<code>global_sigma </code> 表示全局的重叠度（sigma）列表，<code>global_tau</code> 表示全局的重叠度（tau）列表。</p>
<p>接下来，代码定义了一些参数：<code>tr</code> 表示阈值，<code>tp</code> 表示真正例比例阈值，<code>fsc_k</code> 表示 F1 分数的参数 k，<code>k </code>表示一个系数。</p>
<p>这段代码仅仅给这些变量和参数赋了初值，并没有其他具体的逻辑操作。</p>
</blockquote>
<ul>
<li>评估</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> input_id <span class="hljs-keyword">in</span> tqdm(allInputs):<br>    <span class="hljs-keyword">if</span> (input_id != <span class="hljs-string">&#x27;.DS_Store&#x27;</span>) <span class="hljs-keyword">and</span> (input_id != <span class="hljs-string">&#x27;Pascal_result.txt&#x27;</span>) <span class="hljs-keyword">and</span> (<br>            input_id != <span class="hljs-string">&#x27;Pascal_result_curved.txt&#x27;</span>) <span class="hljs-keyword">and</span> (input_id != <span class="hljs-string">&#x27;Pascal_result_non_curved.txt&#x27;</span>) <span class="hljs-keyword">and</span> (input_id != <span class="hljs-string">&#x27;Deteval_result.txt&#x27;</span>) <span class="hljs-keyword">and</span> (input_id != <span class="hljs-string">&#x27;Deteval_result_curved.txt&#x27;</span>) \<br>            <span class="hljs-keyword">and</span> (input_id != <span class="hljs-string">&#x27;Deteval_result_non_curved.txt&#x27;</span>):<br>        <span class="hljs-comment"># print(input_id)</span><br>        detections = input_reading_mod(input_dir, input_id)<br>        groundtruths = gt_reading_mod(gt_dir, input_id)<br>        detections = detection_filtering(detections, groundtruths)  <span class="hljs-comment"># filters detections overlapping with DC area</span><br>        dc_id = np.where(groundtruths[:, <span class="hljs-number">5</span>] == <span class="hljs-string">&#x27;#&#x27;</span>)<br>        groundtruths = np.delete(groundtruths, (dc_id), (<span class="hljs-number">0</span>))<br><br>        local_sigma_table = np.zeros((groundtruths.shape[<span class="hljs-number">0</span>], <span class="hljs-built_in">len</span>(detections)))<br>        local_tau_table = np.zeros((groundtruths.shape[<span class="hljs-number">0</span>], <span class="hljs-built_in">len</span>(detections)))<br><br>        <span class="hljs-keyword">for</span> gt_id, gt <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(groundtruths):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(detections) &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">for</span> det_id, detection <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(detections):<br>                    detection = detection.split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>                    detection = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, detection))<br>                    det_y = detection[<span class="hljs-number">0</span>::<span class="hljs-number">2</span>]<br>                    det_x = detection[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>]<br>                    gt_x = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, np.squeeze(gt[<span class="hljs-number">1</span>])))<br>                    gt_y = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, np.squeeze(gt[<span class="hljs-number">3</span>])))<br><br>                    local_sigma_table[gt_id, det_id] = sigma_calculation(det_x, det_y, gt_x, gt_y)<br>                    local_tau_table[gt_id, det_id] = tau_calculation(det_x, det_y, gt_x, gt_y)<br><br>        global_sigma.append(local_sigma_table)<br>        global_tau.append(local_tau_table)<br><br>global_accumulative_recall = <span class="hljs-number">0</span><br>global_accumulative_precision = <span class="hljs-number">0</span><br>total_num_gt = <span class="hljs-number">0</span><br>total_num_det = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码通过一个 <code>for</code> 循环遍历名为 <code>allInputs</code> 的列表中的每个元素 <code>input_id</code>。</p>
<p>在循环内部，首先使用一系列条件语句来过滤掉一些特定的 <code>input_id</code>，包括 <code>.DS_Store</code>、<code>Pascal_result.txt </code>等等。然后调用 <code>input_reading_mod </code>函数从 <code>input_dir</code> 目录中读取输入数据，调用 <code>gt_reading_mod</code> 函数从 <code>gt_dir</code> 目录中读取标注数据。</p>
<p>接下来，通过调用 <code>detection_filtering</code> 函数对检测结果进行过滤，去掉与 DC 区域重叠的检测结果。然后找到标注数据中 DC 区域对应的索引，并通过 <code>np.delete</code> 函数将其从标注数据中删除。</p>
<p>接着，创建了两个零矩阵 <code>local_sigma_table</code> 和 <code>local_tau_table</code>，形状分别为 <code>(groundtruths.shape[0], len(detections))</code>，用来存储每个标注和检测结果之间的重叠度信息。</p>
<p>接下来的两个嵌套的 <code>for</code> 循环用于计算每个标注和检测结果之间的重叠度。首先解析检测结果和标注数据的坐标信息，并调用 <code>sigma_calculation</code> 和 <code>tau_calculation</code> 函数来计算重叠度。将计算得到的重叠度存储在 <code>local_sigma_table</code> 和 <code>local_tau_table</code> 中。</p>
<p>最后，将 <code>local_sigma_table</code> 和 <code>local_tau_table</code> 分别添加到 <code>global_sigma</code> 和 <code>global_tau</code> 列表中，用于保存所有标注和检测结果之间的重叠度信息。</p>
<p>代码的最后几行定义了一些变量，包括 <code>global_accumulative_recall</code>、<code>global_accumulative_precision</code>、<code>total_num_gt</code>和 <code>total_num_det</code>，并给它们赋初值 0。这些变量可能在后续代码中使用。</p>
</blockquote>
<ul>
<li><code>one_to_one()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">one_to_one</span>(<span class="hljs-params">local_sigma_table, local_tau_table, local_accumulative_recall,</span><br><span class="hljs-params">               local_accumulative_precision, global_accumulative_recall, global_accumulative_precision,</span><br><span class="hljs-params">               gt_flag, det_flag</span>):<br>    <span class="hljs-keyword">for</span> gt_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gt):<br>        gt_matching_qualified_sigma_candidates = np.where(local_sigma_table[gt_id, :] &gt; tr)<br>        gt_matching_num_qualified_sigma_candidates = gt_matching_qualified_sigma_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br>        gt_matching_qualified_tau_candidates = np.where(local_tau_table[gt_id, :] &gt; tp)<br>        gt_matching_num_qualified_tau_candidates = gt_matching_qualified_tau_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>        det_matching_qualified_sigma_candidates = np.where(local_sigma_table[:, gt_matching_qualified_sigma_candidates[<span class="hljs-number">0</span>]] &gt; tr)<br>        det_matching_num_qualified_sigma_candidates = det_matching_qualified_sigma_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br>        det_matching_qualified_tau_candidates = np.where(local_tau_table[:, gt_matching_qualified_tau_candidates[<span class="hljs-number">0</span>]] &gt; tp)<br>        det_matching_num_qualified_tau_candidates = det_matching_qualified_tau_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br><br>        <span class="hljs-keyword">if</span> (gt_matching_num_qualified_sigma_candidates == <span class="hljs-number">1</span>) <span class="hljs-keyword">and</span> (gt_matching_num_qualified_tau_candidates == <span class="hljs-number">1</span>) <span class="hljs-keyword">and</span> \<br>                (det_matching_num_qualified_sigma_candidates == <span class="hljs-number">1</span>) <span class="hljs-keyword">and</span> (det_matching_num_qualified_tau_candidates == <span class="hljs-number">1</span>):<br>            global_accumulative_recall = global_accumulative_recall + <span class="hljs-number">1.0</span><br>            global_accumulative_precision = global_accumulative_precision + <span class="hljs-number">1.0</span><br>            local_accumulative_recall = local_accumulative_recall + <span class="hljs-number">1.0</span><br>            local_accumulative_precision = local_accumulative_precision + <span class="hljs-number">1.0</span><br><br>            gt_flag[<span class="hljs-number">0</span>, gt_id] = <span class="hljs-number">1</span><br>            matched_det_id = np.where(local_sigma_table[gt_id, :] &gt; tr)<br>            det_flag[<span class="hljs-number">0</span>, matched_det_id] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, gt_flag, det_flag<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码定义了一个名为 <code>one_to_one</code> 的函数，它接受多个参数，包括 <code>local_sigma_table</code>、<code>local_tau_table</code>、<code>local_accumulative_recall</code>、<code>local_accumulative_precision</code>、<code>global_accumulative_recall</code>、<code>global_accumulative_precision</code>、<code>gt_flag</code> 和 <code>det_flag</code>。</p>
<p>函数中的 <code>for</code> 循环遍历从 0 到 <code>num_gt</code> 的每个 <code>gt_id</code>，其中 <code>num_gt</code> 是标注数据的数量。</p>
<p>在循环内部，首先使用 <code>np.where</code> 函数找到满足条件 <code>local_sigma_table[gt_id, :] &gt; tr</code> 的索引，然后计算满足条件的索引数量，并分别保存在 <code>gt_matching_num_qualified_sigma_candidates</code> 和 <code>gt_matching_qualified_tau_candidates</code> 变量中。</p>
<p>接着，再次使用 <code>np.where</code> 函数找到与上述条件对应的检测结果的索引，并计算满足条件的索引数量，分别保存在 <code>det_matching_num_qualified_sigma_candidates</code> 和 <code>det_matching_num_qualified_tau_candidates</code> 变量中。</p>
<p>之后，通过一系列的条件判断，检查是否满足&quot;一对一&quot;匹配的条件，即只有一个满足重叠度阈值要求的标注和一个满足重叠度阈值要求的检测结果。如果满足这些条件，则更新相关计数变量，并将相应的标志位设置为1。</p>
<p>最后，函数返回更新后的 <code>local_accumulative_recall</code>、<code>local_accumulative_precision</code>、<code>global_accumulative_recall</code>、<code>global_accumulative_precision</code>、<code>gt_flag</code> 和 <code>det_flag</code>。</p>
</blockquote>
<ul>
<li><code>one_to_many()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">one_to_many</span>(<span class="hljs-params">local_sigma_table, local_tau_table, local_accumulative_recall,</span><br><span class="hljs-params">               local_accumulative_precision, global_accumulative_recall, global_accumulative_precision,</span><br><span class="hljs-params">               gt_flag, det_flag</span>):<br>    <span class="hljs-keyword">for</span> gt_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gt):<br>        <span class="hljs-comment">#skip the following if the groundtruth was matched</span><br>        <span class="hljs-keyword">if</span> gt_flag[<span class="hljs-number">0</span>, gt_id] &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">continue</span><br><br>        non_zero_in_sigma = np.where(local_sigma_table[gt_id, :] &gt; <span class="hljs-number">0</span>)<br>        num_non_zero_in_sigma = non_zero_in_sigma[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-keyword">if</span> num_non_zero_in_sigma &gt;= k:<br>            <span class="hljs-comment">####search for all detections that overlaps with this groundtruth</span><br>            qualified_tau_candidates = np.where((local_tau_table[gt_id, :] &gt;= tp) &amp; (det_flag[<span class="hljs-number">0</span>, :] == <span class="hljs-number">0</span>))<br>            num_qualified_tau_candidates = qualified_tau_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>            <span class="hljs-keyword">if</span> num_qualified_tau_candidates == <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">if</span> ((local_tau_table[gt_id, qualified_tau_candidates] &gt;= tp) <span class="hljs-keyword">and</span> (local_sigma_table[gt_id, qualified_tau_candidates] &gt;= tr)):<br>                    <span class="hljs-comment">#became an one-to-one case</span><br>                    global_accumulative_recall = global_accumulative_recall + <span class="hljs-number">1.0</span><br>                    global_accumulative_precision = global_accumulative_precision + <span class="hljs-number">1.0</span><br>                    local_accumulative_recall = local_accumulative_recall + <span class="hljs-number">1.0</span><br>                    local_accumulative_precision = local_accumulative_precision + <span class="hljs-number">1.0</span><br><br>                    gt_flag[<span class="hljs-number">0</span>, gt_id] = <span class="hljs-number">1</span><br>                    det_flag[<span class="hljs-number">0</span>, qualified_tau_candidates] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> (np.<span class="hljs-built_in">sum</span>(local_sigma_table[gt_id, qualified_tau_candidates]) &gt;= tr):<br>                gt_flag[<span class="hljs-number">0</span>, gt_id] = <span class="hljs-number">1</span><br>                det_flag[<span class="hljs-number">0</span>, qualified_tau_candidates] = <span class="hljs-number">1</span><br><br>                global_accumulative_recall = global_accumulative_recall + fsc_k<br>                global_accumulative_precision = global_accumulative_precision + num_qualified_tau_candidates * fsc_k<br><br>                local_accumulative_recall = local_accumulative_recall + fsc_k<br>                local_accumulative_precision = local_accumulative_precision + num_qualified_tau_candidates * fsc_k<br><br>    <span class="hljs-keyword">return</span> local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, gt_flag, det_flag<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码定义了一个名为 <code>one_to_many</code> 的函数，它与之前的 <code>one_to_one</code> 函数类似，接受相同的参数。</p>
<p>函数中的 <code>for</code> 循环遍历从 0 到 <code>num_gt</code> 的每个 <code>gt_id</code>，其中 <code>num_gt</code> 是标注数据的数量。</p>
<p>在循环内部，首先检查是否已经匹配过该标注数据，如果 <code>gt_flag[0, gt_id] </code>大于 0，则表示已进行匹配，直接跳过后续操作。</p>
<p>接下来，使用 <code>np.where</code> 函数找到满足条件 <code>local_sigma_table[gt_id, :] &gt; 0</code> 的索引，并计算满足条件的索引数量，保存在 <code>num_non_zero_in_sigma</code> 变量中。</p>
<p>然后，如果满足条件 <code>num_non_zero_in_sigma &gt;= k</code>，进入下一步操作。</p>
<p>在下一步操作中，通过<code>np.where</code>函数找到满足条件 <code>(local_tau_table[gt_id, :] &gt;= tp) &amp; (det_flag[0, :] == 0)</code> 的索引，并计算满足条件的索引数量，保存在 <code>num_qualified_tau_candidates</code> 变量中。</p>
<p>接着，判断 <code>num_qualified_tau_candidates</code> 的值，如果为 1，则进一步判断该标注和对应的检测结果是否满足&quot;一对一&quot;匹配的条件，即重叠度要求同时满足。如果满足条件，则更新相关计数变量，并将相应的标志位设置为1。</p>
<p>如果 <code>num_qualified_tau_candidates</code> 的值大于 1，并且满足条件 <code>np.sum(local_sigma_table[gt_id, qualified_tau_candidates]) &gt;= tr</code>，则将相关计数变量更新，并将标志位设置为 1。</p>
<p>最后，函数返回更新后的 <code>local_accumulative_recall</code>、<code>local_accumulative_precision</code>、<code>global_accumulative_recall</code>、<code>global_accumulative_precision</code>、<code>gt_flag</code> 和 <code>det_flag</code>。</p>
</blockquote>
<ul>
<li><code>many_to_one()</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">many_to_one</span>(<span class="hljs-params">local_sigma_table, local_tau_table, local_accumulative_recall,</span><br><span class="hljs-params">               local_accumulative_precision, global_accumulative_recall, global_accumulative_precision,</span><br><span class="hljs-params">               gt_flag, det_flag</span>):<br>    <span class="hljs-keyword">for</span> det_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_det):<br>        <span class="hljs-comment"># skip the following if the detection was matched</span><br>        <span class="hljs-keyword">if</span> det_flag[<span class="hljs-number">0</span>, det_id] &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">continue</span><br><br>        non_zero_in_tau = np.where(local_tau_table[:, det_id] &gt; <span class="hljs-number">0</span>)<br>        num_non_zero_in_tau = non_zero_in_tau[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-keyword">if</span> num_non_zero_in_tau &gt;= k:<br>            <span class="hljs-comment">####search for all detections that overlaps with this groundtruth</span><br>            qualified_sigma_candidates = np.where((local_sigma_table[:, det_id] &gt;= tp) &amp; (gt_flag[<span class="hljs-number">0</span>, :] == <span class="hljs-number">0</span>))<br>            num_qualified_sigma_candidates = qualified_sigma_candidates[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]<br><br>            <span class="hljs-keyword">if</span> num_qualified_sigma_candidates == <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">if</span> ((local_tau_table[qualified_sigma_candidates, det_id] &gt;= tp) <span class="hljs-keyword">and</span> (local_sigma_table[qualified_sigma_candidates, det_id] &gt;= tr)):<br>                    <span class="hljs-comment">#became an one-to-one case</span><br>                    global_accumulative_recall = global_accumulative_recall + <span class="hljs-number">1.0</span><br>                    global_accumulative_precision = global_accumulative_precision + <span class="hljs-number">1.0</span><br>                    local_accumulative_recall = local_accumulative_recall + <span class="hljs-number">1.0</span><br>                    local_accumulative_precision = local_accumulative_precision + <span class="hljs-number">1.0</span><br><br>                    gt_flag[<span class="hljs-number">0</span>, qualified_sigma_candidates] = <span class="hljs-number">1</span><br>                    det_flag[<span class="hljs-number">0</span>, det_id] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> (np.<span class="hljs-built_in">sum</span>(local_tau_table[qualified_sigma_candidates, det_id]) &gt;= tp):<br>                det_flag[<span class="hljs-number">0</span>, det_id] = <span class="hljs-number">1</span><br>                gt_flag[<span class="hljs-number">0</span>, qualified_sigma_candidates] = <span class="hljs-number">1</span><br><br>                global_accumulative_recall = global_accumulative_recall + num_qualified_sigma_candidates * fsc_k<br>                global_accumulative_precision = global_accumulative_precision + fsc_k<br><br>                local_accumulative_recall = local_accumulative_recall + num_qualified_sigma_candidates * fsc_k<br>                local_accumulative_precision = local_accumulative_precision + fsc_k<br>    <span class="hljs-keyword">return</span> local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, gt_flag, det_flag<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码定义了一个名为 <code>many_to_one</code> 的函数，与之前的 <code>one_to_one</code> 和 <code>one_to_many</code> 函数类似，接受相同的参数。</p>
<p>函数中的 <code>for</code> 循环遍历从 0 到 <code>num_det</code> 的每个 <code>det_id</code>，其中 <code>num_det</code> 是检测结果的数量。</p>
<p>在循环内部，首先检查是否已经匹配过该检测结果，如果 <code>det_flag[0, det_id]</code> 大于 0，则表示已进行匹配，直接跳过后续操作。</p>
<p>接下来，使用 <code>np.where </code>函数找到满足条件 <code>local_tau_table[:, det_id] &gt; 0</code> 的索引，并计算满足条件的索引数量，保存在 <code>num_non_zero_in_tau </code>变量中。</p>
<p>然后，如果满足条件 <code>num_non_zero_in_tau &gt;= k</code>，进入下一步操作。</p>
<p>在下一步操作中，通过 <code>np.where</code> 函数找到满足条件 <code>(local_sigma_table[:, det_id] &gt;= tp) &amp; (gt_flag[0, :] == 0)</code> 的索引，并计算满足条件的索引数量，保存在 <code>num_qualified_sigma_candidates</code> 变量中。</p>
<p>接着，判断 <code>num_qualified_sigma_candidates</code> 的值，如果为 1，则进一步判断该检测结果和对应的标注数据是否满足&quot;一对一&quot;匹配的条件，即重叠度和重合度要求同时满足。如果满足条件，则更新相关计数变量，并将相应的标志位设置为 1。</p>
<p>如果 <code>num_qualified_sigma_candidates</code> 的值大于 1，并且满足条件 <code>np.sum(local_tau_table[qualified_sigma_candidates, det_id]) &gt;= tp</code>，则将相关计数变量更新，并将标志位设置为 1。</p>
<p>最后，函数返回更新后的 <code>local_accumulative_recall</code>、<code>local_accumulative_precision</code>、<code>global_accumulative_recall</code>、<code>global_accumulative_precision</code>、<code>gt_flag</code> 和 <code>det_flag</code>。</p>
</blockquote>
<ul>
<li>保存结果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(global_sigma)):<br>    <span class="hljs-built_in">print</span>(allInputs[idx])<br>    local_sigma_table = global_sigma[idx]<br>    local_tau_table = global_tau[idx]<br><br>    num_gt = local_sigma_table.shape[<span class="hljs-number">0</span>]<br>    num_det = local_sigma_table.shape[<span class="hljs-number">1</span>]<br><br>    total_num_gt = total_num_gt + num_gt<br>    total_num_det = total_num_det + num_det<br><br>    local_accumulative_recall = <span class="hljs-number">0</span><br>    local_accumulative_precision = <span class="hljs-number">0</span><br>    gt_flag = np.zeros((<span class="hljs-number">1</span>, num_gt))<br>    det_flag = np.zeros((<span class="hljs-number">1</span>, num_det))<br><br>    <span class="hljs-comment">#######first check for one-to-one case##########</span><br>    local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, \<br>    gt_flag, det_flag = one_to_one(local_sigma_table, local_tau_table,<br>                                  local_accumulative_recall, local_accumulative_precision,<br>                                  global_accumulative_recall, global_accumulative_precision,<br>                                  gt_flag, det_flag)<br><br>    <span class="hljs-comment">#######then check for one-to-many case##########</span><br>    local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, \<br>    gt_flag, det_flag = one_to_many(local_sigma_table, local_tau_table,<br>                                   local_accumulative_recall, local_accumulative_precision,<br>                                   global_accumulative_recall, global_accumulative_precision,<br>                                   gt_flag, det_flag)<br><br>    <span class="hljs-comment">#######then check for many-to-one case##########</span><br>    local_accumulative_recall, local_accumulative_precision, global_accumulative_recall, global_accumulative_precision, \<br>    gt_flag, det_flag = many_to_one(local_sigma_table, local_tau_table,<br>                                    local_accumulative_recall, local_accumulative_precision,<br>                                    global_accumulative_recall, global_accumulative_precision,<br>                                    gt_flag, det_flag)<br><br><br><br><br>    fid = <span class="hljs-built_in">open</span>(fid_path, <span class="hljs-string">&#x27;a+&#x27;</span>)<br>    <span class="hljs-keyword">try</span>:<br>        local_precision = local_accumulative_precision / num_det<br>    excerpt ZeroDivisionError:<br>        local_precision = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">try</span>:<br>        local_recall = local_accumulative_recall / num_gt<br>    excerpt ZeroDivisionError:<br>        local_recall = <span class="hljs-number">0</span><br><br>    temp = (<span class="hljs-string">&#x27;%s______/Precision:_%s_______/Recall:_%s\n&#x27;</span> % (allInputs[idx], <span class="hljs-built_in">str</span>(local_precision), <span class="hljs-built_in">str</span>(local_recall)))<br>    fid.write(temp)<br>    fid.close()<br><span class="hljs-keyword">try</span>:<br>    recall = global_accumulative_recall / total_num_gt<br>excerpt ZeroDivisionError:<br>    recall = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">try</span>:<br>    precision = global_accumulative_precision / total_num_det<br>excerpt ZeroDivisionError:<br>    precision = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">try</span>:<br>    f_score = <span class="hljs-number">2</span>*precision*recall/(precision+recall)<br>excerpt ZeroDivisionError:<br>    f_score = <span class="hljs-number">0</span><br><br>fid = <span class="hljs-built_in">open</span>(fid_path, <span class="hljs-string">&#x27;a&#x27;</span>)<br>temp = (<span class="hljs-string">&#x27;Precision:_%s_______/Recall:_%s\n&#x27;</span> %(<span class="hljs-built_in">str</span>(precision), <span class="hljs-built_in">str</span>(recall)))<br>fid.write(temp)<br>fid.close()<br><span class="hljs-built_in">print</span>(temp)<br></code></pre></td></tr></table></figure>
<blockquote>
<p>这段代码是一个循环，循环遍历 <code>global_sigma</code> 列表中的每个元素。</p>
<p>在每次循环中，首先打印 <code>allInputs[idx]</code> 的值，然后将 <code>global_sigma[idx]</code> 赋值给 <code>local_sigma_table</code>，将 <code>global_tau[idx] </code>赋值给 <code>local_tau_table</code>。</p>
<p>接下来，计算 <code>local_sigma_table </code>的形状，并将结果分别赋值给 <code>num_gt</code> 和 <code>num_det</code>。</p>
<p>然后，将 <code>num_gt</code> 和 <code>num_det</code> 加到累计变量 <code>total_num_gt</code> 和 <code>total_num_det</code> 上。</p>
<p>接着，初始化一些变量，包括 <code>local_accumulative_recall</code>、<code>local_accumulative_precision</code>、<code>gt_flag</code> 和 <code>det_flag</code>。</p>
<p>然后，依次调用 <code>one_to_one</code>、<code>one_to_many</code> 和 <code>many_to_one</code> 函数，对 <code>local_sigma_table</code> 和 <code>local_tau_table</code> 进行匹配计算，并更新相关计数变量和标志位。</p>
<p>接下来，打开一个文件，并将 <code>local_accumulative_precision</code> 和 <code>local_precision</code> 计算结果写入文件。</p>
</blockquote>
<h3 id="pascal-voc" tabindex="-1" id="Pascal-VOC">Pascal VOC</h3>
<p>​    传统的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span> 阈值。</p>
<hr>
<p>​    提供了两种语言：Matlab 和 Python，只有 Matlab 的有示例……Python 的没有，绝</p>
<p><img src="CE1.png" alt="png"></p>
<h2 id="groundtruth" tabindex="-1" id="Groundtruth">Groundtruth</h2>
<p>​    可提供的 GT：</p>
<ul>
<li>
<p>Pixel 级</p>
<ul>
<li>
<p>Character Level Mask</p>
<ul>
<li>The pixel level groundtruth of Total-Text dataset can be downloaded at <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1w25smwrft7QKhDvK3CuFmdwSLraSKbEn/view?usp=sharing">this https URL</a> (80Mb).</li>
</ul>
<p><img src="pixel.gif" alt="gif"></p>
</li>
<li>
<p>Text Region Mask</p>
<ul>
<li>The text region mask groundtruth of Total-Text dataset can be downloaded at <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1WgQh6D3HlDobpinmtTCSyNFuk-tUttAz/view?usp=sharing">this https URL</a> (6Mb).</li>
</ul>
<p><img src="textregion.gif" alt="gif"></p>
</li>
</ul>
</li>
<li>
<p>Text 级</p>
<p><img src="polygon.png" alt="png"></p>
<ul>
<li>txt 格式 <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1v-pd-74EkZ3dWe6k0qppRtetjdPQ3ms1/view?usp=sharing">this https URL</a></li>
<li>mat 格式 <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/19quCaJGePvTc3yPZ7MAGNijjKfy77-ke/view?usp=sharing">this https URL</a>，Can be load with Matlab, scipy.io.loadmat, etc…</li>
</ul>
</li>
</ul>
<h1 id="%E8%AE%A1%E5%88%92%EF%BC%88%E5%AF%84%EF%BC%89" tabindex="-1">计划（寄）</h1>
<p>​    复现一下 <a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/scene-text-detection-on-total-text">Total-Text Benchmark (Scene Text Detection) | Papers With Code</a> 和 <a target="_blank" rel="noopener" href="https://github.com/cs-chan/Total-Text-Dataset">cs-chan/Total-Text-Dataset: Total Text Dataset. It consists of 1555 images with more than 3 different text orientations: Horizontal, Multi-Oriented, and Curved, one of a kind. (github.com)</a> 里的代码。</p>
<p>​    真是太难复现了我日。</p>
<p>​    尝试过的/打算尝试的：</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>F-Measure</th>
<th>Precision</th>
<th>Recall</th>
<th>Paper</th>
<th>GitHub</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>CentripetalText</td>
<td>87.85%</td>
<td>90.67</td>
<td>85.19</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/centripetaltext-an-efficient-text-instance">CentripetalText: An Efficient Text Instance Representation for Scene Text Detection Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/shengtao96/centripetaltext">shengtao96/CentripetalText (github.com)</a></td>
<td>默认的 Total-Text 形式</td>
</tr>
<tr>
<td>FCE</td>
<td>89.3</td>
<td>82.5</td>
<td>85.8</td>
<td><a target="_blank" rel="noopener" href="https://github.com/gxym/textbpn-plus-plus">GXYM/TextBPN-Plus-Plus: Arbitrary Shape Text Detection via Boundary Transformer；The paper at: https://arxiv.org/abs/2205.05320, which has been accepted by IEEE Transactions on Multimedia (T-MM 2023). (github.com)</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/gxym/textbpn-plus-plus">GXYM/TextBPN-Plus-Plus: Arbitrary Shape Text Detection via Boundary Transformer；The paper at: https://arxiv.org/abs/2205.05320, which has been accepted by IEEE Transactions on Multimedia (T-MM 2023). (github.com)</a></td>
<td>默认的 Total-Text 形式</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/dptext-detr-towards-better-scene-text">DPText-DETR<br/>(ResNet-50)</a></td>
<td>87.3%</td>
<td>82.1</td>
<td>93.1</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2211.10772">[2211.10772] DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting (arxiv.org)</a></td>
<td>[ViTAE-Transformer/DeepSolo: The official repo for <a target="_blank" rel="noopener" href="https://github.com/vitae-transformer/deepsolo">CVPR’23] “DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting” &amp; [ArXiv’23] “DeepSolo++: Let Transformer Decoder with Explicit Points Solo for Text Spotting” (github.com)</a></td>
<td>Total-Text 的形式不同于默认形式（复杂的 json 文件）</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/fast-searching-for-a-faster-arbitrarily">FAST-B-800</a></td>
<td>87.5%</td>
<td>90.0</td>
<td>85.2</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.02394v2">[2111.02394v2] FAST: Faster Arbitrarily-Shaped Text Detector with Minimalist Kernel Representation (arxiv.org)</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/czczup/FAST">czczup/FAST: Faster Arbitrarily-Shaped Text Detector with Minimalist Kernel Representation (github.com)</a></td>
<td><code>sh ./compile.sh</code> 编译失败，<font color="red"><strong>寄！</strong></font></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/textfusenet-scene-text-detection-with-richer">TextFuseNet<br/>(ResNeXt-101)</a></td>
<td>87.5%</td>
<td>89.2</td>
<td>85.8</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/textfusenet-scene-text-detection-with-richer">TextFuseNet: Scene Text Detection with Richer Fused Features Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/ying09/TextFuseNet">ying09/TextFuseNet: A PyTorch implementation of “TextFuseNet: Scene Text Detection with Richer Fused Features”. (github.com)</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/i3cl-intra-and-inter-instance-collaborative">I3CL + SSL<br/>(ResNet-50)</a></td>
<td>86.9%</td>
<td>89.8</td>
<td>84.2</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/i3cl-intra-and-inter-instance-collaborative">I3CL + SSL<br/>(ResNet-50)</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/ViTAE-Transformer/I3CL">ViTAE-Transformer/I3CL: The official repo for [IJCV’22] “I3CL: Intra- and Inter-Instance Collaborative Learning for Arbitrary-shaped Scene Text Detection” (github.com)</a></td>
<td>仓库里好像没有适配 Total-Text 的</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/convolutional-character-networks">CharNet H-88 (multi-scale)</a></td>
<td>86.5%</td>
<td>88</td>
<td>85</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/convolutional-character-networks#code">Convolutional Character Networks  Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/msight-tech/research-charnet">msight-tech/research-charnet: CharNet: Convolutional Character Networks (github.com)</a></td>
<td>仓库里好像没有适配 Total-Text 的，只有 ICDAR2015</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/real-time-scene-text-detection-with-1">DBNet++<br/>(ResNet-50)</a></td>
<td>86%</td>
<td>88.9</td>
<td>83.2</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/real-time-scene-text-detection-with-1">Real-Time Scene Text Detection with Differentiable Binarization and Adaptive Scale Fusion Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/MhLiao/DB">MhLiao/DB: A PyTorch implementation of “Real-time Scene Text Detection with Differentiable Binarization”. (github.com)</a></td>
<td>Total-Text 的形式不同于默认形式（较易懂的 txt 形式）</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/efficient-and-accurate-arbitrary-shaped-text">PAN-640</a></td>
<td>85%</td>
<td>89.3</td>
<td>81</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/efficient-and-accurate-arbitrary-shaped-text">Efficient and Accurate Arbitrary-Shaped Text Detection with Pixel Aggregation Network Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/WenmuZhou/PAN.pytorch">WenmuZhou/PAN.pytorch: A unofficial pytorch implementation of PAN(PSENet2): Efficient and Accurate Arbitrary-Shaped Text Detection with Pixel Aggregation Network (github.com)</a></td>
<td>仓库里好像没有适配 Total-Text 的，只有 ICDAR2015</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/real-time-scene-text-detection-with">DB-ResNet-50 (800)</a></td>
<td>84.7%</td>
<td></td>
<td></td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/real-time-scene-text-detection-with">Real-time Scene Text Detection with Differentiable Binarization Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/MhLiao/DB">MhLiao/DB: A PyTorch implementation of “Real-time Scene Text Detection with Differentiable Binarization”. (github.com)</a></td>
<td>Total-Text 的形式不同于默认形式（较易懂的 txt 形式）</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/character-region-awareness-for-text-detection">CRAFT</a></td>
<td>83.6%</td>
<td>87.6</td>
<td>79.9</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/character-region-awareness-for-text-detection">Character Region Awareness for Text Detection Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/clovaai/CRAFT-pytorch">clovaai/CRAFT-pytorch: Official implementation of Character Region Awareness for Text Detection (CRAFT) (github.com)</a></td>
<td>仓库里好像没有适配 Total-Text 的</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/textsnake-a-flexible-representation-for">TextSnake</a></td>
<td>78.4%</td>
<td>82.7</td>
<td>74.5</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/textsnake-a-flexible-representation-for">TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes Papers With Code</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/princewang1994/TextSnake.pytorch">princewang1994/TextSnake.pytorch: A PyTorch implementation of ECCV2018 Paper: TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes (github.com)</a></td>
<td>Total-Text 的形式不同于默认形式</td>
</tr>
</tbody>
</table>
<h1 id="%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E9%9B%86" tabindex="-1">可视化数据集</h1>
<p>​    根据数据集的<strong>源图像</strong>以及它的 <strong>txt 标注</strong>格式，再一阵 ChatGPT 和一阵操作，写一个可视化代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>index = <span class="hljs-number">396</span><br><br>image_dir = <span class="hljs-string">r&#x27;E:\dataset\TotalText\Images\Test\\&#x27;</span><br>label_dir = <span class="hljs-string">r&#x27;E:\dataset\TotalText\GroundTruth\Text\Test\\&#x27;</span><br><br>image_path = os.path.join(image_dir, <span class="hljs-string">&#x27;img&#x27;</span> + <span class="hljs-built_in">str</span>(index) + <span class="hljs-string">&#x27;.jpg&#x27;</span>)<br>label_path = os.path.join(label_dir, <span class="hljs-string">&#x27;poly_gt_img&#x27;</span> + <span class="hljs-built_in">str</span>(index) + <span class="hljs-string">&#x27;.txt&#x27;</span>)<br><br>image_origin = cv2.imread(image_path)<br>image = image_origin.copy()<br>height, width, _ = image.shape<br>label_file = <span class="hljs-built_in">open</span>(label_path, <span class="hljs-string">&#x27;r&#x27;</span>)<br>annotations = label_file.readlines()<br>label_file.close()<br><br><span class="hljs-keyword">for</span> annotation <span class="hljs-keyword">in</span> annotations:<br>    x = [<span class="hljs-built_in">int</span>(num) <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> annotation[annotation.find(<span class="hljs-string">&quot;x: [[&quot;</span>) + <span class="hljs-number">5</span>: annotation.find(<span class="hljs-string">&quot;]], y: [[&quot;</span>)].split()]<br>    y = [<span class="hljs-built_in">int</span>(num) <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> annotation[annotation.find(<span class="hljs-string">&quot;y: [[&quot;</span>) + <span class="hljs-number">5</span>: annotation.find(<span class="hljs-string">&quot;]], ornt: [&quot;</span>)].split()]<br>    ornt = annotation[annotation.find(<span class="hljs-string">&quot;ornt: [u&#x27;&quot;</span>) + <span class="hljs-number">9</span>: annotation.find(<span class="hljs-string">&quot;&#x27;], transcriptions: [&quot;</span>)]<br>    transcriptions = annotation[annotation.find(<span class="hljs-string">&quot;transcriptions: [u&#x27;&quot;</span>) + <span class="hljs-number">19</span>: -<span class="hljs-number">3</span>]<br>    <br>    points = np.array([x, y], np.int32).T<br>    <br>    cv2.polylines(image, [points], isClosed=<span class="hljs-literal">True</span>, color=(<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), thickness=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> points:<br>        cv2.circle(image, (p[<span class="hljs-number">0</span>], p[<span class="hljs-number">1</span>]), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">150</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>), -<span class="hljs-number">1</span>)<br><br>    cv2.putText(image, ornt, (x[<span class="hljs-number">0</span>], y[<span class="hljs-number">0</span>] + <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">50</span>)), cv2.FONT_HERSHEY_SIMPLEX,<br>                <span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">1000</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">500</span>))<br>    cv2.putText(image, transcriptions, (x[<span class="hljs-number">0</span>], y[<span class="hljs-number">0</span>] - <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">150</span>)), cv2.FONT_HERSHEY_SIMPLEX,<br>                <span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">1000</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-built_in">int</span>(<span class="hljs-built_in">min</span>(height, width) / <span class="hljs-number">500</span>))<br>    <br>fig, axes = plt.subplots(nrows=<span class="hljs-number">1</span>, ncols=<span class="hljs-number">2</span>, figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">9</span>))<br>axes = axes.flatten()<br><br>axes[<span class="hljs-number">0</span>].imshow(cv2.cvtColor(image_origin, cv2.COLOR_BGR2RGB))<br>axes[<span class="hljs-number">0</span>].axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">&#x27;Origin&#x27;</span>)<br><br>axes[<span class="hljs-number">1</span>].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br>axes[<span class="hljs-number">1</span>].axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>axes[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">&#x27;Annotation&#x27;</span>)<br><br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="Vis.png" alt="png"></p>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/Server-MindOCR/">
                        上一篇：Server-MindOCR
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/Diary-%E6%9A%91%E5%81%87%EF%BC%81/">
                        下一篇：Diary-暑假！
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">120</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">435</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	
		
			
				<link rel="stylesheet" href="/css/plugins/katex/katex.min.css">
				<script src="/js/plugins/copy-tex.js"></script>
			
		
	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

