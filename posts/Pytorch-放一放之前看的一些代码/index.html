<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Pytorch-放一放之前看的一些代码 | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="Python,Pytorch,李宏毅,">
<meta name="description" content="李宏毅《机器学习 2022》的作业代码。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/Python"><span>Python</span></a></li>
						
							<li><a href="/tags/Pytorch"><span>Pytorch</span></a></li>
						
							<li><a href="/tags/李宏毅"><span>李宏毅</span></a></li>
						
					
				</ul>
				
				<h1>Pytorch-放一放之前看的一些代码</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>李宏毅《机器学习 2022》的作业代码。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2023/05/20 20:54:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="homework-1%3A-covid-19-cases-prediction-(regression)" tabindex="-1"><strong>Homework 1: COVID-19 Cases Prediction (Regression)</strong></h1>
<p>Objectives:</p>
<ul>
<li>Solve a regression problem with deep neural networks (DNN).
<ul>
<li>用 DNN 解决回归问题</li>
</ul>
</li>
<li>Understand basic DNN training tips.
<ul>
<li>了解 DNN 的训练技巧</li>
</ul>
</li>
<li>Familiarize yourself with PyTorch.
<ul>
<li>熟悉 Pytorch</li>
</ul>
</li>
</ul>
<p>If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to <a href="mailto:mlta-2023-spring@googlegroups.com">mlta-2023-spring@googlegroups.com</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># check gpu type</span><br>!nvidia-smi<br></code></pre></td></tr></table></figure>
<pre><code>Tue May  2 06:43:11 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   60C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre>
<h1 id="download-data" tabindex="-1">Download data</h1>
<p>If the Google Drive links below do not work, you can use the dropbox link below or download data from <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/ml2023spring-hw1/overview">Kaggle</a>, and upload data manually to the workspace.</p>
<p>如果下面的 Google Drive 链接不起作用，您可以使用下面的 dropbox 链接或从 Kaggle 下载数据，然后手动将数据上传到工作区。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># google drive link</span><br><span class="hljs-comment"># !gdown --id &#x27;1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-&#x27; --output covid_train.csv</span><br><span class="hljs-comment"># !gdown --id &#x27;1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1&#x27; --output covid_test.csv</span><br><br><span class="hljs-comment"># dropbox link</span><br>!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=<span class="hljs-number">0</span><br>!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<pre><code>--2023-05-02 06:43:11--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0
Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112
Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: /s/raw/lmy1riadzoy0ahw/covid.train.csv [following]
--2023-05-02 06:43:11--  https://www.dropbox.com/s/raw/lmy1riadzoy0ahw/covid.train.csv
Reusing existing connection to www.dropbox.com:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com/cd/0/inline/B7R_XAdqGQ7y45IwWWr91JE9O5ftQ1LzcdRGRkGnWhDV7CbEgZ1gwBymu8fh5bpaPWp9zICKowq6MjrON0BR4nSmqUicNGD370j62Mq2GXwtl0e-8qpV5Oi-x6JOi1bcQMGLMbska_B9vEIgQgpg2S6ny5XiLPOameEMqLg9dA_Eog/file# [following]
--2023-05-02 06:43:11--  https://uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com/cd/0/inline/B7R_XAdqGQ7y45IwWWr91JE9O5ftQ1LzcdRGRkGnWhDV7CbEgZ1gwBymu8fh5bpaPWp9zICKowq6MjrON0BR4nSmqUicNGD370j62Mq2GXwtl0e-8qpV5Oi-x6JOi1bcQMGLMbska_B9vEIgQgpg2S6ny5XiLPOameEMqLg9dA_Eog/file
Resolving uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com (uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f
Connecting to uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com (uc5421dd31d98edf16e9af0f0b3d.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2162766 (2.1M) [text/plain]
Saving to: ‘covid_train.csv’

covid_train.csv     100%[===================&gt;]   2.06M  4.86MB/s    in 0.4s    

2023-05-02 06:43:12 (4.86 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]

--2023-05-02 06:43:13--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0
Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112
Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: /s/raw/zalbw42lu4nmhr2/covid.test.csv [following]
--2023-05-02 06:43:13--  https://www.dropbox.com/s/raw/zalbw42lu4nmhr2/covid.test.csv
Reusing existing connection to www.dropbox.com:443.
HTTP request sent, awaiting response... 302 Found
Location: https://uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com/cd/0/inline/B7T1uyyfVM4P3twEWZx3H4-pVXJ-c4Y5vMd0jVufeZ8aideA5_Zpgz2vdLvJjQsnLRbk7gffgKO4b2TWtNHYcAbfYb4YLQNQd7oa3etDtxXpWd1xxwoSg_emm6WNprlrzqzAFbQVh448Xp2PGEai1MO7BatFrLvH4to5CoOCRBs9Zg/file# [following]
--2023-05-02 06:43:13--  https://uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com/cd/0/inline/B7T1uyyfVM4P3twEWZx3H4-pVXJ-c4Y5vMd0jVufeZ8aideA5_Zpgz2vdLvJjQsnLRbk7gffgKO4b2TWtNHYcAbfYb4YLQNQd7oa3etDtxXpWd1xxwoSg_emm6WNprlrzqzAFbQVh448Xp2PGEai1MO7BatFrLvH4to5CoOCRBs9Zg/file
Resolving uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com (uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f
Connecting to uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com (uc77577a7cac975663cf90524f71.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 638359 (623K) [text/plain]
Saving to: ‘covid_test.csv’

covid_test.csv      100%[===================&gt;] 623.40K  --.-KB/s    in 0.04s   

2023-05-02 06:43:14 (16.9 MB/s) - ‘covid_test.csv’ saved [638359/638359]
</code></pre>
<p>​</p>
<h1 id="import-packages" tabindex="-1">Import packages</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Numerical Operations 数值运算</span><br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Reading/Writing Data 读写数据</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> csv<br><br><span class="hljs-comment"># For Progress Bar 进度条</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># Pytorch</span><br><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader, random_split<br><br><span class="hljs-comment"># For plotting learning curve 绘制损失函数曲线</span><br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br></code></pre></td></tr></table></figure>
<h1 id="some-utility-functions" tabindex="-1">Some Utility Functions</h1>
<p>一些实用程序函数</p>
<p>You do not need to modify this part.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">same_seed</span>(<span class="hljs-params">seed</span>): <br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Fixes random number generator seeds for reproducibility.</span><br><span class="hljs-string">    固定随机数种子以获得可复现性。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 将 CuDNN 的随机性设置为确定性模式，这是为了确保每次运行时 CuDNN 生成的随机数列是一样的。</span><br>    torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span>  <span class="hljs-comment"># 禁用 CuDNN 的自动调整功能，避免出现由于 CuDNN 自动调整导致的运行时间不稳定的情况。</span><br>    np.random.seed(seed)  <span class="hljs-comment"># 设置 NumPy 库的随机数种子，如果程序中有使用到 NumPy 生成的随机数，也可以保证其生成的随机数序列是一致的。</span><br>    torch.manual_seed(seed)  <span class="hljs-comment"># 设置 PyTorch 的 CPU 随机数种子。</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():  <span class="hljs-comment"># 如果 GPU 可用，则设置 PyTorch 的 GPU 随机数种子。</span><br>        torch.cuda.manual_seed_all(seed)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_valid_split</span>(<span class="hljs-params">data_set, valid_ratio, seed</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Split provided training data into training set and validation set</span><br><span class="hljs-string">    将提供的训练数据拆分为训练集和验证集</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    valid_set_size = <span class="hljs-built_in">int</span>(valid_ratio * <span class="hljs-built_in">len</span>(data_set))  <span class="hljs-comment"># 根据验证集所占比例和数据集的大小，计算出验证集的大小</span><br>    train_set_size = <span class="hljs-built_in">len</span>(data_set) - valid_set_size  <span class="hljs-comment"># 通过数据集的总大小和验证集的大小计算出训练集的大小</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    使用 random_split 函数将 data_set 随机划分为训练集和验证集，</span><br><span class="hljs-string">    具体来说，</span><br><span class="hljs-string">    函数的第一个参数是要划分的数据集，</span><br><span class="hljs-string">    第二个参数是一个列表，表示训练集和验证集的大小，列表的元素按照训练集和验证集的顺序排列，</span><br><span class="hljs-string">    第三个参数是用于生成随机数的生成器，需要手动设置随机数种子</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))<br>    <span class="hljs-keyword">return</span> np.array(train_set), np.array(valid_set)  <span class="hljs-comment"># 将训练集和验证集转换为 NumPy 数组格式，并返回</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">test_loader, model, device</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    用于在给定的测试集上使用已训练好的神经网络模型进行预测并返回预测结果。</span><br><span class="hljs-string">    test_loader：一个 PyTorch 的 DataLoader 对象，用于逐批次地加载测试数据；</span><br><span class="hljs-string">    model：一个已训练好的神经网络模型；</span><br><span class="hljs-string">    device：指定计算设备，如&quot;cpu&quot;或者&quot;cuda&quot;。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># Set your model to evaluation mode. 函数调用 model.eval()将模型设置为评估模式（即在推断过程中不会进行梯度计算，以加速运行）</span><br>    preds = []  <span class="hljs-comment"># 定义一个空列表 preds 用于存储每个批次的预测结果。</span><br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tqdm(test_loader):  <span class="hljs-comment"># 通过一个循环来逐批次地遍历 test_loader 中的测试数据</span><br>        x = x.to(device)  <span class="hljs-comment"># 将当前的批次数据 x 移动到指定的设备上（如 GPU 设备）</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 关闭梯度计算的上下文环境，以减少内存占用和加快计算速度</span><br>            pred = model(x)  <span class="hljs-comment"># 对当前批次的数据进行预测</span><br>            preds.append(pred.detach().cpu())  <span class="hljs-comment"># 将预测结果 pred 附加到 preds 列表中</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    在所有批次预测结束后，使用 torch.cat 函数将所有预测结果沿着指定维度（通常是批次维度）拼接成一个大的张量，并将其转换为 NumPy 数组格式返回</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    preds = torch.cat(preds, dim=<span class="hljs-number">0</span>).numpy()<br>    <span class="hljs-keyword">return</span> preds<br></code></pre></td></tr></table></figure>
<h2 id="dataset" tabindex="-1" id="Dataset">Dataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">COVID19Dataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    x: Features.  特征</span><br><span class="hljs-string">    y: Targets, if none, do prediction. 标签，如果为空，则做 prediction</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> y <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-variable language_">self</span>.y = y  <span class="hljs-comment"># 设为 none</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.y = torch.FloatTensor(y)  <span class="hljs-comment"># 转成 tensor 格式</span><br>        <span class="hljs-variable language_">self</span>.x = torch.FloatTensor(x)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.y <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.x[idx]  <span class="hljs-comment"># 返回标签</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.x[idx], <span class="hljs-variable language_">self</span>.y[idx]  <span class="hljs-comment"># 返回特征和对应的标签</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.x)  <span class="hljs-comment"># 返回数据集长度</span><br></code></pre></td></tr></table></figure>
<h2 id="neural-network-model" tabindex="-1" id="Neural-Network-Model">Neural Network Model</h2>
<p>Try out different model architectures by modifying the class below.</p>
<p>通过修改下面的类来尝试不同的模型体系结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">My_Model</span>(nn.Module):  <span class="hljs-comment"># 声明了一个自定义的 PyTorch 神经网络模型，继承自 nn.Module</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim</span>):  <span class="hljs-comment"># 定义了该神经网络模型的初始化方法。参数 input_dim 表示输入张量的维度</span><br>        <span class="hljs-built_in">super</span>(My_Model, <span class="hljs-variable language_">self</span>).__init__()  <span class="hljs-comment"># 调用父类的初始化方法，即 nn.Module 中的__init__()方法，来初始化该自定义模型。</span><br>        <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> modify model&#x27;s structure, be aware of dimensions. </span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        self.layers 声明了一个由多个层和激活函数组成的神经网络模型，</span><br><span class="hljs-string">        用于传递输入数据并输出预测结果。</span><br><span class="hljs-string">        其中，nn.Sequential()表示将多个层按顺序组合在一起，组成一个网络模型。</span><br><span class="hljs-string">        3 个线性层，2 个 ReLU 激活函数</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-variable language_">self</span>.layers = nn.Sequential(<br>            nn.Linear(input_dim, <span class="hljs-number">16</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        定义了该自定义神经网络模型的前向传播方法，即输入数据 x 经过一系列层和激活函数的变换之后，最终输出预测结果。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        x = <span class="hljs-variable language_">self</span>.layers(x)  <span class="hljs-comment"># 表示将输入数据 x 输入到 self.layers 中，进行多层次的线性变换和非线性激活。</span><br>        <span class="hljs-comment"># 表示对最终输出的张量进行压缩，将形状为(batch_size, 1)的张量压缩为形状为(batch_size,)的张量，方便后续处理和计算损失值</span><br>        x = x.squeeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, 1) -&gt; (B)</span><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>
<h2 id="feature-selection" tabindex="-1" id="Feature-Selection">Feature Selection</h2>
<p>Choose features you deem useful by modifying the function below.</p>
<p>通过修改下面的功能来选择您认为有用的功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">select_feat</span>(<span class="hljs-params">train_data, valid_data, test_data, select_all=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    定义了一个函数 select_feat，该函数接受三个张量类型的输入参数 train_data、valid_data 和 test_data，</span><br><span class="hljs-string">    分别表示训练数据集、验证数据集和测试数据集。</span><br><span class="hljs-string">    另外，该函数还包含一个可选参数 select_all，默认为 True，表示是否选择全部特征列。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;Selects useful features to perform regression&#x27;&#x27;&#x27;</span><br>    y_train, y_valid = train_data[:,-<span class="hljs-number">1</span>], valid_data[:,-<span class="hljs-number">1</span>]  <span class="hljs-comment"># 将原始的训练数据集和验证数据集中的标签列（最后一列）提取出来，分别赋值给变量 y_train 和 y_valid，用于后续的回归分析。</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    将原始的训练数据集、验证数据集和测试数据集中除标签列之外的所有列提取出来，</span><br><span class="hljs-string">    分别赋值给变量 raw_x_train、raw_x_valid 和 raw_x_test，用于后续的特征选择。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-<span class="hljs-number">1</span>], valid_data[:,:-<span class="hljs-number">1</span>], test_data<br><br>    <span class="hljs-keyword">if</span> select_all:<br>        feat_idx = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(raw_x_train.shape[<span class="hljs-number">1</span>]))  <span class="hljs-comment"># 将所有原始特征列的索引放入一个列表中，并赋值给变量 feat_idx</span><br>    <span class="hljs-keyword">else</span>:<br>        feat_idx = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>] <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Select suitable feature columns.  选择适当的特征列</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    返回特征选择后的训练数据、验证数据和测试数据。</span><br><span class="hljs-string">    其中，raw_x_train[:,feat_idx]表示从训练数据集中选择指定的特征列，</span><br><span class="hljs-string">    raw_x_valid[:,feat_idx]表示从验证数据集中选择指定的特征列，</span><br><span class="hljs-string">    raw_x_test[:,feat_idx]表示从测试数据集中选择指定的特征列，</span><br><span class="hljs-string">    最后两个参数 y_train 和 y_valid 表示训练数据集和验证数据集的标签列。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">return</span> raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid<br></code></pre></td></tr></table></figure>
<h2 id="training-loop" tabindex="-1" id="Training-Loop">Training Loop</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">trainer</span>(<span class="hljs-params">train_loader, valid_loader, model, config, device</span>):<br>    <span class="hljs-comment"># 定义了一个均方误差损失函数 MSELoss，用于计算模型预测结果和真实标签之间的差异。</span><br>    criterion = nn.MSELoss(reduction=<span class="hljs-string">&#x27;mean&#x27;</span>) <span class="hljs-comment"># Define your loss function, do not modify this. </span><br><br>    <span class="hljs-comment"># Define your optimization algorithm.  定义你自己的优化函数</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> L2 regularization (optimizer(weight decay...) or implement by your self).  L2 正则化（优化器（权重衰减…）或自行实现）。</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    定义了一个随机梯度下降（SGD）优化器，用于优化模型的参数。</span><br><span class="hljs-string">    其中，model.parameters()表示需要优化的模型参数，</span><br><span class="hljs-string">    lr=config[&#x27;learning_rate&#x27;]表示学习率，</span><br><span class="hljs-string">    momentum=0.7 表示使用动量法进行优化。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    optimizer = torch.optim.SGD(model.parameters(), lr=config[<span class="hljs-string">&#x27;learning_rate&#x27;</span>], momentum=<span class="hljs-number">0.7</span>)<br>    writer = SummaryWriter() <span class="hljs-comment"># Writer of tensoboard.  创建了一个 SummaryWriter 对象，用于将训练过程中的监控指标写入 tensorboard 日志文件。</span><br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isdir(<span class="hljs-string">&#x27;./models&#x27;</span>):<br>        os.mkdir(<span class="hljs-string">&#x27;./models&#x27;</span>) <span class="hljs-comment"># Create directory of saving models.  创建一个文件夹以保存模型</span><br>    <span class="hljs-comment"># 设置了几个变量，包括训练轮数 n_epochs、最佳损失值 best_loss、当前训练步数 step 和早停计数器 early_stop_count</span><br>    n_epochs, best_loss, step, early_stop_count = config[<span class="hljs-string">&#x27;n_epochs&#x27;</span>], math.inf, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):  <span class="hljs-comment"># 开始迭代训练，共进行 n_epochs 轮训练。</span><br>        model.train() <span class="hljs-comment"># Set your model to train mode.  将模型切换为训练模式。</span><br>        loss_record = []  <span class="hljs-comment"># 新建一个列表以存储每一个 epoch 损失函数的值。</span><br><br>        <span class="hljs-comment"># tqdm is a package to visualize your training progress.  使用 tqdm 库创建一个进度条，用于可视化训练进度。</span><br>        train_pbar = tqdm(train_loader, position=<span class="hljs-number">0</span>, leave=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> train_pbar:  <span class="hljs-comment"># 开始迭代训练集，依次提取出输入特征 x 和标签 y。</span><br>            optimizer.zero_grad()  <span class="hljs-comment"># Set gradient to zero.  清零梯度，避免上一次的梯度对本次梯度的影响。</span><br>            x, y = x.to(device), y.to(device)   <span class="hljs-comment"># Move your data to device. 将输入特征 x 和标签 y 复制到 GPU 设备上进行加速计算。</span><br>            pred = model(x)  <span class="hljs-comment"># 将输入特征 x 输入到模型中，得到预测结果 pred。</span><br>            loss = criterion(pred, y)  <span class="hljs-comment"># 计算预测结果 pred 和真实标签 y 之间的误差，即损失函数值。</span><br>            loss.backward()  <span class="hljs-comment"># Compute gradient(backpropagation).  自动计算损失函数对各个参数的梯度。</span><br>            optimizer.step()  <span class="hljs-comment"># Update parameters.  通过优化器更新模型参数。</span><br>            step += <span class="hljs-number">1</span><br>            loss_record.append(loss.detach().item())  <span class="hljs-comment"># 将每一批次的损失函数值记录下来。</span><br>            <br>            <span class="hljs-comment"># Display current epoch number and loss on tqdm progress bar.</span><br>            train_pbar.set_description(<span class="hljs-string">f&#x27;Epoch [<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;n_epochs&#125;</span>]&#x27;</span>)  <span class="hljs-comment"># 在进度条中显示当前轮数和总轮数。</span><br>            train_pbar.set_postfix(&#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss.detach().item()&#125;)  <span class="hljs-comment"># 在进度条中显示当前批次的损失函数值。</span><br><br>        mean_train_loss = <span class="hljs-built_in">sum</span>(loss_record)/<span class="hljs-built_in">len</span>(loss_record)  <span class="hljs-comment"># 计算当前轮训练集的平均损失函数值。</span><br>        writer.add_scalar(<span class="hljs-string">&#x27;Loss/train&#x27;</span>, mean_train_loss, step)  <span class="hljs-comment"># 将训练集的平均损失函数值写入 tensorboard 日志文件。</span><br><br>        model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># Set your model to evaluation mode.  将模型切换为评估模式，用于对验证集进行预测和评估。</span><br>        loss_record = []  <span class="hljs-comment"># 新建一个列表以存储每一个 epoch 损失函数的值。</span><br>        <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> valid_loader:  <span class="hljs-comment"># 开始迭代验证集，依次提取出输入特征 x 和标签 y。</span><br>            x, y = x.to(device), y.to(device)  <span class="hljs-comment"># 将输入特征 x 和标签 y 复制到 GPU 设备上进行加速计算。</span><br>            <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 评估验证集的时候不改变模型参数，关闭梯度</span><br>                pred = model(x)  <span class="hljs-comment"># 将输入特征 x 输入到模型中，得到预测结果 pred。</span><br>                loss = criterion(pred, y)  <span class="hljs-comment"># 计算预测结果 pred 和真实标签 y 之间的误差，即损失函数值。</span><br><br>            loss_record.append(loss.item())  <span class="hljs-comment"># 将每一批次的损失函数值记录下来。</span><br>            <br>        mean_valid_loss = <span class="hljs-built_in">sum</span>(loss_record)/<span class="hljs-built_in">len</span>(loss_record)  <span class="hljs-comment"># 计算当前轮验证集的平均损失函数值。</span><br>        <span class="hljs-comment"># 打印当前轮的训练集和验证集的平均损失函数值。</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch [<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;n_epochs&#125;</span>]: Train loss: <span class="hljs-subst">&#123;mean_train_loss:<span class="hljs-number">.4</span>f&#125;</span>, Valid loss: <span class="hljs-subst">&#123;mean_valid_loss:<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)<br>        <span class="hljs-comment"># writer.add_scalar(&#x27;Loss/valid&#x27;, mean_valid_loss, step)</span><br><br>        <span class="hljs-keyword">if</span> mean_valid_loss &lt; best_loss:<br>            <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">            如果当前轮的验证集平均损失函数值优于历史最佳值，则更新最佳损失值和最佳模型参数，并将模型保存到指定路径</span><br><span class="hljs-string">            &#x27;&#x27;&#x27;</span><br>            best_loss = mean_valid_loss<br>            torch.save(model.state_dict(), config[<span class="hljs-string">&#x27;save_path&#x27;</span>]) <span class="hljs-comment"># Save your best model</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Saving model with loss &#123;:.3f&#125;...&#x27;</span>.<span class="hljs-built_in">format</span>(best_loss))<br>            early_stop_count = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 如果当前轮的验证集平均损失函数值没有优于历史最佳值，则早停计数器加 1</span><br>            early_stop_count += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> early_stop_count &gt;= config[<span class="hljs-string">&#x27;early_stop&#x27;</span>]:  <span class="hljs-comment"># 如果早停计数器超过早停阈值，则停止训练并返回</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nModel is not improving, so we halt the training session.&#x27;</span>)<br>            <span class="hljs-keyword">return</span><br></code></pre></td></tr></table></figure>
<h2 id="configurations" tabindex="-1" id="Configurations">Configurations</h2>
<p><code>config</code> contains hyper-parameters for training and the path to save your model.</p>
<p>config 包含用于训练的超参数和保存模型的路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>config = &#123;<br>    <span class="hljs-string">&#x27;seed&#x27;</span>: <span class="hljs-number">5201314</span>,      <span class="hljs-comment"># Your seed number, you can pick your lucky number. :)</span><br>    <span class="hljs-string">&#x27;select_all&#x27;</span>: <span class="hljs-literal">True</span>,   <span class="hljs-comment"># Whether to use all features.</span><br>    <span class="hljs-string">&#x27;valid_ratio&#x27;</span>: <span class="hljs-number">0.2</span>,   <span class="hljs-comment"># validation_size = train_size * valid_ratio</span><br>    <span class="hljs-string">&#x27;n_epochs&#x27;</span>: <span class="hljs-number">5000</span>,     <span class="hljs-comment"># Number of epochs.            </span><br>    <span class="hljs-string">&#x27;batch_size&#x27;</span>: <span class="hljs-number">256</span>, <br>    <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">1e-5</span>,              <br>    <span class="hljs-string">&#x27;early_stop&#x27;</span>: <span class="hljs-number">600</span>,    <span class="hljs-comment"># If model has not improved for this many consecutive epochs, stop training.  若模型在这么多连续的时期内并没有得到改善，就停止训练。     </span><br>    <span class="hljs-string">&#x27;save_path&#x27;</span>: <span class="hljs-string">&#x27;./models/model.ckpt&#x27;</span>  <span class="hljs-comment"># Your model will be saved here.</span><br>&#125;<br><br></code></pre></td></tr></table></figure>
<h2 id="dataloader" tabindex="-1" id="Dataloader">Dataloader</h2>
<p>Read data from files and set up training, validation, and testing sets. You do not need to modify this part.</p>
<p>从文件中读取数据，并设置培训、验证和测试集。您不需要修改此部件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python">same_seed(config[<span class="hljs-string">&#x27;seed&#x27;</span>])  <span class="hljs-comment"># 设置随机数种子，保证每次训练的结果可复现。</span><br><span class="hljs-comment"># 从指定文件路径读取训练集和测试集数据，并将其转换成 numpy 数组的形式。</span><br>train_data, test_data = pd.read_csv(<span class="hljs-string">&#x27;./covid_train.csv&#x27;</span>).values, pd.read_csv(<span class="hljs-string">&#x27;./covid_test.csv&#x27;</span>).values<br><span class="hljs-comment"># 将训练集拆分为新的训练集和验证集，其中 train_valid_split()函数接受三个参数：原始训练集、验证集比例和随机数种子。</span><br>train_data, valid_data = train_valid_split(train_data, config[<span class="hljs-string">&#x27;valid_ratio&#x27;</span>], config[<span class="hljs-string">&#x27;seed&#x27;</span>])<br><br><span class="hljs-comment"># Print out the data size.  打印出训练集、验证集和测试集的大小。</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&quot;&quot;train_data size: <span class="hljs-subst">&#123;train_data.shape&#125;</span> </span><br><span class="hljs-string">valid_data size: <span class="hljs-subst">&#123;valid_data.shape&#125;</span> </span><br><span class="hljs-string">test_data size: <span class="hljs-subst">&#123;test_data.shape&#125;</span>&quot;&quot;&quot;</span>)<br><br><span class="hljs-comment">## Select features</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">选择特征，其中 select_feat()函数接受四个参数：</span><br><span class="hljs-string">训练集、验证集、测试集和是否选择所有特征（如果是，则选择所有特征；如果否，则根据一定规则筛选特征）。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config[<span class="hljs-string">&#x27;select_all&#x27;</span>])<br><br><span class="hljs-comment"># Print out the number of features.</span><br><span class="hljs-comment"># 打印出特征数量。</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;number of features: <span class="hljs-subst">&#123;x_train.shape[<span class="hljs-number">1</span>]&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 创建训练集、验证集和测试集的数据集。</span><br>train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \<br>                                            COVID19Dataset(x_valid, y_valid), \<br>                                            COVID19Dataset(x_test)<br><br><span class="hljs-comment"># Pytorch data loader loads pytorch dataset into batches.</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">使用 PyTorch 提供的 DataLoader 将训练集数据集加载到内存中，并设置每个 batch 的大小、是否打乱顺序以及是否将数据存储在 GPU 显存中。</span><br><span class="hljs-string">同样，valid_loader 和 test_loader 也是通过 DataLoader 加载验证集和测试集数据集。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>train_loader = DataLoader(train_dataset, batch_size=config[<span class="hljs-string">&#x27;batch_size&#x27;</span>], shuffle=<span class="hljs-literal">True</span>, pin_memory=<span class="hljs-literal">True</span>)<br>valid_loader = DataLoader(valid_dataset, batch_size=config[<span class="hljs-string">&#x27;batch_size&#x27;</span>], shuffle=<span class="hljs-literal">True</span>, pin_memory=<span class="hljs-literal">True</span>)<br>test_loader = DataLoader(test_dataset, batch_size=config[<span class="hljs-string">&#x27;batch_size&#x27;</span>], shuffle=<span class="hljs-literal">False</span>, pin_memory=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<pre><code>train_data size: (2408, 89) 
valid_data size: (601, 89) 
test_data size: (997, 88)
number of features: 88
</code></pre>
<h2 id="start-training!" tabindex="-1" id="Start-training">Start training!</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = My_Model(input_dim=x_train.shape[<span class="hljs-number">1</span>]).to(device) <span class="hljs-comment"># put your model and data on the same computation device.</span><br>trainer(train_loader, valid_loader, model, config, device)<br></code></pre></td></tr></table></figure>
<pre><code>Epoch [1/5000]: 100%|██████████| 10/10 [00:03&lt;00:00,  3.26it/s, loss=131]


Epoch [1/5000]: Train loss: 263.8631, Valid loss: 94.9638
Saving model with loss 94.964...
</code></pre>
<p>……</p>
<pre><code>Epoch [998/5000]: Train loss: 3.8978, Valid loss: 6.7839


Epoch [999/5000]: 100%|██████████| 10/10 [00:00&lt;00:00, 135.57it/s, loss=2.35]
</code></pre>
<h2 id="plot-learning-curves-with-tensorboard-(optional)" tabindex="-1" id="Plot-learning-curves-with-tensorboard-optional">Plot learning curves with <code>tensorboard</code> (optional)</h2>
<p><code>tensorboard</code> is a tool that allows you to visualize your training progress.</p>
<p>If this block does not display your learning curve, please wait for few minutes, and re-run this block. It might take some time to load your logging information.</p>
<p>tensorboard 是一个工具，可以让你可视化你的训练进度。
如果此块没有显示您的学习曲线，请等待几分钟，然后重新运行此块。加载日志信息可能需要一些时间。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">%reload_ext tensorboard<br>%tensorboard --logdir=./runs/<br></code></pre></td></tr></table></figure>
<h2 id="testing" tabindex="-1" id="Testing">Testing</h2>
<p>The predictions of your model on testing set will be stored at <code>pred.csv</code>.</p>
<p>您的模型在测试集上的预测将存储在 pred.csv 中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_pred</span>(<span class="hljs-params">preds, file</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Save predictions to specified file</span><br><span class="hljs-string">    自定义函数 save_pred()，接受两个参数：预测结果和指定的文件路径。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> fp:  <span class="hljs-comment"># 使用指定的路径打开文件，以写入的模式打开（&#x27;w&#x27;）。</span><br>        writer = csv.writer(fp)  <span class="hljs-comment"># 使用 Python 标准库 csv 中的 writer()方法创建一个写入器</span><br>        writer.writerow([<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;tested_positive&#x27;</span>])  <span class="hljs-comment"># 写入文件头。</span><br>        <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(preds):  <span class="hljs-comment"># 循环遍历预测结果，并将每个样本的 ID 和预测值写入文件中。</span><br>            writer.writerow([i, p])<br><br>model = My_Model(input_dim=x_train.shape[<span class="hljs-number">1</span>]).to(device)  <span class="hljs-comment"># 创建一个名为 My_Model 的模型，其中 input_dim 是输入数据的特征维度。</span><br>model.load_state_dict(torch.load(config[<span class="hljs-string">&#x27;save_path&#x27;</span>]))  <span class="hljs-comment"># 利用 PyTorch 提供的 load_state_dict()方法加载训练好的模型参数。</span><br>preds = predict(test_loader, model, device)  <span class="hljs-comment">#  使用定义好的 predict()函数对测试集进行预测，其中 predict()函数接受三个参数：测试集的数据加载器、模型以及设备类型。</span><br>save_pred(preds, <span class="hljs-string">&#x27;pred.csv&#x27;</span>)  <span class="hljs-comment"># 将预测结果保存到指定文件中。</span><br></code></pre></td></tr></table></figure>
<h2 id="download" tabindex="-1" id="Download">Download</h2>
<p>Run this block to download the <code>pred.csv</code> automatically.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> files<br>files.download(<span class="hljs-string">&#x27;pred.csv&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="reference" tabindex="-1" id="Reference">Reference</h2>
<p>This notebook uses code written by Heng-Jui Chang @ NTUEE (<a target="_blank" rel="noopener" href="https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb">https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb</a>)</p>
<h1 id="homework-2%3A-phoneme-classification" tabindex="-1"><strong>Homework 2: Phoneme Classification</strong></h1>
<p><strong>Task Description</strong></p>
<ul>
<li>Phoneme Classification
<ul>
<li>音素分类</li>
</ul>
</li>
<li>Training data: 3429 preprocessed audio features w/ labels (total 2116794 frames)
<ul>
<li>训练数据：3429 个带标签的预处理音频特征（共 2116794 帧）</li>
</ul>
</li>
<li>Testing data: 857 preprocessed audio features w/o labels (total 527364 frames)
<ul>
<li>测试数据：857 个带标签（共 527364 帧）的预处理语音特征</li>
</ul>
</li>
<li>Label: 41 classes, each class represents a phoneme
<ul>
<li>标签：41 个类，每个类代表一个音素</li>
</ul>
</li>
</ul>
<p>Objectives:</p>
<ul>
<li>Solve a classification problem with deep neural networks (DNNs).
<ul>
<li>使用 DNN 解决分类问题</li>
</ul>
</li>
<li>Understand recursive neural networks (RNNs).
<ul>
<li>了解递归神经网络（RNN）。
If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to <a href="mailto:mlta-2023-spring@googlegroups.com">mlta-2023-spring@googlegroups.com</a></li>
</ul>
</li>
</ul>
<h2 id="some-utility-functions-1" tabindex="-1" id="Some-Utility-Functions">Some Utility Functions</h2>
<p><strong>Fixes random number generator seeds for reproducibility.</strong></p>
<p>固定随机数生成器种子以获得再现性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">same_seeds</span>(<span class="hljs-params">seed</span>):<br>    random.seed(seed) <br>    np.random.seed(seed)  <br>    torch.manual_seed(seed)<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        torch.cuda.manual_seed(seed)<br>        torch.cuda.manual_seed_all(seed) <br>    torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span>  <span class="hljs-comment"># 将 CuDNN 的随机性设置为确定性模式，这是为了确保每次运行时 CuDNN 生成的随机数列是一样的。</span><br>    torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 禁用 CuDNN 的自动调整功能，避免出现由于 CuDNN 自动调整导致的运行时间不稳定的情况。</span><br></code></pre></td></tr></table></figure>
<p><strong>Helper functions to pre-process the training data from raw MFCC features of each utterance.</strong></p>
<p><strong>辅助函数用于预处理来自每个话语的原始 MFCC 特征的训练数据。</strong></p>
<p>A phoneme may span several frames and is dependent to past and future frames. <br>
Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The <strong>concat_feat</strong> function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.</p>
<p>一个音素可能跨越几个帧，并依赖于过去和未来的帧。<br>
因此，我们将相邻的音素连接起来进行训练，以获得更高的精度。<strong>concat_filt</strong>函数连接过去和未来的 k 帧（总共 2k+1=n 帧），我们预测中心帧。</p>
<p>Feel free to modify the data preprocess functions, but <strong>do not drop any frame</strong> (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)</p>
<p>可以随意修改数据预处理函数，但<strong>不要丢弃任何帧</strong>（如果修改函数，请记住检查帧数是否与幻灯片中提到的相同）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_feat</span>(<span class="hljs-params">path</span>):<br>    feat = torch.load(path)  <span class="hljs-comment"># 用于加载已保存模型的函数。该函数接受一个文件路径参数，返回包含模型参数的 Python 字典对象。</span><br>    <span class="hljs-keyword">return</span> feat<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">shift</span>(<span class="hljs-params">x, n</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    shift 函数用来实现对一个一维或二维的 Tensor x 进行循环移位操作。其中，移位的距离为整数值 n，可以为正、负、零。</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    repeat() 函数是用来对一个序列进行重复的函数，即将原序列中的元素按照指定次数进行重复。</span><br><span class="hljs-string">    具体而言，对于一个具有 n 个元素的序列 x，</span><br><span class="hljs-string">    调用 x.repeat(m) 函数可以得到一个新的序列，其中包含原序列 x 中的所有元素，每个元素均重复 m 次。</span><br><span class="hljs-string">    例如，对于 [1, 2, 3] 序列执行 repeat(3) 操作后得到的序列为 [1, 2, 3, 1, 2, 3, 1, 2, 3]。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">0</span>:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        如果 n &lt; 0，表示向左移动，</span><br><span class="hljs-string">        此时函数会将 x 最左侧的 n 个元素复制到 x 的最右侧，</span><br><span class="hljs-string">        同时将 x 原来的前 n 个元素截取出来放到 x 的末尾；</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        left = x[<span class="hljs-number">0</span>].repeat(-n, <span class="hljs-number">1</span>)<br>        right = x[:n]<br>    <span class="hljs-keyword">elif</span> n &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        如果 n &gt; 0，表示向右移动，</span><br><span class="hljs-string">        此时函数会将 x 最右侧的 n 个元素复制到 x 的最左侧，</span><br><span class="hljs-string">        同时将 x 原来的后 n 个元素截取出来放到 x 的开头；</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        right = x[-<span class="hljs-number">1</span>].repeat(n, <span class="hljs-number">1</span>)<br>        left = x[n:]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        如果 n = 0，表示不需要移位，直接返回原始的 x。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> x<br>    <span class="hljs-comment"># 使用 torch.cat() 函数将左右两个部分进行拼接，其中 dim=0 表示在第 0 维（即在行方向上）进行拼接。最后返回拼接后的结果。</span><br>    <span class="hljs-keyword">return</span> torch.cat((left, right), dim=<span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">concat_feat</span>(<span class="hljs-params">x, concat_n</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    将输入的张量 x 沿着第 0 维进行拼接。</span><br><span class="hljs-string">    具体而言，将原始的 seq_len x feature_dim 的二维张量，复制 concat_n 次后变为 seq_len x (concat_n*feature_dim) 的形状。</span><br><span class="hljs-string">    将一个二维张量沿着第 0 维进行拼接，并实现了一些操作来保证拼接后的结果具有一定的对称性和规律性。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># assert 语句会在程序中检查某个条件是否成立，如果不成立，就会抛出一个 AssertionError 异常，并给出错误信息。</span><br>    <span class="hljs-keyword">assert</span> concat_n % <span class="hljs-number">2</span> == <span class="hljs-number">1</span> <span class="hljs-comment"># n must be odd 对输入的 concat_n 进行判断，确保其为奇数</span><br>    <span class="hljs-keyword">if</span> concat_n &lt; <span class="hljs-number">2</span>:  <span class="hljs-comment"># 如果 concat_n 小于 2，则直接返回原始的张量 x。</span><br>        <span class="hljs-keyword">return</span> x<br>    seq_len, feature_dim = x.size(<span class="hljs-number">0</span>), x.size(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 对输入的张量获取其 seq_len 和 feature_dim（即第 0 维和第 1 维的大小）</span><br>    x = x.repeat(<span class="hljs-number">1</span>, concat_n)  <span class="hljs-comment"># 使用 repeat() 函数将输入张量在第 1 维上重复 concat_n 次，得到一个新的形状为 seq_len x (concat_n * feature_dim) 的张量</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    使用 view() 函数将张量重新变形，</span><br><span class="hljs-string">    使得第 1 维大小为 concat_n，</span><br><span class="hljs-string">    第 2 维大小为 seq_len，</span><br><span class="hljs-string">    第 3 维大小为 feature_dim。</span><br><span class="hljs-string">    然后使用 permute() 函数交换各维度的位置，使得张量的形状变为 (concat_n, seq_len, feature_dim)。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    x = x.view(seq_len, concat_n, feature_dim).permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># concat_n, seq_len, feature_dim</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    找到张量中心位置 mid = (concat_n // 2)，并对从 mid+1 到最后的行进行循环，对这些行进行移位操作。</span><br><span class="hljs-string">    具体来说，对于每一行，将其向右移动 r_idx 个位置，再将移位后的结果放到对称位置上。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    mid = (concat_n // <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">for</span> r_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, mid+<span class="hljs-number">1</span>):<br>        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)<br>        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)<br>    <span class="hljs-comment"># 使用 permute() 和 view() 函数将张量恢复到 seq_len x (concat_n*feature_dim) 的形状，并返回拼接后的张量</span><br>    <span class="hljs-keyword">return</span> x.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>).view(seq_len, concat_n * feature_dim)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_data</span>(<span class="hljs-params">split, feat_dir, phone_path, concat_nframes, train_ratio=<span class="hljs-number">0.8</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    用于对数据集进行预处理。</span><br><span class="hljs-string">    split: 数据集的划分，可选值为 &#x27;train&#x27;、&#x27;val&#x27; 和 &#x27;test&#x27;。</span><br><span class="hljs-string">    feat_dir: 特征文件所在的目录。</span><br><span class="hljs-string">    phone_path: 声音标签文件所在的目录。</span><br><span class="hljs-string">    concat_nframes: 需要拼接的帧数。</span><br><span class="hljs-string">    train_ratio: 训练集和验证集的划分比例，缺省值为 0.8。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    class_num = <span class="hljs-number">41</span> <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> pre-computed, should not need change 设置音素总数 class_num（注意，此处的值是预先计算好的，不需要更改）。</span><br><br>    <span class="hljs-comment"># 根据 split 参数判断数据集模式 mode，如果是 &#x27;train&#x27; 或 &#x27;val&#x27;，就设置为 &#x27;train&#x27;，否则设置为 &#x27;test&#x27;。</span><br>    <span class="hljs-keyword">if</span> split == <span class="hljs-string">&#x27;train&#x27;</span> <span class="hljs-keyword">or</span> split == <span class="hljs-string">&#x27;val&#x27;</span>:<br>        mode = <span class="hljs-string">&#x27;train&#x27;</span><br>    <span class="hljs-keyword">elif</span> split == <span class="hljs-string">&#x27;test&#x27;</span>:<br>        mode = <span class="hljs-string">&#x27;test&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Invalid \&#x27;split\&#x27; argument for dataset: PhoneDataset!&#x27;</span>)<br><br>    label_dict = &#123;&#125;<br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:  <span class="hljs-comment"># 如果是训练模式</span><br>        <span class="hljs-comment"># 从标签文件中读取标签信息到字典 label_dict 中</span><br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(os.path.join(phone_path, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;mode&#125;</span>_labels.txt&#x27;</span>)).readlines():<br>            line = line.strip(<span class="hljs-string">&#x27;\n&#x27;</span>).split(<span class="hljs-string">&#x27; &#x27;</span>)<br>            label_dict[line[<span class="hljs-number">0</span>]] = [<span class="hljs-built_in">int</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> line[<span class="hljs-number">1</span>:]]<br>        <br>        <span class="hljs-comment"># split training and validation data</span><br>        <span class="hljs-comment"># 从训练集划分文件中读取训练集和验证集的使用情况，并按照参数 train_ratio 进行划分。</span><br>        usage_list = <span class="hljs-built_in">open</span>(os.path.join(phone_path, <span class="hljs-string">&#x27;train_split.txt&#x27;</span>)).readlines()<br>        random.shuffle(usage_list)<br>        train_len = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(usage_list) * train_ratio)<br>        usage_list = usage_list[:train_len] <span class="hljs-keyword">if</span> split == <span class="hljs-string">&#x27;train&#x27;</span> <span class="hljs-keyword">else</span> usage_list[train_len:]<br><br>    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;test&#x27;</span>:<br>        usage_list = <span class="hljs-built_in">open</span>(os.path.join(phone_path, <span class="hljs-string">&#x27;test_split.txt&#x27;</span>)).readlines()<br><br>    <span class="hljs-comment"># 从数据划分文件中读取使用的文件名列表到 usage_list 中，然后将其格式化为标准格式（去除换行符）</span><br>    usage_list = [line.strip(<span class="hljs-string">&#x27;\n&#x27;</span>) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> usage_list]<br>    <span class="hljs-comment"># 打印有关数据集的信息，包括电话类别总数和数据集划分情况。</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[Dataset] - # phone classes: &#x27;</span> + <span class="hljs-built_in">str</span>(class_num) + <span class="hljs-string">&#x27;, number of utterances for &#x27;</span> + split + <span class="hljs-string">&#x27;: &#x27;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(usage_list)))<br><br>    <span class="hljs-comment"># 初始化张量 X 和 y（仅在训练模式下）</span><br>    max_len = <span class="hljs-number">3000000</span><br>    X = torch.empty(max_len, <span class="hljs-number">39</span> * concat_nframes)<br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>        y = torch.empty(max_len, dtype=torch.long)<br><br>    <span class="hljs-comment"># 按顺序读入特征文件中的信息到 X 中，同时将标签信息读入到 y 中。</span><br>    idx = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, fname <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">enumerate</span>(usage_list)):<br>        feat = load_feat(os.path.join(feat_dir, mode, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;fname&#125;</span>.pt&#x27;</span>))<br>        cur_len = <span class="hljs-built_in">len</span>(feat)<br>        feat = concat_feat(feat, concat_nframes)<br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>          label = torch.LongTensor(label_dict[fname])<br><br>        X[idx: idx + cur_len, :] = feat<br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>          y[idx: idx + cur_len] = label<br><br>        idx += cur_len<br><br>    <span class="hljs-comment"># 去掉张量 X 和 y 中多余的部分（即在初始化时申请的空间）</span><br>    X = X[:idx, :]<br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>      y = y[:idx]<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;[INFO] <span class="hljs-subst">&#123;split&#125;</span> set&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(X.shape)<br>    <span class="hljs-comment"># 返回处理后的张量 X（和可选的张量 y）</span><br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:<br>      <span class="hljs-built_in">print</span>(y.shape)<br>      <span class="hljs-keyword">return</span> X, y<br>    <span class="hljs-keyword">else</span>:<br>      <span class="hljs-keyword">return</span> X<br><br></code></pre></td></tr></table></figure>
<h2 id="dataset-1" tabindex="-1" id="Dataset-2">Dataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LibriDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, X, y=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-variable language_">self</span>.data = X<br>        <span class="hljs-keyword">if</span> y <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-variable language_">self</span>.label = torch.LongTensor(y)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.label = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.label <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data[idx], <span class="hljs-variable language_">self</span>.label[idx]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data[idx]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.data)<br><br></code></pre></td></tr></table></figure>
<h2 id="model" tabindex="-1" id="Model">Model</h2>
<p>Feel free to modify the structure of the model.</p>
<p>请随意修改模型的结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, output_dim</span>):<br>        <span class="hljs-built_in">super</span>(BasicBlock, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        BasicBlock 是一个基本的神经网络模块，包含一个全连接层和一个 ReLU 激活层。</span><br><span class="hljs-string">        输入向量的维度是 input_dim，输出向量的维度是 output_dim</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-variable language_">self</span>.block = nn.Sequential(<br>            nn.Linear(input_dim, output_dim),<br>            nn.ReLU(),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.block(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Classifier</span>(nn.Module):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    定义了一个名为 Classifier 的神经网络模型，包含几个 BasicBlock 模块。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, output_dim=<span class="hljs-number">41</span>, hidden_layers=<span class="hljs-number">1</span>, hidden_dim=<span class="hljs-number">256</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        input_dim: 输入向量的维度。</span><br><span class="hljs-string">        output_dim: 输出向量的维度，即分类类别总数，默认为 41。</span><br><span class="hljs-string">        hidden_layers: 隐藏层的数量，缺省值为 1。</span><br><span class="hljs-string">        hidden_dim: 隐藏层的神经元数。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">super</span>(Classifier, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-variable language_">self</span>.fc = nn.Sequential(<br>            <span class="hljs-comment"># 首先通过一个 BasicBlock 将样本输入从 input_dim 维度降到 hidden_dim 维度</span><br>            BasicBlock(input_dim, hidden_dim),<br>            <span class="hljs-comment"># 通过一个 for 循环堆叠多个 BasicBlock 来增加模型深度和表达能力</span><br>            *[BasicBlock(hidden_dim, hidden_dim) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(hidden_layers)],<br>            <span class="hljs-comment"># 通过一个全连接层将输出映射到 output_dim 维度上，完成整个分类任务。</span><br>            nn.Linear(hidden_dim, output_dim)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.fc(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>
<h2 id="hyper-parameters" tabindex="-1" id="Hyper-parameters">Hyper-parameters</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># data prarameters 数据参数</span><br><span class="hljs-comment"># 要连接的帧数，n 必须是奇数（总共 2k+1=n 帧）</span><br>concat_nframes = <span class="hljs-number">3</span>  <span class="hljs-comment"># the number of frames to concat with, n must be odd (total 2k+1 = n frames)</span><br><span class="hljs-comment"># 用于训练的数据比例，其余数据将用于验证</span><br>train_ratio = <span class="hljs-number">0.75</span>  <span class="hljs-comment"># the ratio of data used for training, the rest will be used for validation</span><br><br><span class="hljs-comment"># training parameters  训练参数</span><br>seed = <span class="hljs-number">1213</span>  <span class="hljs-comment"># random seed  随机数种子</span><br>batch_size = <span class="hljs-number">512</span>  <span class="hljs-comment"># batch size 批大小</span><br>num_epoch = <span class="hljs-number">10</span>  <span class="hljs-comment"># the number of training epoch，epoch 次数</span><br>learning_rate = <span class="hljs-number">1e-4</span>  <span class="hljs-comment"># learning rate 学习率</span><br>model_path = <span class="hljs-string">&#x27;./model.ckpt&#x27;</span>  <span class="hljs-comment"># the path where the checkpoint will be saved 检查点保存位置</span><br><br><span class="hljs-comment"># model parameters  模型参数</span><br><span class="hljs-comment"># 模型的输入维数，不应更改该值</span><br>input_dim = <span class="hljs-number">39</span> * concat_nframes  <span class="hljs-comment"># the input dim of the model, you should not change the value</span><br><span class="hljs-comment"># 隐藏层数</span><br>hidden_layers = <span class="hljs-number">2</span>  <span class="hljs-comment"># the number of hidden layers</span><br><span class="hljs-comment"># 隐藏层维数</span><br>hidden_dim = <span class="hljs-number">64</span>  <span class="hljs-comment"># the hidden dim</span><br></code></pre></td></tr></table></figure>
<h2 id="dataloader-1" tabindex="-1" id="Dataloader-2">Dataloader</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> gc  <span class="hljs-comment"># 导入 gc 模块，用于进行垃圾回收操作</span><br><br>same_seeds(seed)  <span class="hljs-comment"># 设置了随机数的种子</span><br><span class="hljs-comment"># 根据是否有 GPU 加速设备来确定程序的运行设备</span><br>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;DEVICE: <span class="hljs-subst">&#123;device&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># preprocess data</span><br><span class="hljs-comment"># 通过 preprocess_data() 函数对训练数据和验证数据进行预处理，并将其存储到 train_X、train_y、val_X 和 val_y 这四个变量中</span><br>train_X, train_y = preprocess_data(split=<span class="hljs-string">&#x27;train&#x27;</span>,<br>                                   <span class="hljs-comment"># 语音特征文件所在目录的路径</span><br>                                   feat_dir=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone/feat&#x27;</span>,<br>                                   <span class="hljs-comment"># 语音标签文件所在的路径</span><br>                                   phone_path=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone&#x27;</span>,<br>                                   <span class="hljs-comment"># 将前后几帧的音频特征拼接成新的特征向量</span><br>                                   concat_nframes=concat_nframes,<br>                                   <span class="hljs-comment"># 训练集和验证集的划分比例</span><br>                                   train_ratio=train_ratio)<br>val_X, val_y = preprocess_data(split=<span class="hljs-string">&#x27;val&#x27;</span>,<br>                               feat_dir=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone/feat&#x27;</span>,<br>                               phone_path=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone&#x27;</span>,<br>                               concat_nframes=concat_nframes,<br>                               train_ratio=train_ratio)<br><br><span class="hljs-comment">## get dataset</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">使用数据集的类 LibriDataset 对每个数据集进行实例化，</span><br><span class="hljs-string">传入训练集和验证集的 X 和 y（即上一步中得到的 train_X, train_y 和 val_X, val_y），</span><br><span class="hljs-string">并将其赋值给 train_set 和 val_set 变量。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>train_set = LibriDataset(train_X, train_y)<br>val_set = LibriDataset(val_X, val_y)<br><br><span class="hljs-comment"># remove raw feature to save memory</span><br><span class="hljs-keyword">del</span> train_X, train_y, val_X, val_y  <span class="hljs-comment"># 为了释放内存，删除 train_X, train_y, val_X 和 val_y 这四个变量</span><br>gc.collect()  <span class="hljs-comment"># 用 gc.collect() 释放所有未引用的内存</span><br><br><span class="hljs-comment">## get dataloader</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">使用 DataLoader 类为训练集和验证集创建 DataLoader 实例，</span><br><span class="hljs-string">指定批次大小 batch_size 和是否需要打乱数据 shuffle，</span><br><span class="hljs-string">并将其赋值给 train_loader 和 val_loader 变量，以供模型训练时使用</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<pre><code>DEVICE: cuda
[Dataset] - # phone classes: 41, number of utterances for train: 2571


2571it [00:23, 107.38it/s]


[INFO] train set
torch.Size([1588590, 117])
torch.Size([1588590])
[Dataset] - # phone classes: 41, number of utterances for val: 858


858it [00:02, 308.31it/s]


[INFO] val set
torch.Size([525078, 117])
torch.Size([525078])
</code></pre>
<h2 id="training" tabindex="-1" id="Training">Training</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># create model, define a loss function, and optimizer</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">创建了一个用于分类的模型实例，</span><br><span class="hljs-string">这里使用了 Classifier 类，指定了输入数据的维度 input_dim、隐藏层的数量 hidden_layers 和每个隐藏层的维度 hidden_dim。</span><br><span class="hljs-string">并将其移动到之前确定的设备中。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)<br><span class="hljs-comment"># 定义交叉熵损失函数 nn.CrossEntropyLoss() </span><br>criterion = nn.CrossEntropyLoss() <br><span class="hljs-comment"># 优化器 Adam，将模型的参数传入优化器中，以便进行反向传播来更新权重。</span><br>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)<br><br>best_acc = <span class="hljs-number">0.0</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epoch):  <span class="hljs-comment"># 开始对模型进行训练，循环执行 num_epoch 次</span><br>    <span class="hljs-comment"># 在每次循环的时候，将 train_acc 和 train_loss、val_acc 和 val_loss 分别初始化为 0</span><br>    train_acc = <span class="hljs-number">0.0</span><br>    train_loss = <span class="hljs-number">0.0</span><br>    val_acc = <span class="hljs-number">0.0</span><br>    val_loss = <span class="hljs-number">0.0</span><br>    <br>    <span class="hljs-comment"># training 将模型设为“训练模式”</span><br>    model.train() <span class="hljs-comment"># set the model to training mode</span><br>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(train_loader)):  <span class="hljs-comment"># 对 train_loader 中的每个 batch 进行循环操作</span><br>        <span class="hljs-comment"># 在每个 batch 中，将 features 和 labels 数据移动到之前设置的设备上（即 device）</span><br>        features, labels = batch<br>        features = features.to(device)<br>        labels = labels.to(device)<br>        <br>        <span class="hljs-comment"># 将模型中的梯度设置为 0</span><br>        optimizer.zero_grad() <br>        <span class="hljs-comment"># 使用模型对 features 进行前向传播，得到预测结果 outputs</span><br>        outputs = model(features) <br>        <br>        <span class="hljs-comment"># 计算损失值 loss</span><br>        loss = criterion(outputs, labels)<br>        <span class="hljs-comment"># 通过反向传播计算出梯度</span><br>        loss.backward() <br>        <span class="hljs-comment"># 更新模型参数</span><br>        optimizer.step() <br>        <br>        <span class="hljs-comment"># 获取预测结果中的最大值</span><br>        _, train_pred = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>) <span class="hljs-comment"># get the index of the class with the highest probability</span><br>        <span class="hljs-comment"># 将其与标签进行比较，得到得到 train_acc 的值</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        train_pred 是模型在训练集上的预测结果，labels 是该 batch 中样本的标签。</span><br><span class="hljs-string">        train_pred.detach() 和 labels.detach() 是为了防止其梯度反向传播而被计算的前后关联（detach 方法是将一个 tensor 从计算图中分离出来，不再参与自动求导）。</span><br><span class="hljs-string">        通过 train_pred.detach() == labels.detach() 的判断，得到一个 boolean 类型的 Tensor，表示模型预测结果是否正确。</span><br><span class="hljs-string">        接着对这个 Tensor 进行 sum() 操作，计算其中 True 的元素个数，即预测正确的样本数。</span><br><span class="hljs-string">        最后使用 item() 方法将结果作为 Python 的 float 类型，累加到 train_acc 变量中。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        train_acc += (train_pred.detach() == labels.detach()).<span class="hljs-built_in">sum</span>().item()<br>        <span class="hljs-comment"># 将损失值加入 train_loss 中</span><br>        train_loss += loss.item()<br>    <br>    <span class="hljs-comment"># validation</span><br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># set the model to evaluation mode 将模型设为“评估模式”</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(val_loader)):  <span class="hljs-comment"># 对 val_loader 中的每个 batch 进行循环操作</span><br>            features, labels = batch<br>            features = features.to(device)<br>            labels = labels.to(device)<br>            outputs = model(features)  <span class="hljs-comment"># 调用模型进行前向计算</span><br>            <br>            loss = criterion(outputs, labels)  <span class="hljs-comment"># 计算 loss 损失值</span><br>            <br>            _, val_pred = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>) <br>            <span class="hljs-comment"># 计算出预测准确率 val_acc 和 val_loss</span><br>            val_acc += (val_pred.cpu() == labels.cpu()).<span class="hljs-built_in">sum</span>().item() <span class="hljs-comment"># get the index of the class with the highest probability</span><br>            val_loss += loss.item()<br>    <span class="hljs-comment"># 在每个 epoch 结束后，计算出 train_acc、train_loss、val_acc 和 val_loss 的平均值，并将其输出以监控训练过程</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;[<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>:03d&#125;</span>/<span class="hljs-subst">&#123;num_epoch:03d&#125;</span>] Train Acc: <span class="hljs-subst">&#123;train_acc/<span class="hljs-built_in">len</span>(train_set):<span class="hljs-number">3.5</span>f&#125;</span> Loss: <span class="hljs-subst">&#123;train_loss/<span class="hljs-built_in">len</span>(train_loader):<span class="hljs-number">3.5</span>f&#125;</span> | Val Acc: <span class="hljs-subst">&#123;val_acc/<span class="hljs-built_in">len</span>(val_set):<span class="hljs-number">3.5</span>f&#125;</span> loss: <span class="hljs-subst">&#123;val_loss/<span class="hljs-built_in">len</span>(val_loader):<span class="hljs-number">3.5</span>f&#125;</span>&#x27;</span>)<br><br>    <span class="hljs-comment"># if the model improves, save a checkpoint at this epoch</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    如果当前模型的验证准确率 val_acc 超过了之前的最佳准确率 best_acc，</span><br><span class="hljs-string">    则将 best_acc 更新为当前的 val_acc 值，</span><br><span class="hljs-string">    将模型的参数保存到指定文件名的模型路径 model_path 中，</span><br><span class="hljs-string">    并输出日志记录保存的模型及其准确率值。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> val_acc &gt; best_acc:<br>        best_acc = val_acc<br>        torch.save(model.state_dict(), model_path)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;saving model with acc <span class="hljs-subst">&#123;best_acc/<span class="hljs-built_in">len</span>(val_set):<span class="hljs-number">.5</span>f&#125;</span>&#x27;</span>)<br><br></code></pre></td></tr></table></figure>
<pre><code>100%|██████████| 3103/3103 [00:19&lt;00:00, 156.88it/s]
100%|██████████| 1026/1026 [00:03&lt;00:00, 273.11it/s]


[001/010] Train Acc: 0.39279Loss: 2.21685 | Val Acc: 0.43877 loss: 1.97101
saving model with acc 0.43877


100%|██████████| 3103/3103 [00:17&lt;00:00, 175.27it/s]
100%|██████████| 1026/1026 [00:03&lt;00:00, 277.94it/s]
</code></pre>
<p>……</p>
<pre><code>[009/010] Train Acc: 0.49606Loss: 1.72781 | Val Acc: 0.49852 loss: 1.71150
saving model with acc 0.49852


100%|██████████| 3103/3103 [00:17&lt;00:00, 180.14it/s]
100%|██████████| 1026/1026 [00:04&lt;00:00, 241.12it/s]

[010/010] Train Acc: 0.49840Loss: 1.71736 | Val Acc: 0.50044 loss: 1.70057
saving model with acc 0.50044
</code></pre>
<p>​<br>
​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">del</span> train_set, val_set<br><span class="hljs-keyword">del</span> train_loader, val_loader<br>gc.collect()<br></code></pre></td></tr></table></figure>
<pre><code>23
</code></pre>
<h2 id="testing-1" tabindex="-1" id="Testing-2">Testing</h2>
<p>Create a testing dataset, and load model from the saved checkpoint.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load data</span><br>test_X = preprocess_data(split=<span class="hljs-string">&#x27;test&#x27;</span>, feat_dir=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone/feat&#x27;</span>, phone_path=<span class="hljs-string">&#x27;/kaggle/input/ml2023spring-hw2/libriphone&#x27;</span>, concat_nframes=concat_nframes)<br>test_set = LibriDataset(test_X, <span class="hljs-literal">None</span>)<br>test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<pre><code>[Dataset] - # phone classes: 41, number of utterances for test: 857


857it [00:08, 103.10it/s]

[INFO] test set
torch.Size([527364, 117])
</code></pre>
<p>​<br>
​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## load model</span><br>model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)<br>model.load_state_dict(torch.load(model_path))<br></code></pre></td></tr></table></figure>
<pre><code>&lt;All keys matched successfully&gt;
</code></pre>
<p>Make prediction.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">pred = np.array([], dtype=np.int32)  <span class="hljs-comment"># 创建一个空的 numpy 数组 pred，其数据类型为 np.int32</span><br><br>model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 将模型设置为“评估模式”</span><br><span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 使用 with torch.no_grad() 上下文管理器，以避免在评估模式下无意中修改了梯度。</span><br>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(test_loader)):  <span class="hljs-comment"># 在 test_loader 上进行循环操作，每次从中取出一个 batch，并将其转换到指定的设备 device 上</span><br>        <span class="hljs-comment"># 使用模型对 features 进行前向传播，得到预测结果 outputs</span><br>        features = batch<br>        features = features.to(device)<br><br>        outputs = model(features)<br>        <br>        <span class="hljs-comment"># 通过 torch.max(outputs, 1) 可以得到每个样本在每个类别上的分数，</span><br>        <span class="hljs-comment"># _ 表示分数张量，test_pred 是在第 1 维度（即类别）上具有最大值的索引，代表模型预测的类别</span><br>        _, test_pred = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>) <span class="hljs-comment"># get the index of the class with the highest probability</span><br>        <span class="hljs-comment"># 将 test_pred 转回 numpy 数组，并使用 np.concatenate() 方法将其与之前的 pred 数组进行拼接，生成更新后的预测结果</span><br>        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=<span class="hljs-number">0</span>)<br><span class="hljs-comment"># 最终，当所有测试集的样本都被预测完毕后，pred 数组中将保存模型在测试集上的所有预测结果。</span><br></code></pre></td></tr></table></figure>
<pre><code>100%|██████████| 1031/1031 [00:01&lt;00:00, 533.21it/s]
</code></pre>
<p>Write prediction to a CSV file.</p>
<p>After finish running this block, download the file <code>prediction.csv</code> from the files section on the left-hand side and submit it to Kaggle.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;prediction.csv&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    f.write(<span class="hljs-string">&#x27;Id,Class\n&#x27;</span>)<br>    <span class="hljs-keyword">for</span> i, y <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred):<br>        f.write(<span class="hljs-string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.<span class="hljs-built_in">format</span>(i, y))<br></code></pre></td></tr></table></figure>
<h2 id="hw3-image-classification" tabindex="-1" id="HW3-Image-Classification"><strong>HW3 Image Classification</strong></h2>
<h4 id="solve-image-classification-with-convolutional-neural-networks(cnn)." tabindex="-1" id="Solve-image-classification-with-convolutional-neural-networks-CNN">Solve image classification with convolutional neural networks(CNN).</h4>
<p>使用卷积神经网络处理图像分类问题。</p>
<h4 id="if-you-have-any-questions%2C-please-contact-the-tas-via-ta-hours%2C-ntu-cool%2C-or-email-to-mlta-2023-spring%40googlegroups.com" tabindex="-1" id="If-you-have-any-questions-please-contact-the-TAs-via-TA-hours-NTU-COOL-or-email-to-mlta-2023-spring-googlegroups-com">If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to <a href="mailto:mlta-2023-spring@googlegroups.com">mlta-2023-spring@googlegroups.com</a></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># check GPU type.</span><br>!nvidia-smi<br></code></pre></td></tr></table></figure>
<pre><code>Tue May  2 10:05:59 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre>
<h3 id="import-packages-1" tabindex="-1" id="Import-Packages">Import Packages</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">_exp_name = <span class="hljs-string">&quot;sample&quot;</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Import necessary packages.</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-comment"># &quot;ConcatDataset&quot; and &quot;Subset&quot; are possibly useful when doing semi-supervised learning.</span><br><span class="hljs-comment"># 在进行半监督学习时，“ConcatDataset”和“Subset”可能很有用。</span><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> ConcatDataset, DataLoader, Subset, Dataset<br><span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> DatasetFolder, VisionDataset<br><span class="hljs-comment"># This is for the progress bar.</span><br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> random<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">myseed = <span class="hljs-number">6666</span>  <span class="hljs-comment"># set a random seed for reproducibility</span><br>torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span><br>torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><br>np.random.seed(myseed)<br>torch.manual_seed(myseed)<br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    torch.cuda.manual_seed_all(myseed)<br></code></pre></td></tr></table></figure>
<h3 id="transforms" tabindex="-1" id="Transforms">Transforms</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Normally, We don&#x27;t need augmentations in testing and validation.</span><br><span class="hljs-comment"># 通常情况下，我们不需要在测试和验证中进行增强。</span><br><span class="hljs-comment"># All we need here is to resize the PIL image and transform it into Tensor.</span><br><span class="hljs-comment"># 这里我们所需要的只是调整 PIL 图像的大小并将其转换为张量。</span><br>test_tfm = transforms.Compose([<br>    transforms.Resize((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>)),<br>    transforms.ToTensor(),<br>])<br><br><span class="hljs-comment"># However, it is also possible to use augmentation in the testing phase.</span><br><span class="hljs-comment"># 然而，在测试阶段也可以使用增强功能。</span><br><span class="hljs-comment"># You may use train_tfm to produce a variety of images and then test using ensemble methods</span><br><span class="hljs-comment"># 您可以使用 train_tfm 生成各种图像，然后使用集成方法进行测试</span><br>train_tfm = transforms.Compose([<br>    <span class="hljs-comment"># Resize the image into a fixed shape (height = width = 128)</span><br>    transforms.Resize((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>)),<br>    <span class="hljs-comment"># You may add some transforms here.</span><br>    <br>    <span class="hljs-comment"># ToTensor() should be the last one of the transforms.  ToTensor（）应该是最后一个 transform。</span><br>    transforms.ToTensor(),<br>])<br></code></pre></td></tr></table></figure>
<h3 id="datasets" tabindex="-1" id="Datasets">Datasets</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FoodDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    该类继承了 PyTorch 中的 Dataset 类，是将数据导入 PyTorch 模型中训练和测试所必需的组件之一</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,path,tfm=test_tfm,files = <span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        用于初始化该类，其中 path 是数据集的路径，tfm 是一个可选参数，代表数据预处理的方法（默认为 test_tfm），</span><br><span class="hljs-string">        files 是一个可选参数，是指要加载的文件列表（默认为 None）。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">super</span>(FoodDataset).__init__()<br>        <span class="hljs-variable language_">self</span>.path = path<br>        <span class="hljs-comment"># 在初始化时，根据给定的路径获取图片文件列表 self.files，并排序，</span><br>        <span class="hljs-variable language_">self</span>.files = <span class="hljs-built_in">sorted</span>([os.path.join(path,x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> os.listdir(path) <span class="hljs-keyword">if</span> x.endswith(<span class="hljs-string">&quot;.jpg&quot;</span>)])<br>        <span class="hljs-comment"># 若 files 不为 None，则使用 files 中指定的文件列表。接着对输入图片进行数据预处理，并将其转化为张量。</span><br>        <span class="hljs-keyword">if</span> files != <span class="hljs-literal">None</span>:<br>            <span class="hljs-variable language_">self</span>.files = files<br>            <br>        <span class="hljs-variable language_">self</span>.transform = tfm<br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        获取该数据集的长度</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.files)<br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self,idx</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        用于获取指定索引 idx 的样本，并将其转换为模型所需的数据格式。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 该函数会根据 idx 获取 self.files 中对应位置的图片文件名 fname</span><br>        fname = <span class="hljs-variable language_">self</span>.files[idx]<br>        <span class="hljs-comment"># 读取图片文件为 PIL.Image 格式的对象 im</span><br>        im = Image.<span class="hljs-built_in">open</span>(fname)<br>        <span class="hljs-comment"># 通过 transform 对象对 im 进行数据预处理，并将结果转换为 torch.Tensor 格式的张量</span><br>        im = <span class="hljs-variable language_">self</span>.transform(im)<br>        <br>        <span class="hljs-comment"># 通过解析文件名 fname 获取样本的标签 label，若 fname 的名称格式不符，则将 label 设为 -1（test 数据集没有 label）。</span><br>        <span class="hljs-keyword">try</span>:<br>            label = <span class="hljs-built_in">int</span>(fname.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>])<br>        excerpt:<br>            label = -<span class="hljs-number">1</span> <span class="hljs-comment"># test has no label</span><br>            <br>        <span class="hljs-keyword">return</span> im,label<br></code></pre></td></tr></table></figure>
<h3 id="model-1" tabindex="-1" id="Model-2">Model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Classifier</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Classifier, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span><br>        <span class="hljs-comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span><br>        <span class="hljs-comment"># input 維度 [3, 128, 128]</span><br>        <span class="hljs-variable language_">self</span>.cnn = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># [64, 128, 128]</span><br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>),      <span class="hljs-comment"># [64, 64, 64]</span><br><br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), <span class="hljs-comment"># [128, 64, 64]</span><br>            nn.BatchNorm2d(<span class="hljs-number">128</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>),      <span class="hljs-comment"># [128, 32, 32]</span><br><br>            nn.Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), <span class="hljs-comment"># [256, 32, 32]</span><br>            nn.BatchNorm2d(<span class="hljs-number">256</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>),      <span class="hljs-comment"># [256, 16, 16]</span><br><br>            nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), <span class="hljs-comment"># [512, 16, 16]</span><br>            nn.BatchNorm2d(<span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>),       <span class="hljs-comment"># [512, 8, 8]</span><br>            <br>            nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), <span class="hljs-comment"># [512, 8, 8]</span><br>            nn.BatchNorm2d(<span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>),       <span class="hljs-comment"># [512, 4, 4]</span><br>        )<br>        <span class="hljs-variable language_">self</span>.fc = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">512</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>, <span class="hljs-number">1024</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">11</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = <span class="hljs-variable language_">self</span>.cnn(x)<br>        out = out.view(out.size()[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)  <span class="hljs-comment"># flatten</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.fc(out)<br></code></pre></td></tr></table></figure>
<h3 id="configurations-1" tabindex="-1" id="Configurations-2">Configurations</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;cuda&quot; only when GPUs are available.</span><br>device = <span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br><br><span class="hljs-comment"># Initialize a model, and put it on the device specified.</span><br>model = Classifier().to(device)<br><br><span class="hljs-comment"># The number of batch size.</span><br>batch_size = <span class="hljs-number">64</span><br><br><span class="hljs-comment"># The number of training epochs.</span><br>n_epochs = <span class="hljs-number">8</span><br><br><span class="hljs-comment"># If no improvement in &#x27;patience&#x27; epochs, early stop.</span><br>patience = <span class="hljs-number">300</span><br><br><span class="hljs-comment"># For the classification task, we use cross-entropy as the measurement of performance.</span><br>criterion = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.</span><br>optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">0.0003</span>, weight_decay=<span class="hljs-number">1e-5</span>)<br></code></pre></td></tr></table></figure>
<h3 id="dataloader-2" tabindex="-1" id="Dataloader-3">Dataloader</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Construct train and valid datasets.</span><br><span class="hljs-comment"># The argument &quot;loader&quot; tells how torchvision reads the data.</span><br>train_set = FoodDataset(<span class="hljs-string">&quot;/kaggle/input/ml2023spring-hw3/train&quot;</span>, tfm=train_tfm)<br>train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, pin_memory=<span class="hljs-literal">True</span>)<br>valid_set = FoodDataset(<span class="hljs-string">&quot;/kaggle/input/ml2023spring-hw3/valid&quot;</span>, tfm=test_tfm)<br>valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, pin_memory=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h3 id="start-training" tabindex="-1" id="Start-Training">Start Training</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Initialize trackers, these are not parameters and should not be changed</span><br>stale = <span class="hljs-number">0</span><br>best_acc = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br><br>    <span class="hljs-comment"># ---------- Training ----------</span><br>    <span class="hljs-comment"># Make sure the model is in train mode before training.</span><br>    model.train()<br><br>    <span class="hljs-comment"># These are used to record information in training.</span><br>    train_loss = []<br>    train_accs = []<br><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(train_loader):<br><br>        <span class="hljs-comment"># A batch consists of image data and corresponding labels.</span><br>        imgs, labels = batch<br>        <span class="hljs-comment">#imgs = imgs.half()</span><br>        <span class="hljs-comment">#print(imgs.shape,labels.shape)</span><br><br>        <span class="hljs-comment"># Forward the data. (Make sure data and model are on the same device.)</span><br>        logits = model(imgs.to(device))<br><br>        <span class="hljs-comment"># Calculate the cross-entropy loss.</span><br>        <span class="hljs-comment"># We don&#x27;t need to apply softmax before computing cross-entropy as it is done automatically.</span><br>        <span class="hljs-comment"># 在计算交叉熵之前，我们不需要应用 softmax，因为它是自动完成的。</span><br>        loss = criterion(logits, labels.to(device))<br><br>        <span class="hljs-comment"># Gradients stored in the parameters in the previous step should be cleared out first.</span><br>        <span class="hljs-comment"># 应首先清除上一步中存储在参数中的梯度。</span><br>        optimizer.zero_grad()<br><br>        <span class="hljs-comment"># Compute the gradients for parameters.</span><br>        loss.backward()<br><br>        <span class="hljs-comment"># Clip the gradient norms for stable training.</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        该代码调用了 PyTorch 中 nn.utils.clip_grad_norm_() 方法，该方法旨在对梯度进行截断，并返回一个梯度范数。</span><br><span class="hljs-string">        该方法接收两个参数：第一个参数是模型的参数，即 model.parameters()，</span><br><span class="hljs-string">        第二个参数是一个 float 类型的变量，表示梯度的最大范数（即 L2 范数）。</span><br><span class="hljs-string">        在这里，max_norm 的值被设置为 10。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="hljs-number">10</span>)<br><br>        <span class="hljs-comment"># Update the parameters with computed gradients.</span><br>        optimizer.step()<br><br>        <span class="hljs-comment"># Compute the accuracy for current batch.</span><br>        acc = (logits.argmax(dim=-<span class="hljs-number">1</span>) == labels.to(device)).<span class="hljs-built_in">float</span>().mean()<br><br>        <span class="hljs-comment"># Record the loss and accuracy.</span><br>        train_loss.append(loss.item())<br>        train_accs.append(acc)<br>        <br>    train_loss = <span class="hljs-built_in">sum</span>(train_loss) / <span class="hljs-built_in">len</span>(train_loss)<br>    train_acc = <span class="hljs-built_in">sum</span>(train_accs) / <span class="hljs-built_in">len</span>(train_accs)<br><br>    <span class="hljs-comment"># Print the information.</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[ Train | <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>:03d&#125;</span>/<span class="hljs-subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="hljs-subst">&#123;train_loss:<span class="hljs-number">.5</span>f&#125;</span>, acc = <span class="hljs-subst">&#123;train_acc:<span class="hljs-number">.5</span>f&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># ---------- Validation ----------</span><br>    <span class="hljs-comment"># Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.</span><br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment"># These are used to record information in validation.</span><br>    valid_loss = []<br>    valid_accs = []<br><br>    <span class="hljs-comment"># Iterate the validation set by batches.</span><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(valid_loader):<br><br>        <span class="hljs-comment"># A batch consists of image data and corresponding labels.</span><br>        imgs, labels = batch<br>        <span class="hljs-comment">#imgs = imgs.half()</span><br><br>        <span class="hljs-comment"># We don&#x27;t need gradient in validation.</span><br>        <span class="hljs-comment"># Using torch.no_grad() accelerates the forward process.</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            logits = model(imgs.to(device))<br><br>        <span class="hljs-comment"># We can still compute the loss (but not the gradient).</span><br>        loss = criterion(logits, labels.to(device))<br><br>        <span class="hljs-comment"># Compute the accuracy for current batch.</span><br>        acc = (logits.argmax(dim=-<span class="hljs-number">1</span>) == labels.to(device)).<span class="hljs-built_in">float</span>().mean()<br><br>        <span class="hljs-comment"># Record the loss and accuracy.</span><br>        valid_loss.append(loss.item())<br>        valid_accs.append(acc)<br>        <span class="hljs-comment">#break</span><br><br>    <span class="hljs-comment"># The average loss and accuracy for entire validation set is the average of the recorded values.</span><br>    valid_loss = <span class="hljs-built_in">sum</span>(valid_loss) / <span class="hljs-built_in">len</span>(valid_loss)<br>    valid_acc = <span class="hljs-built_in">sum</span>(valid_accs) / <span class="hljs-built_in">len</span>(valid_accs)<br><br>    <span class="hljs-comment"># Print the information.</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[ Valid | <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>:03d&#125;</span>/<span class="hljs-subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="hljs-subst">&#123;valid_loss:<span class="hljs-number">.5</span>f&#125;</span>, acc = <span class="hljs-subst">&#123;valid_acc:<span class="hljs-number">.5</span>f&#125;</span>&quot;</span>)<br><br><br>    <span class="hljs-comment"># update logs</span><br>    <span class="hljs-keyword">if</span> valid_acc &gt; best_acc:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f&quot;./<span class="hljs-subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[ Valid | <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>:03d&#125;</span>/<span class="hljs-subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="hljs-subst">&#123;valid_loss:<span class="hljs-number">.5</span>f&#125;</span>, acc = <span class="hljs-subst">&#123;valid_acc:<span class="hljs-number">.5</span>f&#125;</span> -&gt; best&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f&quot;./<span class="hljs-subst">&#123;_exp_name&#125;</span>_log.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[ Valid | <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>:03d&#125;</span>/<span class="hljs-subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="hljs-subst">&#123;valid_loss:<span class="hljs-number">.5</span>f&#125;</span>, acc = <span class="hljs-subst">&#123;valid_acc:<span class="hljs-number">.5</span>f&#125;</span>&quot;</span>)<br><br><br>    <span class="hljs-comment"># save models</span><br>    <span class="hljs-keyword">if</span> valid_acc &gt; best_acc:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Best model found at epoch <span class="hljs-subst">&#123;epoch&#125;</span>, saving model&quot;</span>)<br>        torch.save(model.state_dict(), <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;_exp_name&#125;</span>_best.ckpt&quot;</span>) <span class="hljs-comment"># only save best to prevent output memory exceed error</span><br>        best_acc = valid_acc<br>        stale = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">else</span>:<br>        stale += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> stale &gt; patience:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;No improvment <span class="hljs-subst">&#123;patience&#125;</span> consecutive epochs, early stopping&quot;</span>)<br>            <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure>
<pre><code>  0%|          | 0/157 [00:00&lt;?, ?it/s]


[ Train | 001/008 ] loss = 1.87167, acc = 0.34385

  0%|          | 0/57 [00:00&lt;?, ?it/s]


[ Valid | 001/008 ] loss = 1.87423, acc = 0.34339
[ Valid | 001/008 ] loss = 1.87423, acc = 0.34339 -&gt; best
Best model found at epoch 0, saving model
</code></pre>
<p>……</p>
<pre><code>[ Train | 008/008 ] loss = 0.66352, acc = 0.77070

  0%|          | 0/57 [00:00&lt;?, ?it/s]


[ Valid | 008/008 ] loss = 1.28541, acc = 0.58910
[ Valid | 008/008 ] loss = 1.28541, acc = 0.58910
</code></pre>
<h3 id="dataloader-for-test" tabindex="-1" id="Dataloader-for-test">Dataloader for test</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Construct test datasets.</span><br><span class="hljs-comment"># The argument &quot;loader&quot; tells how torchvision reads the data.</span><br>test_set = FoodDataset(<span class="hljs-string">&quot;/kaggle/input/ml2023spring-hw3/test&quot;</span>, tfm=test_tfm)<br>test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">0</span>, pin_memory=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h3 id="testing-and-generate-prediction-csv" tabindex="-1" id="Testing-and-generate-prediction-CSV">Testing and generate prediction CSV</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">model_best = Classifier().to(device)<br>model_best.load_state_dict(torch.load(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;_exp_name&#125;</span>_best.ckpt&quot;</span>))<br>model_best.<span class="hljs-built_in">eval</span>()<br>prediction = []<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data,_ <span class="hljs-keyword">in</span> tqdm(test_loader):<br>        test_pred = model_best(data.to(device))<br>        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=<span class="hljs-number">1</span>)<br>        prediction += test_label.squeeze().tolist()<br></code></pre></td></tr></table></figure>
<pre><code>  0%|          | 0/47 [00:00&lt;?, ?it/s]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#create test csv</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pad4</span>(<span class="hljs-params">i</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;0&quot;</span>*(<span class="hljs-number">4</span>-<span class="hljs-built_in">len</span>(<span class="hljs-built_in">str</span>(i)))+<span class="hljs-built_in">str</span>(i)<br>df = pd.DataFrame()<br>df[<span class="hljs-string">&quot;Id&quot;</span>] = [pad4(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_set))]<br>df[<span class="hljs-string">&quot;Category&quot;</span>] = prediction<br>df.to_csv(<span class="hljs-string">&quot;submission.csv&quot;</span>,index = <span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<h1 id="hw4-self-attention" tabindex="-1"><strong>HW4 Self-attention</strong></h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ---初始化---</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">set_seed</span>(<span class="hljs-params">seed</span>):<br>    np.random.seed(seed)<br>    random.seed(seed)<br>    torch.manual_seed(seed)<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        torch.cuda.manual_seed(seed)<br>        torch.cuda.manual_seed_all(seed)<br>    torch.backends.cudnn.benchmark = <span class="hljs-literal">False</span><br>    torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span><br><br>set_seed(<span class="hljs-number">114514</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># --- Dataset ---</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> torch.nn.utils.rnn <span class="hljs-keyword">import</span> pad_sequence<br> <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">myDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data_dir, segment_len=<span class="hljs-number">128</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        data_dir 是指音频文件的路径</span><br><span class="hljs-string">        segment_len 是指每个音频片段的长度（默认为 128）</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-variable language_">self</span>.data_dir = data_dir<br>        <span class="hljs-variable language_">self</span>.segment_len = segment_len<br>        <br>        <span class="hljs-comment"># 加载从名字到 id 的映射 读取数据集文件夹中的 mapping.json</span><br>        mapping_path = Path(data_dir) / <span class="hljs-string">&quot;mapping.json&quot;</span><br>        mapping = json.load(mapping_path.<span class="hljs-built_in">open</span>())<br>        <span class="hljs-variable language_">self</span>.speaker2id = mapping[<span class="hljs-string">&quot;speaker2id&quot;</span>]  <span class="hljs-comment"># 演讲者名称到 ID</span><br><br>        <span class="hljs-comment"># 加载元数据</span><br>        metadata_path = Path(data_dir) / <span class="hljs-string">&quot;metadata.json&quot;</span><br>        metadata = json.load(<span class="hljs-built_in">open</span>(metadata_path))[<span class="hljs-string">&quot;speakers&quot;</span>]  <span class="hljs-comment"># 包含了所有演讲者的语音数据信息</span><br><br>        <span class="hljs-comment"># Get the total number of speaker.</span><br>        <span class="hljs-variable language_">self</span>.speaker_num = <span class="hljs-built_in">len</span>(metadata.keys())<br>        <span class="hljs-variable language_">self</span>.data = []<br>        <br>        <span class="hljs-comment"># 建立语音-&gt;ID 的数据    </span><br>        <span class="hljs-keyword">for</span> speaker <span class="hljs-keyword">in</span> metadata.keys():  <span class="hljs-comment"># 遍历 metadata.json 文件中 speakers 字段中的所有键值对</span><br>            <span class="hljs-keyword">for</span> utterances <span class="hljs-keyword">in</span> metadata[speaker]:<br>                <span class="hljs-comment"># 将形如 [utterances[&quot;feature_path&quot;], self.speaker2id[speaker]] 的数据添加到 self.data 中</span><br>                <span class="hljs-variable language_">self</span>.data.append([utterances[<span class="hljs-string">&quot;feature_path&quot;</span>], <span class="hljs-variable language_">self</span>.speaker2id[speaker]])<br>            <br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        返回音频片段数量</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.data)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        feat_path, speaker = <span class="hljs-variable language_">self</span>.data[index]<br>        <span class="hljs-comment"># 元数据的语音 &amp; 名字 ID</span><br>        <span class="hljs-comment"># 打开音频文件？</span><br>        mel = torch.load(os.path.join(<span class="hljs-variable language_">self</span>.data_dir,feat_path))<br>        <br>       <span class="hljs-comment"># 将 mel-spectrogram 分割成 长度为&quot;segment_len&quot; 帧.</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(mel) &gt; <span class="hljs-variable language_">self</span>.segment_len:<br>            <span class="hljs-comment"># 随机截取一段，先随机起点，然后开读</span><br>            start = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(mel) - <span class="hljs-variable language_">self</span>.segment_len)<br>            mel = torch.FloatTensor(mel[start:start+<span class="hljs-variable language_">self</span>.segment_len])<br>        <span class="hljs-keyword">else</span>:<br>            mel = torch.FloatTensor(mel)<br>        <span class="hljs-comment"># 强转转成 long</span><br>        speaker = torch.FloatTensor([speaker]).long()<br>        <span class="hljs-comment"># 返回真音频 ID</span><br>        <span class="hljs-keyword">return</span> mel, speaker <br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_speaker_number</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        返回数据集中演讲者数量</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.speaker_num<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># --- Dataloader ---</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, random_split<br><span class="hljs-keyword">from</span> torch.nn.utils.rnn <span class="hljs-keyword">import</span> pad_sequence<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_batch</span>(<span class="hljs-params">batch</span>):<br>    <span class="hljs-comment"># Process features within a batch.</span><br>    <span class="hljs-string">&quot;&quot;&quot;Collate a batch of data.&quot;&quot;&quot;</span><br>    mel, speaker = <span class="hljs-built_in">zip</span>(*batch)<br>    <span class="hljs-comment"># 因为我们一批一批地训练模型，所以我们需要在同一批中填充特征，以使它们的长度相同。</span><br>    <span class="hljs-comment"># 对于较短的 mel 音频特征，pad_sequence 函数会自动添加 0 填充。</span><br>    <span class="hljs-comment"># 这样，在训练神经网络时，不同长度的 mel 特征就可以组成一个 batch 进行训练了。</span><br>    <span class="hljs-comment"># Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.</span><br>    mel = pad_sequence(mel, batch_first=<span class="hljs-literal">True</span>, padding_value=-<span class="hljs-number">20</span>)    <span class="hljs-comment"># pad log 10^(-20) which is very small value.</span><br>    <span class="hljs-comment"># mel: (batch size, length, 40)</span><br>    <span class="hljs-keyword">return</span> mel, torch.FloatTensor(speaker).long()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader</span>(<span class="hljs-params">data_dir, batch_size, n_workers</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Generate dataloader</span><br><span class="hljs-string">    data_dir：数据集路径</span><br><span class="hljs-string">    batch_size：batch 大小</span><br><span class="hljs-string">    n_workers：读取数据的线程数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    dataset = myDataset(data_dir)<br>    speaker_num = dataset.get_speaker_number()<br>    <span class="hljs-comment"># 分割数据</span><br>    trainlen = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.9</span> * <span class="hljs-built_in">len</span>(dataset))<br>    lengths = [trainlen, <span class="hljs-built_in">len</span>(dataset) - trainlen]<br>    trainset, validset = random_split(dataset, lengths)<br><br>    train_loader = DataLoader(<br>        trainset,  <span class="hljs-comment"># 数据集</span><br>        batch_size=batch_size,  <span class="hljs-comment"># 每个 batch 的大小 </span><br>        shuffle=<span class="hljs-literal">True</span>, <span class="hljs-comment">#traindata 随机排序</span><br>        num_workers=n_workers,  <span class="hljs-comment"># 加载数据时所使用的 CPU 线程数</span><br>        drop_last=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 如果最后一个 batch 的样本数小于 batch_size，则丢弃该 batch</span><br>        pin_memory=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 将内存固定到 GPU 上，加快数据传输</span><br>        collate_fn=collate_batch,  <span class="hljs-comment"># 对每个 batch 中的数据进行批处理和填充，具体实现由 collate_batch 函数完成</span><br>    )<br>    valid_loader = DataLoader(<br>        validset,<br>        batch_size=batch_size,<br>        num_workers=n_workers,<br>        drop_last=<span class="hljs-literal">True</span>,<br>        pin_memory=<span class="hljs-literal">True</span>,<br>        collate_fn=collate_batch,<br>    )<br><br>    <span class="hljs-keyword">return</span> train_loader, valid_loader, speaker_num<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># --- Model ---</span><br>!pip install conformer<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> conformer <span class="hljs-keyword">import</span> ConformerBlock<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Classifier</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model=<span class="hljs-number">256</span>, n_spks=<span class="hljs-number">600</span>, dropout=<span class="hljs-number">0.2</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        该模型是一个语音分类器，用于将语音信号分为不同的说话人。</span><br><span class="hljs-string">        其中，d_model 表示特征维度，n_spks 表示说话人的数量，dropout 表示 dropout 概率。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># input -&gt; d_model</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        Prenet：通过一个全连接层对输入的 mel 音频特征进行转换，将 40 维的 mel 特征转化为 d_model 维的表示。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-variable language_">self</span>.prenet = nn.Linear(<span class="hljs-number">40</span>, d_model)<br>        <br><span class="hljs-comment"># self.encoder_layer = nn.TransformerEncoderLayer(</span><br><span class="hljs-comment"># d_model=d_model, dim_feedforward=256, nhead=2</span><br><span class="hljs-comment"># )</span><br><span class="hljs-comment"># self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)</span><br>        <span class="hljs-comment"># transformer 不行，不如 conformer</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        Encoder：使用 ConformerBlock 实现的编码器，将 Prenet 输出的 mel 音频特征序列编码成固定长度的向量，以便进行分类。</span><br><span class="hljs-string">        该编码器在多头 self-attention 机制的基础上，结合了深度可分离卷积，使用多层非线性变换对输入进行处理，提取更加抽象的特征表示。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-variable language_">self</span>.encoder=ConformerBlock(<br>            dim=d_model,<br>            dim_head=<span class="hljs-number">4</span>,<br>            heads=<span class="hljs-number">4</span>,  <span class="hljs-comment"># attension 层头数？</span><br>            ff_mult=<span class="hljs-number">4</span>,  <span class="hljs-comment"># 在 feed forward network 作为乘数的参数</span><br>            conv_expansion_factor=<span class="hljs-number">2</span>,  <span class="hljs-comment">#在卷积层中作成乘数的参数</span><br>            conv_kernel_size=<span class="hljs-number">20</span>,<br>            attn_dropout=dropout,  <span class="hljs-comment"># attendsion 层</span><br>            ff_dropout=dropout,  <span class="hljs-comment"># feed forward 层</span><br>            conv_dropout=dropout  <span class="hljs-comment"># 卷积层</span><br>        )<br>        <span class="hljs-comment"># Project the the dimension of features from d_model into speaker nums.</span><br>        <span class="hljs-comment"># 将 d_model 中的特征尺寸投影到 speaker 的编号中。</span><br>        <span class="hljs-variable language_">self</span>.pred_layer = nn.Sequential(<br>            <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">            Pred_layer：用于预测说话人标签的全连接神经网络</span><br><span class="hljs-string">            &#x27;&#x27;&#x27;</span><br>            nn.BatchNorm1d(d_model),  <span class="hljs-comment"># 对小批量 e2d 或 3d 输入进行批标准化</span><br>            nn.Linear(d_model, d_model),  <span class="hljs-comment"># 过两层全连接层将其映射到 n_spks 维的向量</span><br>            nn.Sigmoid(),  <span class="hljs-comment"># 通过 sigmoid 函数将每个维度的值限制在 [0, 1] 范围内</span><br>            nn.Linear(d_model, n_spks),  <span class="hljs-comment"># 最后一层采用线性变换输出分类结果</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, mels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        args:</span><br><span class="hljs-string">            mels: (batch size, length, 40)</span><br><span class="hljs-string">        return:</span><br><span class="hljs-string">            out: (batch size, n_spks)</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># out: (batch size, length, d_model)</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        在前向传播过程中，首先将输入的 mels 序列通过 Prenet 层进行特征转换，</span><br><span class="hljs-string">        得到一个形状为 (batch size, length, d_model) 的张量 out，其中 d_model 表示特征维度</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        out = <span class="hljs-variable language_">self</span>.prenet(mels)  <span class="hljs-comment"># 先上到 d_model</span><br>        <span class="hljs-comment"># out: (length, batch size, d_model)</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        通过调用 out.permute(1, 0, 2) 将其第一维和第二维交换位置，变成形状为 (length, batch size, d_model) 的张量，</span><br><span class="hljs-string">        以符合编码器 ConformerBlock 对输入的要求</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        out = out.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># 变形</span><br>        <span class="hljs-comment"># The encoder layer expect features in the shape of (length, batch size, d_model).</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        将 out 作为编码器的输出传入 self.encoder 中，得到一个 shape 为 (length, batch size, d_model) 的张量 out</span><br><span class="hljs-string">        这里使用的是 ConformerBlock 编码器，它采用了改进的 Transformer 结构，</span><br><span class="hljs-string">        在原有的自注意力机制的基础上加入了深度可分离卷积以及位置相关的 Feed-Forward 结构，能够更好地捕捉语音信号的时序特征。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        out = <span class="hljs-variable language_">self</span>.encoder(out)  <span class="hljs-comment"># encoder 就得酱紫，怪捏</span><br>        <span class="hljs-comment"># out: (batch size, length, d_model)</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        将 out 再次变形，将其第一维和第二维交换回来形成一个 shape 为 (batch size, length, d_model) 的张量</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        out = out.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 再变形</span><br>        <span class="hljs-comment"># mean pooling</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        对该张量沿着第一维做 mean pooling 操作，</span><br><span class="hljs-string">        生成一个 shape 为 (batch size, d_model) 的统计量 stats，代表了该批次中每个音频序列的平均特征向量</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        stats = out.mean(dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 取第 1 维的平均</span><br><br>        <span class="hljs-comment"># out: (batch, n_spks)</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        将 stats 作为输入传入全连接神经网络模型 self.pred_layer，得到一个 (batch size, n_spks) 维的输出向量 out，</span><br><span class="hljs-string">        其中 n_spks 表示说话人数量。该输出向量表示每个音频序列属于不同说话人的概率分布情况。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        out = <span class="hljs-variable language_">self</span>.pred_layer(stats)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Optimizer<br><span class="hljs-keyword">from</span> torch.optim.lr_scheduler <span class="hljs-keyword">import</span> LambdaLR <span class="hljs-comment">#注意这玩意</span><br><br><span class="hljs-comment">##学习率调整计划</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_cosine_schedule_with_warmup</span>(<span class="hljs-params"></span><br><span class="hljs-params">    optimizer: Optimizer,  <span class="hljs-comment"># 需要进行学习率调度的优化器对象。</span></span><br><span class="hljs-params">    num_warmup_steps: <span class="hljs-built_in">int</span>,  <span class="hljs-comment"># 学习率预热期的步长，也就是训练前需要逐步提高学习率的迭代次数。</span></span><br><span class="hljs-params">    num_training_steps: <span class="hljs-built_in">int</span>,  <span class="hljs-comment"># 训练总步长，也就是整个训练过程中的总迭代次数。</span></span><br><span class="hljs-params">    num_cycles: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.5</span>,  <span class="hljs-comment"># 余弦函数波形的周期数量，默认值为 0.5，表示每个周期内有一个完整的余弦波形变化。</span></span><br><span class="hljs-params">    last_epoch: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span>,  <span class="hljs-comment"># 可选参数，可以指定学习率调度器在开始训练时的起始 epoch 值。</span></span><br><span class="hljs-params"></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_lambda</span>(<span class="hljs-params">current_step</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        函数内部采用了一个嵌套函数 lr_lambda，其输入为当前训练的步数 current_step。</span><br><span class="hljs-string">        这个函数首先对前 num_warmup_steps 步采用线性递增的方式来提高学习率（因为在训练初期往往需要更小的学习率以避免模型梯度爆炸或消失）。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># Warmup</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        首先对前 num_warmup_steps 步采用线性递增的方式来提高学习率（因为在训练初期往往需要更小的学习率以避免模型梯度爆炸或消失）</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">if</span> current_step &lt; num_warmup_steps:<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(current_step) / <span class="hljs-built_in">float</span>(<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, num_warmup_steps))<br>        <span class="hljs-comment"># decadence</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        在剩余的 num_training_steps 步中，学习率会随着训练步数的增加而不断地逐渐下降。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        progress = <span class="hljs-built_in">float</span>(current_step - num_warmup_steps) / <span class="hljs-built_in">float</span>(<br>            <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, num_training_steps - num_warmup_steps)<br>        )<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(<br>            <span class="hljs-number">0.0</span>, <span class="hljs-number">0.5</span> * (<span class="hljs-number">1.0</span> + math.cos(math.pi * <span class="hljs-built_in">float</span>(num_cycles) * <span class="hljs-number">2.0</span> * progress))<br>        )<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    将 lr_lambda 函数和相关参数使用 LambdaLR 类进行包装，并返回该实例对象供模型训练过程中进行学习率的调度。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">return</span> LambdaLR(optimizer,lr_lambda,last_epoch)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练部分</span><br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_fn</span>(<span class="hljs-params">batch, model, criterion, device</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Forward a batch through the model.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># model.train()</span><br>    <span class="hljs-comment"># 拿数据环节</span><br>    mels, labels = batch<br>    mels = mels.to(device)<br>    labels = labels.to(device)<br>    <span class="hljs-comment"># 求损失环节</span><br>    outs = model(mels)<br>    loss = criterion(outs, labels)<br>    <span class="hljs-comment"># 返回概率最高的 speakerID</span><br>    preds = outs.argmax(<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 求准确率</span><br>    accuracy = torch.mean((preds == labels).<span class="hljs-built_in">float</span>())<br><br>    <span class="hljs-keyword">return</span> loss, accuracy<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 验证部分</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">valid</span>(<span class="hljs-params">dataloader, model, criterion, device</span>): <br>    <span class="hljs-string">&quot;&quot;&quot;Validate on validation set.&quot;&quot;&quot;</span><br><br>    model.<span class="hljs-built_in">eval</span>()<br>    running_loss = <span class="hljs-number">0.0</span><br>    running_accuracy = <span class="hljs-number">0.0</span><br>    pbar = tqdm(total=<span class="hljs-built_in">len</span>(dataloader.dataset), ncols=<span class="hljs-number">0</span>, desc=<span class="hljs-string">&quot;Valid&quot;</span>, unit=<span class="hljs-string">&quot; uttr&quot;</span>)<br><br>    <span class="hljs-keyword">for</span> i, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            loss, accuracy = model_fn(batch, model, criterion, device)<br>            running_loss += loss.item()<br>            running_accuracy += accuracy.item()<br><br>        pbar.update(dataloader.batch_size)<br>        pbar.set_postfix(<br>            loss=<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;running_loss / (i+<span class="hljs-number">1</span>):<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>,<br>            accuracy=<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;running_accuracy / (i+<span class="hljs-number">1</span>):<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>,<br>        )<br><br>    pbar.close()<br>    model.train()<br><br>    <span class="hljs-keyword">return</span> running_accuracy / <span class="hljs-built_in">len</span>(dataloader)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, random_split<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    <span class="hljs-comment"># 设定超参数</span><br>    config = &#123;<br>        <span class="hljs-string">&quot;data_dir&quot;</span>: <span class="hljs-string">&quot;/kaggle/input/ml2023springhw4/Dataset&quot;</span>,<br>        <span class="hljs-string">&quot;save_path&quot;</span>: <span class="hljs-string">&quot;/kaggle/working/model.ckpt&quot;</span>,<br>        <span class="hljs-string">&quot;batch_size&quot;</span>: <span class="hljs-number">32</span>,<br>        <span class="hljs-string">&quot;n_workers&quot;</span>: <span class="hljs-number">8</span>,<br>        <span class="hljs-string">&quot;valid_steps&quot;</span>: <span class="hljs-number">2000</span>,<br>        <span class="hljs-string">&quot;warmup_steps&quot;</span>: <span class="hljs-number">1000</span>,<br>        <span class="hljs-string">&quot;save_steps&quot;</span>: <span class="hljs-number">10000</span>,<br>        <span class="hljs-string">&quot;total_steps&quot;</span>: <span class="hljs-number">70000</span>,<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> config<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params"></span><br><span class="hljs-params">    data_dir,</span><br><span class="hljs-params">    save_path,</span><br><span class="hljs-params">    batch_size,</span><br><span class="hljs-params">    n_workers,</span><br><span class="hljs-params">    valid_steps,</span><br><span class="hljs-params">    warmup_steps,</span><br><span class="hljs-params">    total_steps,</span><br><span class="hljs-params">    save_steps,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Main function.&quot;&quot;&quot;</span><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Use <span class="hljs-subst">&#123;device&#125;</span> now!&quot;</span>)<br><br>    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)<br>    train_iterator = <span class="hljs-built_in">iter</span>(train_loader)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Finish loading data!&quot;</span>,flush = <span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 定义模型</span><br>    model = Classifier(n_spks=speaker_num).to(device)<br>    <span class="hljs-comment"># 定义损失函数</span><br>    criterion = nn.CrossEntropyLoss()<br>    <span class="hljs-comment"># 定义优化器</span><br>    optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>    <span class="hljs-comment"># 对优化器的学习率进行调整</span><br>    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Finish creating model!&quot;</span>,flush = <span class="hljs-literal">True</span>)<br>    <br>    model.load_state_dict(torch.load(<span class="hljs-string">f&quot;/kaggle/input/hw4model3/model (3).ckpt&quot;</span>))<br>    <br>    best_accuracy = -<span class="hljs-number">1.0</span><br>    best_state_dict = <span class="hljs-literal">None</span><br><br>    pbar = tqdm(total=valid_steps, ncols=<span class="hljs-number">0</span>, desc=<span class="hljs-string">&quot;Train&quot;</span>, unit=<span class="hljs-string">&quot; step&quot;</span>)<br>    torch.save(best_state_dict, save_path)<br>    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(total_steps):<br>        <span class="hljs-comment"># Get data</span><br>        <span class="hljs-keyword">try</span>:<br>            batch = <span class="hljs-built_in">next</span>(train_iterator)<br>        excerpt StopIteration:<br>            train_iterator = <span class="hljs-built_in">iter</span>(train_loader)<br>            batch = <span class="hljs-built_in">next</span>(train_iterator)<br><br>        loss, accuracy = model_fn(batch, model, criterion, device)<br>        batch_loss = loss.item()<br>        batch_accuracy = accuracy.item()<br><br>        <span class="hljs-comment"># Updata model</span><br>        loss.backward()<br>        optimizer.step()<br>        scheduler.step()<br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># Log</span><br>        pbar.update()<br>        pbar.set_postfix(<br>            loss=<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;batch_loss:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>,<br>            accuracy=<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;batch_accuracy:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>,<br>            step=step + <span class="hljs-number">1</span>,<br>        )<br><br>        <span class="hljs-comment"># Do validation</span><br>        <span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % valid_steps == <span class="hljs-number">0</span>:<br>            pbar.close()<br>    <br>            valid_accuracy = valid(valid_loader, model, criterion, device)<br><br>            <span class="hljs-comment"># keep the best model</span><br>            <span class="hljs-keyword">if</span> valid_accuracy &gt; best_accuracy:<br>                best_accuracy = valid_accuracy<br>                best_state_dict = model.state_dict()<br><br>            pbar = tqdm(total=valid_steps, ncols=<span class="hljs-number">0</span>, desc=<span class="hljs-string">&quot;Train&quot;</span>, unit=<span class="hljs-string">&quot; step&quot;</span>)<br><br>        <span class="hljs-comment"># Save the best model so far.</span><br>        <span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % save_steps == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> best_state_dict <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            torch.save(best_state_dict, save_path)<br>            pbar.write(<span class="hljs-string">f&quot;Step <span class="hljs-subst">&#123;step + <span class="hljs-number">1</span>&#125;</span>, best model saved. (accuracy=<span class="hljs-subst">&#123;best_accuracy:<span class="hljs-number">.4</span>f&#125;</span>)&quot;</span>)<br><br>    pbar.close()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main(**parse_args())<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;arguments&quot;&quot;&quot;</span><br>    config = &#123;<br>        <span class="hljs-string">&quot;data_dir&quot;</span>: <span class="hljs-string">&quot;/kaggle/input/ml2023springhw4/Dataset&quot;</span>,<br>        <span class="hljs-string">&quot;model_path&quot;</span>: <span class="hljs-string">&quot;/kaggle/working/model.ckpt&quot;</span>,<br>        <span class="hljs-string">&quot;output_path&quot;</span>: <span class="hljs-string">&quot;/kaggle/working/output.csv&quot;</span>,<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> config<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params"></span><br><span class="hljs-params">    data_dir,</span><br><span class="hljs-params">    model_path,</span><br><span class="hljs-params">    output_path,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Main function.&quot;&quot;&quot;</span><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Use <span class="hljs-subst">&#123;device&#125;</span> now!&quot;</span>)<br><br>    mapping_path = Path(data_dir) / <span class="hljs-string">&quot;mapping.json&quot;</span><br>    mapping = json.load(mapping_path.<span class="hljs-built_in">open</span>())<br><br>    dataset = InferenceDataset(data_dir)<br>    dataloader = DataLoader(<br>        dataset,<br>        batch_size=<span class="hljs-number">1</span>,<br>        shuffle=<span class="hljs-literal">False</span>,<br>        drop_last=<span class="hljs-literal">False</span>,<br>        num_workers=<span class="hljs-number">8</span>,<br>        collate_fn=inference_collate_batch,<br>    )<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Finish loading data!&quot;</span>,flush = <span class="hljs-literal">True</span>)<br><br>    speaker_num = <span class="hljs-built_in">len</span>(mapping[<span class="hljs-string">&quot;id2speaker&quot;</span>])<br>    model = Classifier(n_spks=speaker_num).to(device)<br>    model.load_state_dict(torch.load(model_path))<br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;[Info]: Finish creating model!&quot;</span>,flush = <span class="hljs-literal">True</span>)<br><br>    results = [[<span class="hljs-string">&quot;Id&quot;</span>, <span class="hljs-string">&quot;Category&quot;</span>]]<br>    <span class="hljs-keyword">for</span> feat_paths, mels <span class="hljs-keyword">in</span> tqdm(dataloader):<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            mels = mels.to(device)<br>            outs = model(mels)<br>            preds = outs.argmax(<span class="hljs-number">1</span>).cpu().numpy()<br>            <span class="hljs-keyword">for</span> feat_path, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(feat_paths, preds):<br>                results.append([feat_path, mapping[<span class="hljs-string">&quot;id2speaker&quot;</span>][<span class="hljs-built_in">str</span>(pred)]])<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(output_path, <span class="hljs-string">&#x27;w&#x27;</span>, newline=<span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">as</span> csvfile:<br>        writer = csv.writer(csvfile)<br>        writer.writerows(results)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main(**parse_args())<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ---下面就是交数据啦—--</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InferenceDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data_dir</span>):<br>        testdata_path = Path(data_dir) / <span class="hljs-string">&quot;testdata.json&quot;</span><br>        metadata = json.load(testdata_path.<span class="hljs-built_in">open</span>())<br>        <span class="hljs-variable language_">self</span>.data_dir = data_dir<br>        <span class="hljs-variable language_">self</span>.data = metadata[<span class="hljs-string">&quot;utterances&quot;</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        utterance = <span class="hljs-variable language_">self</span>.data[index]<br>        feat_path = utterance[<span class="hljs-string">&quot;feature_path&quot;</span>]<br>        mel = torch.load(os.path.join(<span class="hljs-variable language_">self</span>.data_dir, feat_path))<br><br>        <span class="hljs-keyword">return</span> feat_path, mel<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">inference_collate_batch</span>(<span class="hljs-params">batch</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Collate a batch of data.&quot;&quot;&quot;</span><br>    feat_paths, mels = <span class="hljs-built_in">zip</span>(*batch)<br><br>    <span class="hljs-keyword">return</span> feat_paths, torch.stack(mels)<br>     <br></code></pre></td></tr></table></figure>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/Paper-Medical%20SAM%20Adapter-Adapting%20Segment%20Anything%20Model%20for%20Medical%20Image%20Segmentation/">
                        上一篇：Paper-Medical SAM Adapter-Adapting Segment Anything Model for Medical Image Segmentation
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/ML-%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9C%96%E5%83%8F/">
                        下一篇：ML-李宏毅-機器如何生成圖像
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">121</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">436</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

