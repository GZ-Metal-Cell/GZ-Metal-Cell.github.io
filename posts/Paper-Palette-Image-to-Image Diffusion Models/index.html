<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Paper-Palette-Image-to-Image Diffusion Models | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="论文,生成式网络,">
<meta name="description" content="论文阅读。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/论文"><span>论文</span></a></li>
						
							<li><a href="/tags/生成式网络"><span>生成式网络</span></a></li>
						
					
				</ul>
				
				<h1>Paper-Palette-Image-to-Image Diffusion Models</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>论文阅读。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2022/10/26 08:21:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90" tabindex="-1">相关资源</h1>
<ul>
<li>
<p>原文: [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.05826">2111.05826] Palette: Image-to-Image Diffusion Models (arxiv.org)</a></p>
</li>
<li>
<p>视频解读: <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ze4y1n771/?spm_id_from=333.337.search-card.all.click&amp;vd_source=dc564b163d1e6c5d17c40328d998bddc">【读论文】245 Palette: Image-to-Image Diffusion Models_哔哩哔哩_bilibili</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1P14y187rF">30 分钟带你把【diffusion model】给脱个“精光”！模型解读+代码复现双重出击，直接带你把扩散模型拿捏的死死地！！！-人工智能/扩散模型_哔哩哔哩_bilibili</a></p>
</li>
<li>
<p>github 仓库: <a target="_blank" rel="noopener" href="https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models">Janspiry/Palette-Image-to-Image-Diffusion-Models: Unofficial implementation of Palette: Image-to-Image Diffusion Models by Pytorch (github.com)</a></p>
</li>
</ul>
<h1 id="abstract-%E6%91%98%E8%A6%81" tabindex="-1">ABSTRACT 摘要</h1>
<p>​    这个论文阐述了一个基于<strong>条件扩散模型</strong>的<strong>图像到图像</strong>的统一框架,主要有四个用途:</p>
<ul>
<li>黑白照片上色(Colorization)</li>
</ul>
<p><img src="Colorization.png" alt="png"></p>
<ul>
<li>图像修复(inpainting)</li>
</ul>
<p><img src="Inpainting.png" alt="png"></p>
<ul>
<li>缺失图像补全(uncropping)</li>
</ul>
<p><img src="Uncropping.png" alt="png"></p>
<ul>
<li>JPEG 图像修复(JPEG restoration)</li>
</ul>
<p>![png](JPEG restoration.png)</p>
<hr>
<p>​    我们设计的这个模型优于(outperforms)生成对抗网络(GAN)和基础模型(regression baselines),不需要:</p>
<ul>
<li>
<p>特定于任务(regression baselines)的超参数调优(regression baselines)</p>
</li>
<li>
<p>结构(architecture)定制(customization)</p>
</li>
<li>
<p>任何辅助损失(any auxiliary loss)</p>
</li>
<li>
<p>复杂(sophisticated)的新技术</p>
</li>
</ul>
<hr>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46568930/article/details/115333774?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-115333774-blog-52433975.pc_relevant_3mothn_strategy_and_data_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-115333774-blog-52433975.pc_relevant_3mothn_strategy_and_data_recovery&amp;utm_relevant_index=1">【正则化】—通俗易懂谈正则化：L1 正则化和 L2 正则化_开数据挖掘机的小可爱的博客-CSDN 博客</a></p>
<p>​    我们阐述了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> <strong>正则化</strong>与 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> <strong>正则化</strong>在去噪扩散目标(denoising diffusion objective)在多种样本(sample diversity)中的影响,</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/505105707">Self-attention 自注意力机制讲解 李宏毅版 v.s 吴恩达版 - 知乎 (zhihu.com)</a></p>
<p>​    通过实验研究(empirical studies)证实了<strong>自注意力机制</strong>(self-attention)在神经网络架构(neural architecture)的重要性.</p>
<hr>
<p>​    重要的是, 我们提出了一个基于 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/imagesNet/17752829">ImageNet</a> 的统一评估协议(unified evaluation protocol), 有人工评价(human evaluation)和样本质量分数(sample quality scores)</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40905284/article/details/116541460">FID 图像质量评估指标_csm_81 的博客-CSDN 博客</a></p>
<p>(<strong>FID</strong>,Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images)</p>
<p>​    期待这一评价协议能够在图像间的转换研究(image-to-image translation research)中有用.</p>
<hr>
<p>​    最后,我们展示了这个通用模型(generalist,multi-task diffusion model)比特定于某些任务的模型(task-specific specialist counterparts)效果相当甚至更好.</p>
<hr>
<h1 id="ccs-concepts" tabindex="-1">CCS CONCEPTS</h1>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41971366/article/details/107722049">ACM 投稿时 CCS CONCEPTS 生成及插入_豆浆人的博客-CSDN 博客_ccs concepts</a></p>
<blockquote>
<p>CCS CONCEPTS 这个东西简单来说可以看作一个论文的分类索引，是 ACM 出版论文时论文中必须要附带的东西，一般来说不需要提前放入，等到论文出版时自然会有编辑通知是否需要插入。</p>
</blockquote>
<ul>
<li>计算方法(Computing methodologies)→神经网络(Neural networks)</li>
<li>图像处理(Image processing)</li>
<li>计算机视觉问题(Computer vision problems)</li>
</ul>
<h1 id="keywords-%E5%85%B3%E9%94%AE%E8%AF%8D" tabindex="-1">KEYWORDS 关键词</h1>
<ul>
<li>深度学习(Deep learning)</li>
<li>生成模型(Generative models)</li>
<li>扩散模型(Diffusion models)</li>
</ul>
<h1 id="1-introduction-%E4%BB%8B%E7%BB%8D" tabindex="-1">1 INTRODUCTION 介绍</h1>
<ol>
<li>
<p>许多计算机视觉/图像处理问题可以被归结为图像-图像转换问题:</p>
<ul>
<li>
<p>图像修复(restoration tasks)</p>
</li>
<li>
<p>超分辨率(super-resolution)</p>
</li>
<li>
<p>图像上色(colorization)</p>
</li>
<li>
<p>像素级的图像理解任务(pixel-level image understanding tasks)</p>
<ul>
<li>实例分割(instance segmentation)</li>
<li>深度估计(depth estimation)</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>​    许多问题很复杂,多个<strong>输出图像</strong>对应一个<strong>输入图像</strong>, 一种自然的方法是学习图像的条件分布,使用深度生成模型(deep generative models)可以捕获图像高维空间(high-dimensional space of images)中的多模态分布(multi-modal distributions).</p>
<hr>
<ol start="2">
<li>
<p>GAN 被广泛适用, 然而(Nevertheless)</p>
<ul>
<li>
<p>训练 GAN 会有挑战性</p>
</li>
<li>
<p>会在输出中丢失功能(drop modes)</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zephyr_wang/article/details/126588478">各种生成模型：VAE、GAN、flow、DDPM、autoregressive models_zephyr_wang 的博客-CSDN 博客_生成模型有哪些</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/363615557">normalizing flow - 知乎 (zhihu.com)</a></p>
<p>下列模型在特定应用取得了成功, 但是还没有取得与 GAN 的质量与通用性水平.</p>
<ul>
<li>自回归模型(Autoregressive Models)</li>
<li>变分自编码器(VAEs)</li>
<li>自动化流(Normalizing Flows)</li>
</ul>
</li>
</ol>
<hr>
<ol start="3">
<li>
<p>扩散和基于分数的模型(Diffusion and score-based models)最近备受关注:</p>
<ul>
<li>在连续数据建模(modeling continuous data)方面取得了几个关键进展, 在语音合成(speech synthesis)与目前最好(SoTA)的自回归模型(autoregressive models)<strong>效果相当</strong>.</li>
<li>在类条件(class-conditional)的 ImageNet 生成条件中, 在 FID 得分中<strong>优于</strong>GAN</li>
<li>在图像超分辨率中, 在面部增强(face enhancement)效果中效果优异, (delivered impressive … results)<strong>优于</strong>GAN</li>
</ul>
<p>尽管如此, 尚不明确该模型能否与 GAN 竞争, 为图像处理提供一个通用的框架.</p>
</li>
</ol>
<hr>
<ol start="4">
<li>本文研究了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palettte</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span>​ 的一般适用性.泛用性好, 不用改变超参数(hyper-parameters)和损失函数(loss), 在四大问题(namely colorization, inpainting, uncropping, and JPEG restoration)中输出效果好(delivers high-fidelity outputs)</li>
</ol>
<hr>
<ol start="5">
<li>
<p>我们研究 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 的关键组成部分:</p>
<ul>
<li>去噪损失函数(denoising loss function)</li>
<li>神经网络架构(the neural net architecture)</li>
</ul>
</li>
</ol>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 在去噪目标(denoising objective)的损失函数中产生了类似的样本质量分数(similar sample-quality scores), 导致了模型样本中更高程度的多样性,</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>产生更保守的输出(more conservative outputs) .</p>
<p>我们还发现, 从 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 的 U-Net 架构中移除自我注意层(self-attention layers)建立的完全卷积模型(fully convolutional model)会损失性能.</p>
<p>我们提出了一个基于 ImageNet 的标准化评估协议, 汇报了几个基线的样本质量评分(sample quality scores for several baselines), 我们希望这个基准将有助于 image-to-image translation 的研究.</p>
<h1 id="2-related-work-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C" tabindex="-1">2 RELATED WORK 相关工作</h1>
<ol>
<li>
<p>我们的工作灵感来自于<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38411618">Pix2Pix</a>(对称图像转换（pix2pix，使用对抗损失和重建损失形成输入和输出图像之间的映射。),它基于 GANs 探索无数(myriad)的 image-to-image translation tasks, 基于 GAN 的技术(GAN-based techniques)也被用来解决 image-to-image 问题:</p>
<ul>
<li>
<p>未配对转换(unpaired translation)</p>
</li>
<li>
<p>无监督跨域生成(unsupervised crossdomain generation)<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/fe20d246c83f">Unsupervised Cross-Domain Image Generation - 简书 (jianshu.com)</a></p>
<p>![png](unsupervised crossdomain generation.png)</p>
</li>
<li>
<p>多域转换(multi-domain translation)</p>
</li>
<li>
<p>小样本非监督图像转换模型(few shot translation)</p>
</li>
</ul>
<p>然而, 现有的 GAN 模型有时无法对具有一致结构(consistent structural) 和 纹理规律性(consistent structural) 的图像进行整体翻译.</p>
</li>
</ol>
<hr>
<ol start="2">
<li>扩散模型(Diffusion models)在下列方面取得了令人印象深刻的成果:
<ul>
<li>图像生成(image generation)</li>
<li>音频合成(audio synthesis)</li>
<li>图像超分辨率(image super-resolution)</li>
<li>未配对(unpaired) image-to-image translation</li>
</ul>
</li>
</ol>
<p>​    我们的条件扩散模型建立在这些最新进展的基础上，显示了一套 image-to-image translation 任务的通用性。</p>
<hr>
<ol start="3">
<li>
<ul>
<li>
<p>大多数用于图像修复(inpainting)和其他线性逆问题(linear inverse problems) 都适应了无条件模型(unconditional models)以便在条件任务(conditional tasks)中使用.这样做的好处是只有一个模型需要被训练.</p>
</li>
<li>
<p>然而无条件任务(unconditional tasks)通常比有条件任务(conditional tasks)更难.</p>
</li>
<li>
<p>我们将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 转换为一个条件模型, 如果想要一个用于多个任务的单一模型(single model for multiple tasks), 则选择多任务训练(multitask training).</p>
</li>
</ul>
</li>
</ol>
<hr>
<ol start="4">
<li>
<ul>
<li>
<p>早期的<strong>图像修复</strong>方法(Early <strong>inpainting</strong> approaches)在纹理区域(textured regions)上工作得很好 但 往往无法生成语义一致的结构(often fall short in generating semantically consistent structure)</p>
</li>
<li>
<p>GANs 被广泛使用, 但通常需要辅助:</p>
<ul>
<li>结构(structures)</li>
<li>上下文(context)</li>
<li>边缘(edges)</li>
<li>轮廓(contours)</li>
<li>手工工程特征(hand-engineered features)</li>
</ul>
<p>而且它们的产出缺乏多样性(lack diversity)</p>
</li>
</ul>
</li>
</ol>
<hr>
<ol start="5">
<li>
<ul>
<li><strong>图像补全</strong>(Image uncropping)被认为比图像修复(inpainting)更具挑战性, 因为它需要生成较少上下文(less context)的开放式内容(generating open-ended content).</li>
<li>目前 GAN 占主导地位, 但是局限于特定领域</li>
<li>我们展示了大型数据集(large datasets)上训练的条件扩散模型(conditional diffusion models)可靠地解决了跨图像域的 inpainting 和 uncropping.</li>
</ul>
</li>
</ol>
<hr>
<ol start="6">
<li>
<ul>
<li>
<p><strong>上色</strong>(Colorization)需要一定程度的场景理解(requiring a degree of scene understanding), 使它成为自我监督学习(self-supervised learning)的自然选择(natural choice), 挑战性包括:</p>
<ul>
<li>多样化的色彩(diverse colorization)</li>
<li>尊重语义类别(符合实际情况?)(respecting semantic categories)</li>
<li>产生高质量的颜色(producing high-fidelity color)</li>
</ul>
</li>
<li>
<p>虽然之前的一些工作使用了专门的 auxiliary classification losses, 但我们发现, 在没有 task-specific specialization 的情况下, 通用的 image-to-image diffusion models 做得很好</p>
<hr>
</li>
<li>
<p><strong>JPEG 修复</strong>是去除压缩伪影(removing compression artifacts)的非线性逆问题(nonlinear inverse problem), 使用深度卷积神经网络(deep CNN)架构应用于 JPEG 回复, 将 GANs 应用于伪影去除, 但它们被限制在 10 以上的质量因子.<a target="_blank" rel="noopener" href="https://zhidao.baidu.com/question/478283572.html">问：Photoshop 中 jpg 的品质与 jpg 图像的质量因子之间的关系？急……_百度知道 (baidu.com)</a></p>
<p>我们展示了 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在去除质量因子低至 5 的有效性.</p>
</li>
</ul>
</li>
</ol>
<hr>
<ol start="7">
<li>
<ul>
<li>
<p><strong>多任务训练</strong>(Multi-task training)<a target="_blank" rel="noopener" href="https://blog.csdn.net/u013854886/article/details/38425499">Multi-task learning（多任务学习）简介_MultiMediaGroup_USTC 的博客-CSDN 博客_multi-task learning</a>同时训练多个任务(train simultaneously on multiple tasks),</p>
</li>
<li>
<p>但它们主要专注于增强任务(enhancement tasks):</p>
<ul>
<li>去除模糊(deblurring)</li>
<li>去除噪声(denoising)</li>
<li>超分辨率(super-resolution)</li>
</ul>
<p>它们使用更小的模块化网络(smaller modular networks)</p>
</li>
<li>
<p>一些工作也处理了针对单一任务(a single task)的多种退化模型(multiple degradations)<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41332469/article/details/116423357">RealSR-SR with Multiple Degradations_lpppcccc 的博客-CSDN 博客</a>的同时训练(simultaneous training), e.g.</p>
<ul>
<li>多尺度超分辨率(multi-scale super-resolution)</li>
<li>多重质量因子的 JPEG 恢复(JPEG restoration on multiple quality factors)</li>
</ul>
</li>
<li>
<p>使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span>, 我们迈出了 multi-task image-to-image diffusion models for 各种各样的任务 (a wide variety of tasks) 的第一步.</p>
</li>
</ul>
</li>
</ol>
<h1 id="3-palette" tabindex="-1">3 PALETTE</h1>
<ol>
<li>
<ul>
<li><strong>Diffusion models</strong> 通过迭代去噪过程(iterative denoising process)将标准正态分布(standard Gaussian distribution) 的样本 <em>转换为</em>  经验数据分布的样本(samples from an empirical data distribution)<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/380790564">经验分布函数简介 - 知乎 (zhihu.com)</a></li>
<li><strong>Conditional diffusion models</strong> 去噪过程中以输入信号为条件.</li>
<li><strong>Image-to-image diffusion models</strong> 是以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mrow><mi mathvariant="bold">y</mi></mrow><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">p(\mathbf{y}|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord textstyle uncramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span><span class="mord mathrm">∣</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> 为形式的条件扩散模型, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="bold">y</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.44444em;"></span><span class="strut bottom" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span></span> 都是图像, 例如 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> 是灰度图像, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="bold">y</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.44444em;"></span><span class="strut bottom" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span></span> 是彩色图像(输入灰度图像, 输出彩色图像?)</li>
</ul>
<p>这些模型已经应用于 image super-resolution.</p>
<p>我们研究了图像到图像扩散模型在广泛的任务集上的一般适用性.</p>
</li>
</ol>
<hr>
<ol start="2">
<li>
<ul>
<li>关于 diffusion model 的详细处理, 请参见附录 A, 这里我们简要讨论去噪损失函数</li>
<li>给定一个训练输出图像 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="bold">y</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.44444em;"></span><span class="strut bottom" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span></span>, 我们有一个噪声的版本 $\tilde{\mathbf{y}} $, 然后训练一个神经网络 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.10764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> , 给定 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> 和一个噪声水平指标(noise level indicator) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05556em;">γ</span></span></span></span> 给 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mrow><mi mathvariant="bold">y</mi></mrow></mrow><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{y}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.6813em;"></span><span class="strut bottom" style="height:0.87574em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span><span style="top:-0.36344em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>~</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 降噪, 损失函数是: <img src="loss.png" alt="png"></li>
<li>XX 建议使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 正则化, 即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span>, 而标准的制定是基于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 正则化.</li>
<li>我们认为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 的样本多样性明显低于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, 我们这里采用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 正则化.</li>
</ul>
</li>
</ol>
<hr>
<ol start="3">
<li>
<ul>
<li>
<p><strong>结构</strong>(Architecture):</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 基于 U-Net 结构</li>
<li>网格架构(network architecture)<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>5</mn><mn>6</mn><mo>×</mo><mn>2</mn><mn>5</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">256\times 256</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">6</span></span></span></span> 类条件 U-Net 模型</li>
</ul>
<p>两者区别:</p>
<ul>
<li>缺少类条件反射(absence of class-conditioning)</li>
<li>通过连接对原图像进行额外的条件反射(additional conditioning of the source image via concatenation)</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="4-evaluation-protocol-%E8%AF%84%E4%BC%B0%E5%8D%8F%E8%AE%AE" tabindex="-1">4 EVALUATION PROTOCOL 评估协议</h1>
<ol>
<li>
<ul>
<li>Colorization 之前的工作依赖于 FID 评分 和 人类评价 进行模型比较(model comparison)</li>
<li>Inpainting 和 UnCropping 往往严重依赖 定性评价(qualitative evaluation)</li>
<li>对于其他任务, 如 JPEG restoration, 通常使用基于参考的像素级相似度评分(reference-based pixel-level similarity scores), 如  <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/psnr/2925132">PSNR</a> 和 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/SSIM/2091025">SSIM</a></li>
<li>同样注意的是, 许多任务缺乏用于评估的标准化数据集(standardized dataset for evaluation), 例如，不同测试集具有方法特定的分割(method-specific splits)进行评估。</li>
</ul>
</li>
</ol>
<hr>
<ol start="2">
<li>
<ul>
<li>鉴于 ImageNet 的规模(scale), 多样性(diversity)和公共可用性(public availability), 我们提出了一种统一的评估协议, 用于在 ImageNet 上进行 inpainting, uncropping, JPEG restoration.</li>
<li>对于 inpainting 和 uncropping 现有的工作依赖 <a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_28442665/article/details/110933850">Places2</a> 进行评估, 因此我们还在 Places2 上为这些任务使用标准的评估设置(standard evaluation setup).</li>
<li>具体来说，我们主张使用 <a target="_blank" rel="noopener" href="https://paperswithcode.com/sota/colorization-on-imagenet-ctest10k">ImageNet ctest10k split</a> 作为 ImageNet 上所有 image-to-image translation tasks 的基准测试的标准子集, 还引入了 <a target="_blank" rel="noopener" href="https://github.com/romkatv/powerlevel10k">places10k</a>。</li>
<li>除了受控的人工评估外(in addition to controlled human evaluation), 我们进一步提倡使用自动度量(automated metrics)来捕获图像质量和多样性</li>
<li>避免使用 PSNR 和 SSIM 这样的像素级指标(倾向于选择模糊回归输出 blurry regression outputs, 不像人类的感知 unlike human perception), 对于需要幻觉?(hallucination)的困难任务, 比如 super-resolution work, 它们不是可靠的样本质量衡量标准.</li>
</ul>
</li>
</ol>
<hr>
<ol start="4">
<li>
<ul>
<li>
<p>对于 image-to-image translation, 我们用四个方式量化:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/263652288"><strong>Inception Score (IS)</strong></a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013043762/article/details/115908872"><strong>Fréchet Inception Distance (FID)</strong></a></li>
<li>预训练 ResNet-50 分类器 (pre-trained ResNet-50 classifier) 的 <a target="_blank" rel="noopener" href="https://blog.csdn.net/ChenglinBen/article/details/95449445"><strong>Classification Accuracy (CA)</strong></a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/206470186"><strong>Perceptual Distance (PD)</strong></a>的简单测量方法, 即, Inception-v1 特征空间中的欧氏距离</li>
</ul>
<p>其他参见附录 C.5</p>
<p>对于某些任务, 通过多个模型输出之间的成对的 SSIM 和 LPIPS 评分来评估<strong>样本多样性</strong>(sample diversity).</p>
</li>
</ul>
</li>
</ol>
<hr>
<ol start="5">
<li>最终评价还是<strong>人的评价</strong>(human evaluation), 根据<strong>愚弄率</strong>(fool rate)总结结果, 即当被问及“你猜哪个图像来自相机?”时，人类评分者选择模型输出而不是自然图像的百分比。(附录 C)</li>
</ol>
<h1 id="5-experiments-%E5%AE%9E%E9%AA%8C" tabindex="-1">5 EXPERIMENTS 实验</h1>
<p>我们将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 用于: <strong>Colorization</strong>, <strong>Inpainting</strong>, <strong>Uncropping</strong>, <strong>JPEG restoration</strong></p>
<p>我们不需要:</p>
<ul>
<li>特定于任务的超参数调优(task-specific hyper-parameter tuning)</li>
<li>体系结构定制(architecture customization)</li>
<li>任何辅助损失函数(any auxiliary loss function)</li>
</ul>
<p>所有任务的输入和输出都表示为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mn>5</mn><mn>6</mn><mo>×</mo><mn>2</mn><mn>5</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">256\times 256</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">6</span></span></span></span> RGB 图像, 每项任务都具有独特的挑战:</p>
<ul>
<li>
<p>Colorization:</p>
<ul>
<li>对对象进行表示(representation of objects)</li>
<li>分割(segmentation)</li>
<li>布局(layout)</li>
<li>具有长期的图像依赖性(with long-range image dependencies)</li>
</ul>
</li>
<li>
<p>Inpainting:</p>
<ul>
<li>大图(large masks)</li>
<li>图像杂乱的场景(image diversity and cluttered scenes)</li>
</ul>
</li>
<li>
<p>Uncropping</p>
<ul>
<li>比 Inpainting 更具挑战性, 周围环境很少约束语义意义的生成(less surrounding
context to constrain semantically meaningful generation)</li>
</ul>
</li>
<li>
<p>JPEG restoration</p>
<ul>
<li>一个非线性的逆问题(non-linear inverse problem)</li>
<li>需要一个良好的自然统计局部模型(a good local model of natural image statistics)来检测(detect)和纠正压缩伪影(correct compression artifacts)</li>
</ul>
</li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 损失作为去噪目标, 除非单独声明(unless otherwises pecified)(附录 B)</p>
<h2 id="5.1-colorization" tabindex="-1" id="5-1-Colorization">5.1 Colorization</h2>
<ul>
<li>
<p>之前的工作采用 [LAB](<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/Lab">https://baike.baidu.com/item/Lab</a> 色彩空间/6833664) 或 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/YCbCr/10012133">YCbCr</a> 颜色空间来表示输出图像进行 Colorization, 而我们使用 RGB 颜色空间来保持任务间的通用性(maintain generality across tasks), 但是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在 YCbCr 和 RGB 颜色空间中同样有效.</p>
</li>
<li>
<p>我们将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 与 PixColor 和 ColTran 进行比较:</p>
<p><img src="figure3.png" alt="png"></p>
<ul>
<li>量化得分:</li>
</ul>
<p><img src="table1.png" alt="png"></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 建立了一个新的 SoTA, FID, IS 和 CA 表面, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 输出与用于创建测试灰度输入的原始图像 (test greyscale inputs) 几乎无法区分.有着接近 50% 的理想欺骗率(ideal fool rate).</li>
</ul>
</li>
</ul>
<h2 id="5.2-inpainting" tabindex="-1" id="5-2-Inpainting">5.2 Inpainting</h2>
<ul>
<li>
<p>我们在自由形式生成的蒙版(free-form generated masks)上训练嵌入 inpainting 模型, 用简单的矩形模板(simple rectangular masks)进行增强.</p>
</li>
<li>
<p>为了在任务间保持 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 的通用性(generality), 我们没有向模型传递二进制 inpainting mask, 我们用标准的高斯噪声填充 masked region 以 兼容去噪扩散模型(compatible with denoising diffusion models), 训练损耗只考虑被遮蔽的像素, 而不是整个图像, 以加速训练.</p>
</li>
<li>
<p>我们将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 与 DeepFillv2 , Photoshop 的感知填充, Co-ModGAN 进行比较, 结果比它们都好(附录 C.2)</p>
</li>
</ul>
<p><img src="table2.png" alt="png"></p>
<h2 id="5.3-uncropping" tabindex="-1" id="5-3-Uncropping">5.3 Uncropping</h2>
<ul>
<li>
<p>我们训练 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在四个方向中的任意一个方向上 Uncropping, 或者在四面的整个图像边界上 Uncropping.</p>
</li>
<li>
<p>在所有情况下, 我们都保留 masked region 为源图像的 50%.</p>
</li>
<li>
<p>像 inpainting 一样, 我们用 Gussian noise 填充 masked region, 并在推理过程(inference)中保持 unmasked region 不变.</p>
</li>
<li>
<p>我们将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 与 Boundless 和 InfinityGAN 比较.</p>
</li>
</ul>
<p><img src="table3.png" alt="png"></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Paletee</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">e</span><span class="mord mathit">e</span></span></span></span> 具有惊人的鲁棒性:</li>
</ul>
<p><img src="figure2.png" alt="png"></p>
<h2 id="5.4-jpeg-restoration" tabindex="-1" id="5-4-JPEG-restoration">5.4 JPEG restoration</h2>
<ul>
<li>
<p>尽管之前的工作限制自身的质量因子 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">\ge</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.63597em;"></span><span class="strut bottom" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="base textstyle uncramped"><span class="mrel">≥</span></span></span></span> 10, 但我们这次训练质量因子低至 5</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在所有质量因素上都表现出很强的性能, 优于 regression baseline.(比其产生更清晰的图像.)</p>
</li>
</ul>
<p><img src="table4.png" alt="png"></p>
<h2 id="5.5-self-attention-in-diffusion-model-architectures" tabindex="-1" id="5-5-Self-attention-in-diffusion-model-architectures">5.5 Self-attention in diffusion model architectures</h2>
<ul>
<li>
<p>Self-attention layers 一直是用于 diffusion models 的 U-Net 架构的重要组成部分</p>
</li>
<li>
<p>虽然 self-attention layers 提供了一种直接的全局依赖形式(direct form of global dependency), 但它们阻止了对不可见图像分辨率的泛化(prevent generalization to unseen image resolutions)</p>
</li>
<li>
<p>对于 image-to-image tasks, 在测试时泛化到新的分辨率是方便的, 因此之前的工作依赖于完全卷积的体系结构(fully convolutional architectures)</p>
</li>
<li>
<p>我们分析了 self-attention layers 对 inpainting 样本质量的影响, inpainting 是 image-to-image tasks 中比较困难的之一.</p>
</li>
<li>
<p>为了支持 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 的输入分辨率泛化, 我们探索用不同的备选方案替换 global self-attention layers, 每个备选方案都代表了 大上下文依赖性(large context dependency) 和 分辨率的健壮性(resolution robustness) 的均衡:</p>
<ul>
<li><strong>Global Self-Attention</strong>: 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mn>2</mn><mo>×</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">32\times 32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mord mathrm">2</span><span class="mbin">×</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>6</mn><mo>×</mo><mn>1</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">16\times 16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord mathrm">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">8</span><span class="mbin">×</span><span class="mord mathrm">8</span></span></span></span> 分辨率上使用 Global Self-Attention 的基线配置(Baseline configuration).</li>
<li><strong>Local Self-Attention</strong>: 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mn>2</mn><mo>×</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">32\times 32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mord mathrm">2</span><span class="mbin">×</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>6</mn><mo>×</mo><mn>1</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">16\times 16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord mathrm">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">8</span><span class="mbin">×</span><span class="mord mathrm">8</span></span></span></span> 分辨率上, 将特征图划分为 4 个不重叠的查询块.</li>
<li><strong>More ResNet Blocks w/o Self-Attention</strong>: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">2\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mbin">×</span></span></span></span> residual blocks  在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mn>2</mn><mo>×</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">32\times 32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mord mathrm">2</span><span class="mbin">×</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>6</mn><mo>×</mo><mn>1</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">16\times 16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord mathrm">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">8</span><span class="mbin">×</span><span class="mord mathrm">8</span></span></span></span> 分辨率上允许更深的卷积(deeper convolutions) 增加接受域大小(increase receptive field sizes).</li>
<li>没有自我注意的膨胀卷积(<strong>Dilated Convolutions w/o Self-Attention</strong>): 类似于 More ResNet Blocks w/o Self-Attention, ResNet 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mn>2</mn><mo>×</mo><mn>3</mn><mn>2</mn></mrow><annotation encoding="application/x-tex">32\times 32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mord mathrm">2</span><span class="mbin">×</span><span class="mord mathrm">3</span><span class="mord mathrm">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mn>6</mn><mo>×</mo><mn>1</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">16\times 16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">6</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord mathrm">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">8</span><span class="mbin">×</span><span class="mord mathrm">8</span></span></span></span> 分辨率上阻塞, 扩张率不断增加, 允许接受视野呈指数增长.</li>
</ul>
</li>
<li>
<p>训练效率:</p>
</li>
</ul>
<p><img src="table5.png" alt="png"></p>
<h2 id="5.6-sample-diversity-%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%A4%9A%E6%A0%B7%E6%80%A7" tabindex="-1" id="5-6-Sample-diversity-样本的多样性">5.6 Sample diversity 样本的多样性</h2>
<ul>
<li>分析 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在 colorization 和 inpainting 两个任务中的 sample diversity, 具体地, 我们分析了扩散损失函数(diffusion loss function) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{simple}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit">m</span><span class="mord mathit">p</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, 比较 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 对样本多样性的影响.</li>
<li>现有的 conditional diffusion models, SR3, wavegard 发现 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 正则化比 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> loss 表现更好.</li>
<li>为了定量比较样本多样性, 我们使用 multi-scale 和 LPIPS 多样性评分</li>
</ul>
<p><img src="table6.png" alt="png"></p>
<h2 id="5.7-multi-task-learning-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0" tabindex="-1" id="5-7-Multi-task-learning-多任务学习">5.7 Multi-task learning 多任务学习</h2>
<ul>
<li>
<p>多任务训练是学习单一模型(learning a single model)进行多个 image-to-image 任务, 即盲图像增强</p>
</li>
<li>
<p>另一种是将无条件模型(unconditional model) 应用于具有归责性(imputation)的条件任务(conditional tasks)</p>
<ul>
<li>
<p>例如 inpainting:</p>
<p>在迭代细化的每一步中, 他们去噪来自上一步的噪声图像, 然后简单地用观察到的图像区域的像素替换估计图像(estimated image) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="bold">y</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.44444em;"></span><span class="strut bottom" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span></span>, 然后添加噪声并进行下一个去噪迭代(next denoising iteration).</p>
</li>
</ul>
</li>
<li>
<p>下图将此方法针对所有四个任务训练的多任务 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 模型 和仅针对 inpainting 训练的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 模型进行比较, 所有模型都使用相同的体系结构(architecture), 训练数据(training data)和训练步骤的数量(number of training steps)</p>
</li>
</ul>
<p><img src="figure9.png" alt="png"></p>
<ul>
<li>为了更深入地探索多任务模型的潜力, 下表提供了同时训练 JPEG restoration, inpainting 和 colorization, 这表明 multi-task generalist <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 优于 task-specific <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span>  models, 但是 inpainting 和 colorization 略微(slightly)落后于 task-specific <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span>  models.</li>
<li>我们希望通过更多的 training 来提高多任务处理能力(multi-task performance)</li>
</ul>
<h1 id="6-conclusion" tabindex="-1">6 CONCLUSION</h1>
<p>​    <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>a</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Palette</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">e</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span></span></span></span> 在四个具有挑战性的问题上取得了很好的结果.</p>
<h1 id="acknowledgments-%E8%87%B4%E8%B0%A2" tabindex="-1">Acknowledgments 致谢</h1>
<h1 id="references-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE" tabindex="-1">REFERENCES 参考文献</h1>
<h1 id="%E9%99%84%E5%BD%95" tabindex="-1">附录</h1>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/DIP-Introductory%20python%20tutorials%20for%20image%20processing(1-21)-Python%20Basics/">
                        上一篇：DIP-Introductory python tutorials for image processing(1-21)-Python Basics
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/Theory-%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA%E5%AF%BC%E5%BC%952/">
                        下一篇：Theory-计算理论导引2
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">122</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">438</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	
		
			
				<link rel="stylesheet" href="/css/plugins/katex/katex.min.css">
				<script src="/js/plugins/copy-tex.js"></script>
			
		
	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

