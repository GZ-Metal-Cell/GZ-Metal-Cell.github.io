<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Pytorch-深度学习快速入门教程（绝对通俗易懂！）【小土堆】 | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="Python,Pytorch,小土堆,">
<meta name="description" content="学习自 B 站 UP 主 我是土堆。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/Python"><span>Python</span></a></li>
						
							<li><a href="/tags/Pytorch"><span>Pytorch</span></a></li>
						
							<li><a href="/tags/小土堆"><span>小土堆</span></a></li>
						
					
				</ul>
				
				<h1>Pytorch-深度学习快速入门教程（绝对通俗易懂！）【小土堆】</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>学习自 B 站 UP 主 我是土堆。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2023/03/27 19:08:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="%E8%A7%86%E9%A2%91" tabindex="-1">视频</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1hE411t7RN">PyTorch 深度学习快速入门教程（绝对通俗易懂！）【小土堆】_哔哩哔哩_bilibili</a></li>
</ul>
<h1 id="%E8%AF%BE%E7%A8%8B" tabindex="-1">课程</h1>
<h2 id="python-%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%A4%E5%A4%A7%E6%B3%95%E5%AE%9D%E5%87%BD%E6%95%B0%EF%BC%88%E5%BD%93%E7%84%B6%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%94%A8%E5%9C%A8-pytorch%EF%BC%89" tabindex="-1" id="Python-学习中的两大法宝函数（当然也可以用在-PyTorch）">Python 学习中的两大法宝函数（当然也可以用在 PyTorch）</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">help</span>(Dataset)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Dataset??<br></code></pre></td></tr></table></figure>
<h2 id="pytorch-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%9D%E8%AE%A4%E8%AF%86" tabindex="-1" id="PyTorch-加载数据初认识">PyTorch 加载数据初认识</h2>
<p><code>Pytorch</code> 有两个类:</p>
<ul>
<li><code>Dataset</code>: 提供一种方式去获取数据及其标签
<ul>
<li>如何获取每一个数据及其标签</li>
<li>告诉我们总共有多少数据</li>
</ul>
</li>
<li><code>Dataloader</code>: 为后面的网络提供不同的数据形式</li>
</ul>
<h2 id="dataset-%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98" tabindex="-1" id="Dataset-类代码实战">Dataset 类代码实战</h2>
<p><img src="6_1.png" alt="png"></p>
<p>​    下载了数据包，是一个蚂蚁和蜜蜂的二分类问题。训练集根目录为 <code>dataset/train</code>，标签有 <code>ants</code> 和 <code>bees</code>。</p>
<p>​    设计一个类 <code>MyData</code>，负责读取数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, root_dir, label_dir</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化</span><br><span class="hljs-string">        :param root_dir: 根目录</span><br><span class="hljs-string">        :param label_dir: 标签目录</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-variable language_">self</span>.root_dir = root_dir<br>        <span class="hljs-variable language_">self</span>.label_dir = label_dir<br>        <span class="hljs-variable language_">self</span>.path = os.path.join(<span class="hljs-variable language_">self</span>.root_dir, <span class="hljs-variable language_">self</span>.label_dir)<br>        <span class="hljs-variable language_">self</span>.img_path = os.listdir(<span class="hljs-variable language_">self</span>.path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        获取对象</span><br><span class="hljs-string">        :param idx: 索引</span><br><span class="hljs-string">        :return:</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        img_name = <span class="hljs-variable language_">self</span>.img_path[idx]<br>        img_item_path = os.path.join(<span class="hljs-variable language_">self</span>.root_dir, <span class="hljs-variable language_">self</span>.label_dir, img_name)<br>        img = Image.<span class="hljs-built_in">open</span>(img_item_path)<br>        label = <span class="hljs-variable language_">self</span>.label_dir<br>        <span class="hljs-keyword">return</span> img, label<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.img_path)<br><br><br>root_dir = <span class="hljs-string">&quot;dataset/train&quot;</span><br>ants_label_dir = <span class="hljs-string">&quot;ants&quot;</span><br>bees_label_dir = <span class="hljs-string">&quot;bees&quot;</span><br>ants_dataset = MyData(root_dir, ants_label_dir)<br>bees_dataset = MyData(root_dir, bees_label_dir)<br></code></pre></td></tr></table></figure>
<h2 id="tensorboard-%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89" tabindex="-1" id="TensorBoard-的使用（一）">TensorBoard 的使用（一）</h2>
<p>使用 pytorch 的 <code>tensorboard</code> 在网页端显示函数图像 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mn>2</mn><mi>x</mi></mrow><annotation encoding="application/x-tex">y=2x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord mathrm">2</span><span class="mord mathit">x</span></span></span></span>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=2x&quot;</span>, <span class="hljs-number">2</span> * i, i)<br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p>在 shell 端口中 <code>tensorboard --logdir=logs</code>：（启动 tensorboard，logdir 目录为 <code>logs</code>）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">PS D:\Study\1st-year-master\XiaoTuDui\Test&gt; tensorboard --logdir=logs<br>Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all<br>TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)<br></code></pre></td></tr></table></figure>
<p><img src="7_1.png" alt="png"></p>
<p>如果两段 <code>writer.add_scalar</code> 名称相同，可能会出现一张图像混合形成两张图像的情况，可以考虑清除项目中 <code>logs/</code> 的缓存刷新。</p>
<h2 id="tensorboard-%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89" tabindex="-1" id="TensorBoard-的使用（二）">TensorBoard 的使用（二）</h2>
<p>主要讲了 <code>writer.add_image</code> 的用法。</p>
<blockquote>
<pre><code>def add_image(
    self, tag, img_tensor, global_step=None, walltime=None, dataformats=&quot;CHW&quot;
):
    &quot;&quot;&quot;Add image data to summary.

    Note that this requires the ``pillow`` package.
                                    
    Args:
        tag (str): Data identifier
        img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data
        global_step (int): Global step value to record
        walltime (float): Optional override default walltime (time.time())
          seconds after epoch of event
        dataformats (str): Image data format specification of the form
          CHW, HWC, HW, WH, etc.
    Shape:
        img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to
        convert a batch of tensor into 3xHxW format or call ``add_images`` and let us do the job.
        Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitable as long as
        corresponding ``dataformats`` argument is passed, e.g. ``CHW``, ``HWC``, ``HW``.
                                    
    Examples::
                                    
        from torch.utils.tensorboard import SummaryWriter
        import numpy as np
        img = np.zeros((3, 100, 100))
        img[0] = np.arange(0, 10000).reshape(100, 100) / 10000
        img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000
                                    
        img_HWC = np.zeros((100, 100, 3))
        img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000
        img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000
                                    
        writer = SummaryWriter()
        writer.add_image('my_image', img, 0)
                                    
        # If you have non-default dimension setting, set the dataformats argument.
        writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')
        writer.close()
                                    
    Expected result:
                                    
    .. image:: _static/img/tensorboard/add_image.png
       :scale: 50%
                                    
    &quot;&quot;&quot;
</code></pre>
</blockquote>
<p>​    从 PIL 到 numpy，需要在 <code>add_image()</code> 中指定 shape 中每一个数字/维表示的含义。<code>dataformats=&quot;HWC&quot;</code>（高、宽、通道数）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>image_path = <span class="hljs-string">r&quot;dataset\train\ants\0013035.jpg&quot;</span><br>img_PIL = Image.<span class="hljs-built_in">open</span>(image_path)<br>img_array = np.array(img_PIL)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img_array))<br><span class="hljs-built_in">print</span>(img_array.shape)<br><br>writer.add_image(<span class="hljs-string">&quot;test&quot;</span>, img_array, <span class="hljs-number">2</span>, dataformats=<span class="hljs-string">&quot;HWC&quot;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=2x&quot;</span>, <span class="hljs-number">2</span> * i, i)<br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p><img src="8_1.png" alt="png"></p>
<h2 id="transforms-%E7%9A%84%E4%BD%BF%E7%94%A8" tabindex="-1" id="Transforms-的使用">Transforms 的使用</h2>
<p>transforms 是一个工具包，读入图片经过 transforms 后产生结果。</p>
<p>如 <code>transforms.ToTensor()</code> 将 Image 格式转换成 tensor 格式。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>img_path = <span class="hljs-string">r&quot;dataset/train/ants/0013035.jpg&quot;</span><br>img = Image.<span class="hljs-built_in">open</span>(img_path)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br><br><span class="hljs-comment"># transforms 该如何被使用</span><br>tensor_trans = transforms.ToTensor()<br>tensor_img = tensor_trans(img)<br><br><span class="hljs-built_in">print</span>(tensor_img)<br><br>writer.add_image(<span class="hljs-string">&quot;Tensor_img&quot;</span>, tensor_img)<br><br>writer.close()<br></code></pre></td></tr></table></figure>
<h2 id="%E5%B8%B8%E8%A7%81%E7%9A%84-transforms%EF%BC%88%E4%B8%80%EF%BC%89" tabindex="-1" id="常见的-Transforms（一）">常见的 Transforms（一）</h2>
<p>讲了 <code>transforms.Normalize</code> 的用法。</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">class Normalize(torch.nn.Module):<br>    &quot;&quot;&quot;Normalize a tensor image with mean and standard deviation. 使用平均值和标准偏差归一化张量图像<br>    This transform does not support PIL Image.<br>    Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``<br>    channels, this transform will normalize each channel of the input<br>    ``torch.*Tensor`` i.e.,<br>    ``output[channel] = (input[channel] - mean[channel]) / std[channel]``<br><br>    .. note::<br>        This transform acts out of place, i.e., it does not mutate the input tensor.<br><br>    Args:<br>        mean (sequence): Sequence of means for each channel.<br>        std (sequence): Sequence of standard deviations for each channel.<br>        inplace(bool,optional): Bool to make this operation in-place.<br><br>    &quot;&quot;&quot;<br></code></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;images/pytorch.png&quot;</span>)<br><span class="hljs-built_in">print</span>(img)<br><br><span class="hljs-comment"># ToTensor</span><br>trans_totensor = transforms.ToTensor()<br>img_tensor = trans_totensor(img)<br>writer.add_image(<span class="hljs-string">&quot;ToTensor&quot;</span>, img_tensor)<br><br><span class="hljs-comment"># Normalize</span><br><span class="hljs-built_in">print</span>(img_tensor[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br>trans_norm = transforms.Normalize([<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">9</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>])<br>img_norm = trans_norm(img_tensor)<br><span class="hljs-built_in">print</span>(img_norm[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br>writer.add_image(<span class="hljs-string">&quot;Normalize&quot;</span>, img_norm, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p><img src="12_1.png" alt="png"></p>
<h2 id="%E5%B8%B8%E8%A7%81%E7%9A%84-transforms%EF%BC%88%E4%BA%8C%EF%BC%89" tabindex="-1" id="常见的-Transforms（二）">常见的 Transforms（二）</h2>
<p><code>Resize</code> 调整图像大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Resize</span><br><span class="hljs-built_in">print</span>(img.size)<br>trans_resize = transforms.Resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))<br><span class="hljs-comment"># img PIL -&gt; resize -&gt; img_resize PIL</span><br>img_resize = trans_resize(img)<br><span class="hljs-comment"># img_resize PIL -&gt; totensor -&gt; img_resize tensor</span><br>img_resize = trans_totensor(img_resize)<br>writer.add_image(<span class="hljs-string">&quot;Resize&quot;</span>, img_resize, <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(img_resize)<br></code></pre></td></tr></table></figure>
<p><img src="13_1.png" alt="png"></p>
<hr>
<p><code>Compose</code>: 将transforms列表里面的transform操作进行遍历。</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">class Compose:<br>    &quot;&quot;&quot;Composes several transforms together. This transform does not support torchscript.<br>    Please, see the note below.<br><br>    Args:<br>        transforms (list of ``Transform`` objects): list of transforms to compose.<br><br>    Example:<br>        &gt;&gt;&gt; transforms.Compose([<br>        &gt;&gt;&gt;     transforms.CenterCrop(10),<br>        &gt;&gt;&gt;     transforms.PILToTensor(),<br>        &gt;&gt;&gt;     transforms.ConvertImageDtype(torch.float),<br>        &gt;&gt;&gt; ])<br><br>    .. note::<br>        In order to script the transformations, please use ``torch.nn.Sequential`` as below.<br><br>        &gt;&gt;&gt; transforms = torch.nn.Sequential(<br>        &gt;&gt;&gt;     transforms.CenterCrop(10),<br>        &gt;&gt;&gt;     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),<br>        &gt;&gt;&gt; )<br>        &gt;&gt;&gt; scripted_transforms = torch.jit.script(transforms)<br><br>        Make sure to use only scriptable transformations, i.e. that work with ``torch.Tensor``, does not require<br>        `lambda` functions or ``PIL.Image``.<br><br>    &quot;&quot;&quot;<br></code></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Compose - resize - 2</span><br>trans_resize_2 = transforms.Resize(<span class="hljs-number">512</span>)<br><span class="hljs-comment"># PIL -&gt; PIL -&gt; tensor</span><br>trans_compose = transforms.Compose([trans_resize_2, trans_totensor])<br>img_resize_2 = trans_compose(img)<br>writer.add_image(<span class="hljs-string">&quot;Resize&quot;</span>, img_resize_2, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>​    相当于先缩放 <code>trans_resize_2</code>，再转换成 tensor 类型 <code>trans_totensor</code>。</p>
<hr>
<p><code>RandomCrop</code> 随机裁剪</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># RandomCrop</span><br>trans_random = transforms.RandomCrop([<span class="hljs-number">32</span>, <span class="hljs-number">64</span>])<br>trans_compose_2 = transforms.Compose([trans_random, trans_totensor])<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    img_crop = trans_compose_2(img)<br>    writer.add_image(<span class="hljs-string">&quot;RandomCropHW&quot;</span>, img_crop, i)<br></code></pre></td></tr></table></figure>
<p><img src="13_2.png" alt="png"></p>
<h2 id="torchvision-%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8" tabindex="-1" id="torchvision-中的数据集使用">torchvision 中的数据集使用</h2>
<p>​    在官网上查看 torchvision.datasets 的用法</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://pytorch.org/vision/stable/datasets.html">Datasets — Torchvision 0.15 documentation (pytorch.org)</a></li>
</ul>
<p>​    选用 <code>CIFAR10</code> 数据集，读入 <code>train_set</code> 和 <code>test_set</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">train_set = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">True</span>, transform=dataset_transform, download=<span class="hljs-literal">True</span>)<br>test_set = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=dataset_transform, download=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>​    如果选择 <code>download=True</code>，会检查并验证 <code>root</code> 中是否存在数据集且是否完整，若没有，则会下载：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">C:\Users\gzjzx\anaconda3\python.exe D:/Study/1st-year-master/XiaoTuDui/Test/P10_dataset_transform.py<br>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset\cifar-10-python.tar.gz<br>  1%|          | 1114112/170498071 [00:40&lt;48:11, 58582.60it/s]<br></code></pre></td></tr></table></figure>
<p>​    可以将网址 <a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a> 复制到迅雷中由训练代下载，速度会快，将下载好的数据库拷贝回去。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Using downloaded and verified file: ./dataset\cifar-10-python.tar.gz<br>Extracting ./dataset\cifar-10-python.tar.gz to ./dataset<br>Files already downloaded and verified<br></code></pre></td></tr></table></figure>
<p>​    根据官网 <a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 and CIFAR-100 datasets (toronto.edu)</a> 对数据库的描述，查看数据信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(test_set[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(test_set.classes)<br><br>img, target = test_set[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(img)<br><span class="hljs-built_in">print</span>(target)<br><span class="hljs-built_in">print</span>(test_set.classes[target])<br><span class="hljs-comment"># img.show()</span><br><span class="hljs-built_in">print</span>(test_set[<span class="hljs-number">0</span>])<br><br><span class="hljs-comment"># 在 TensorBoard 中查看数据集中前 10 张图</span><br>writer = SummaryWriter(<span class="hljs-string">&quot;p10&quot;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    img, target = test_set[i]<br>    writer.add_image(<span class="hljs-string">&quot;test_set&quot;</span>, img, i)<br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p><img src="14_1.png" alt="png"></p>
<h2 id="dataloader-%E7%9A%84%E4%BD%BF%E7%94%A8" tabindex="-1" id="DataLoader-的使用">DataLoader 的使用</h2>
<p><img src="15_1.png" alt="png"></p>
<ul>
<li><code>Pytorch</code> 有两个类:
<ul>
<li><code>Dataset</code>: 提供一种方式去获取数据及其标签
<ul>
<li>如何获取每一个数据及其标签</li>
<li>告诉我们总共有多少数据</li>
</ul>
</li>
<li><code>DataLoader</code>: 为后面的网络提供不同的数据形式</li>
</ul>
</li>
</ul>
<hr>
<p><code>DataLoader</code> 的使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment"># 准备的测试数据集</span><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor())<br><br>test_loader = DataLoader(dataset=test_data, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, drop_last=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 测试数据集中第一张图片及 target</span><br>img, target = test_data[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(img.shape)<br><span class="hljs-built_in">print</span>(target)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;dataloader&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>    imgs, targets = data<br>    <span class="hljs-comment"># print(imgs.shape)</span><br>    <span class="hljs-comment"># print(targets)</span><br>    writer.add_images(<span class="hljs-string">&quot;test_data&quot;</span>, imgs, step)<br>    step += <span class="hljs-number">1</span><br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p><code>test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=0, drop_last=False)</code></p>
<ul>
<li><code>dataset=test_data</code>，读入 <code>test_data</code> 的数据集</li>
<li><code>batch_size=4</code>，每次读入 4 张图片</li>
<li><code>shuffle=True</code>，打乱图片顺序</li>
<li><code>drop_last=False</code>，数据集数量如果不能被 batch_size 整除，要丢弃最后一块吗？否</li>
</ul>
<p><img src="15_2.png" alt="png"></p>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6-nn.module%E7%9A%84%E4%BD%BF%E7%94%A8" tabindex="-1" id="神经网络的基本骨架-nn-Module的使用">神经网络的基本骨架-nn.Module的使用</h2>
<p>​    查看帮助文档：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html?highlight=torch+nn#module-torch.nn">torch.nn — PyTorch 2.0 documentation</a></li>
</ul>
<p>​    对于神经网络的前向传播，input-forward-output, 自行设计一个神经网络的类，继承 <code>nn.Moudle</code>：初始化时，<code>super(Model, self).__init__()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Model, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(<span class="hljs-variable language_">self</span>.conv1(x))<br>        <span class="hljs-keyword">return</span> F.relu(<span class="hljs-variable language_">self</span>.conv2(x))<br></code></pre></td></tr></table></figure>
<hr>
<p>​    设计一个最简单的函数，让 output 为 input 的加 1：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-built_in">input</span> + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> output<br><br>myClass = MyClass()<br><span class="hljs-built_in">input</span> = torch.tensor(<span class="hljs-number">1.0</span>)<br>output = myClass(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor(<span class="hljs-number">2.</span>)<br></code></pre></td></tr></table></figure>
<h2 id="%E5%9C%9F%E5%A0%86%E8%AF%B4%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%EF%BC%88%E5%8F%AF%E9%80%89%E7%9C%8B%EF%BC%89" tabindex="-1" id="土堆说卷积操作（可选看）">土堆说卷积操作（可选看）</h2>
<p>​    大概讲了卷积操作 <code>torch.nn.functional.conv2d</code>，<code>stride</code> 和 <code>padding</code> 的含义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                      [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><br>kernel = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>                       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>                       [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>kernel = torch.reshape(kernel, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><span class="hljs-built_in">print</span>(kernel.shape)<br><br>output = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(output)<br><br>output2 = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(output2)<br><br>output3 = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(output3)<br></code></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">torch.Size([1, 1, 5, 5])<br>torch.Size([1, 1, 3, 3])<br>tensor([[[[10, 12, 12],<br>          [18, 16, 16],<br>          [13,  9,  3]]]])<br>tensor([[[[10, 12],<br>          [13,  3]]]])<br>tensor([[[[ 1,  3,  4, 10,  8],<br>          [ 5, 10, 12, 12,  6],<br>          [ 7, 18, 16, 16,  8],<br>          [11, 13,  9,  3,  4],<br>          [14, 13,  9,  7,  4]]]])<br></code></pre></td></tr></table></figure>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%8D%B7%E7%A7%AF%E5%B1%82" tabindex="-1" id="神经网络-卷积层">神经网络-卷积层</h2>
<p>官方文档：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">Conv2d — PyTorch 2.0 documentation</a></li>
</ul>
<p><code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)</code>：</p>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image 输入图像中的通道数</li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution 卷积产生的通道数</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel 卷积核的大小</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</li>
</ul>
<hr>
<p>较少用：</p>
<ul>
<li><strong>padding_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1 内核元素之间的间距。默认值：1</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1 从输入通道到输出通道的阻塞连接数。默认值：1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code> 如果为“True”，则在输出中添加可学习的偏差。</li>
</ul>
<hr>
<p><img src="18_2.png" alt="png"></p>
<p>​    输入/输出的大小计算公式，如果看论文时论文没有阐明，可以用这个公式推断出具体的参数。</p>
<hr>
<p>导入相关库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>dataset = test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>,<br>                                                   train=<span class="hljs-literal">False</span>,<br>                                                   transform=torchvision.transforms.ToTensor(),<br>                                                   download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br></code></pre></td></tr></table></figure>
<hr>
<p>设计卷积神经网络结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.conv1 = Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.conv1(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>myClass = MyClass()<br><span class="hljs-built_in">print</span>(myClass)<br></code></pre></td></tr></table></figure>
<hr>
<p>执行操作并输出到 Tensorboard 上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">writer = SummaryWriter(<span class="hljs-string">&quot;./logs&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    output = myClass(imgs)<br>    <span class="hljs-built_in">print</span>(imgs.shape)<br>    <span class="hljs-built_in">print</span>(output.shape)<br>    <span class="hljs-comment"># torch.Size([64, 3, 32, 32])</span><br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    <span class="hljs-comment"># torch.Size([64, 6, 30, 30]) -&gt; [xxx, 3, 30, 30]</span><br>    output = torch.reshape(output, (-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">30</span>, <span class="hljs-number">30</span>))<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>
<p><img src="18_1.png" alt="png"></p>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E7%9A%84%E4%BD%BF%E7%94%A8" tabindex="-1" id="神经网络-最大池化的使用">神经网络-最大池化的使用</h2>
<p>Max-pooling 是 下采样的一种。</p>
<p>官方文档：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool2d#torch.nn.MaxPool2d">MaxPool2d — PyTorch 2.0 documentation</a></li>
</ul>
<p><code>torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)</code>：</p>
<ul>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple"><em>Tuple</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]**]</em>) – the size of the window to take a max over 要放大的窗口的大小</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple"><em>Tuple</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]**]</em>) – the stride of the window. Default value is <code>kernel_size</code> 窗户的跨步</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple"><em>Tuple</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]**]</em>) – Implicit negative infinity padding to be added on both sides 要在两侧添加的隐式负无穷大填充</li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union"><em>Union</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple"><em>Tuple</em></a><em>[</em><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>]**]</em>) – a parameter that controls the stride of elements in the window 一个参数，用于控制窗口中元素的步幅</li>
<li><strong>return_indices</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a>) – if <code>True</code>, will return the max indices along with the outputs. Useful for <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d"><code>torch.nn.MaxUnpool2d</code></a> later 如果为“True”，则将返回最大索引以及输出</li>
<li><strong>ceil_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a>) – when True, will use ceil instead of floor to compute the output shap 当为True时，将使用ceil（向上取整）而不是floor（向下取整）来计算输出形状</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> MaxPool2d<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>dataset = test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>,<br>                                                   train=<span class="hljs-literal">False</span>,<br>                                                   transform=torchvision.transforms.ToTensor(),<br>                                                   download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                      [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]], dtype=torch.float32)<br>torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>, ceil_mode=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-variable language_">self</span>.maxpool1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br><br>myClass = MyClass()<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;./logs_maxpool&quot;</span>)<br>step = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    output = myClass(imgs)<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step += <span class="hljs-number">1</span><br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p><img src="19_1.png" alt="png"></p>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB" tabindex="-1" id="神经网络-非线性激活">神经网络-非线性激活</h2>
<p>官方文档：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU">ReLU — PyTorch 2.0 documentation</a></li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> ReLU<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, -<span class="hljs-number">0.5</span>],<br>                      [-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>))  <span class="hljs-comment"># 将其转换为 ReLU 能接受的形式</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><br>dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>,<br>                                       transform=torchvision.transforms.ToTensor())<br><br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.relu1 = ReLU()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-variable language_">self</span>.relu1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br><br>myclass = MyClass()<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;./logs_relu&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;inputs&quot;</span>, imgs, global_step=step)<br>    output = myclass(imgs)<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step += <span class="hljs-number">1</span><br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p><img src="20_1.png" alt="png"></p>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%BA%BF%E6%80%A7%E5%B1%82%E5%8F%8A%E5%85%B6%E4%BB%96%E5%B1%82%E4%BB%8B%E7%BB%8D" tabindex="-1" id="神经网络-线性层及其他层介绍">神经网络-线性层及其他层介绍</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                       download=<span class="hljs-literal">True</span>)<br><br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.linear1 = Linear(<span class="hljs-number">196608</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-variable language_">self</span>.linear1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br><br>myclass = MyClass()<br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    <span class="hljs-built_in">print</span>(imgs.shape)<br>    output = torch.flatten(imgs)<br>    <span class="hljs-comment"># output = torch.reshape(imgs, (1, 1, 1, -1))</span><br>    <span class="hljs-built_in">print</span>(output.shape)<br>    output = myclass(output)<br>    <span class="hljs-built_in">print</span>(output.shape)<br></code></pre></td></tr></table></figure>
<p>​    从 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html?highlight=torch+nn#module-torch.nn">torch.nn — PyTorch 2.0 documentation</a> 获取更多神经网络架构。</p>
<p>​    也可从 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/search.html?q=model&amp;check_keywords=yes&amp;area=default">Search — Torchvision 0.15 documentation (pytorch.org)</a> 或 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html">Models and pre-trained weights — Torchvision 0.15 documentation (pytorch.org)</a> 获取经典神经网络模型。</p>
<h2 id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E6%90%AD%E5%BB%BA%E5%B0%8F%E5%AE%9E%E6%88%98%E5%92%8C-sequential-%E7%9A%84%E4%BD%BF%E7%94%A8" tabindex="-1" id="神经网络-搭建小实战和-Sequential-的使用">神经网络-搭建小实战和 Sequential 的使用</h2>
<p>​    使用 <code>Sequential()</code> 将多个神经网络架构整合成一个。</p>
<p>​    整合如下神经网络：</p>
<p><img src="22_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.model1 = Sequential(<br>        Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Flatten(),<br>        Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">64</span>),<br>        Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.model1(x)<br>        <span class="hljs-keyword">return</span> x<br><br>myClass = MyClass()<br><span class="hljs-built_in">print</span>(myClass)<br><span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<br>output = myClass(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output.shape)<br><br>writer = SummaryWriter(<span class="hljs-string">&#x27;../logs_seq&#x27;</span>)<br>writer.add_graph(myClass, <span class="hljs-built_in">input</span>)<br>writer.close()<br></code></pre></td></tr></table></figure>
<p>​    在 <code>SummaryWriter()</code> 中显示完整架构。</p>
<p><img src="22_2.png" alt="png"></p>
<h2 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD" tabindex="-1" id="损失函数与反向传播">损失函数与反向传播</h2>
<p>pytorch 中内置了很多损失函数。<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/search.html?q=loss&amp;check_keywords=yes&amp;area=default">Search — PyTorch 2.0 documentation</a></p>
<p><code>L1Loss()</code>、<code>MSELoss()</code>、<code>CrossEntropyLoss()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> L1Loss, MSELoss<br><br>inputs = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=torch.float32)<br>targets = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>], dtype=torch.float32)<br><br>inputs = torch.reshape(inputs, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>))<br>targets = torch.reshape(targets, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>))<br><br>loss = L1Loss()<br>result = loss(inputs, targets)<br><br>loss_mse = MSELoss()<br>result_mse = loss_mse(inputs, targets)<br><br><span class="hljs-built_in">print</span>(result, result_mse)<br><br>x = torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>])<br>y = torch.tensor([<span class="hljs-number">1</span>])<br>x = torch.reshape(x, (<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))<br>loss_cross = nn.CrossEntropyLoss()<br>result_cross = loss_cross(x, y)<br><span class="hljs-built_in">print</span>(result_cross)<br></code></pre></td></tr></table></figure>
<p>​    对损失函数进行反向传播可以得到模型中各个参数的梯度。<code>result_loss.backward()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;../dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                       download=<span class="hljs-literal">True</span>)<br><br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">1</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.model1 = Sequential(<br>        Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>        MaxPool2d(<span class="hljs-number">2</span>),<br>        Flatten(),<br>        Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">64</span>),<br>        Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.model1(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>loss = nn.CrossEntropyLoss()<br>myClass = MyClass()<br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    outputs = myClass(imgs)<br>    <span class="hljs-built_in">print</span>(outputs)<br>    <span class="hljs-built_in">print</span>(targets)<br>    result_loss = loss(outputs, targets)<br>    <span class="hljs-built_in">print</span>(result_loss)<br>    result_loss.backward()<br></code></pre></td></tr></table></figure>
<h2 id="%E4%BC%98%E5%8C%96%E5%99%A8" tabindex="-1" id="优化器">优化器</h2>
<p>官方文档：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/optim.html">torch.optim — PyTorch 2.0 documentation</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">loss = nn.CrossEntropyLoss()<br>myClass = MyClass()<br>optim = torch.optim.SGD(myClass.parameters(), lr=<span class="hljs-number">0.01</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>        imgs, targets = data<br>        outputs = myClass(imgs)<br>        result_loss = loss(outputs, targets)<br>        optim.zero_grad()<br>        result_loss.backward()<br>        optim.step()<br>        running_loss = running_loss + result_loss<br>    <span class="hljs-built_in">print</span>(running_loss)<br></code></pre></td></tr></table></figure>
<p>​    以最基本的随机梯度下降为例：<code>optim = torch.optim.SGD(myClass.parameters(), lr=0.01)</code></p>
<p>，读入模型参数，然后读入学习率。</p>
<ul>
<li>
<p>嵌套在<code>for epoch in range(20):</code> 进行多轮参数优化。</p>
</li>
<li>
<p>每次梯度下降都要清零梯度：<code>optim.zero_grad()</code></p>
</li>
<li>
<p>计算出新的梯度：<code>result_loss.backward()</code></p>
</li>
<li>
<p>更新模型参数：<code>optim.step()</code></p>
</li>
</ul>
<p>​    一般而言，每轮迭代会让损失函数值变小。</p>
<h2 id="%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E4%BF%AE%E6%94%B9" tabindex="-1" id="现有网络模型的使用及修改">现有网络模型的使用及修改</h2>
<p>​    从官网 <a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/models.html#classification">Models and pre-trained weights — Torchvision 0.15 documentation (pytorch.org)</a> 中可以获得流行的模型以及 pretrain 后的模型。</p>
<ul>
<li>
<p>初始化 vgg-16 模型，参数不变：<code>vgg16_false = torchvision.models.vgg16(pretrained=False)</code></p>
</li>
<li>
<p>初始化 vgg-16 模型，并从官网上下载经过预训练后的参数：<code>vgg16_true = torchvision.models.vgg16(pretrained=True)</code></p>
</li>
<li>
<p>在现有模型后追加层：<code>vgg16_true.add_module('add_linear', nn.Linear(1000, 10))</code></p>
</li>
<li>
<p>在现有模型后更改层：<code>vgg16_false.classifier[6] = nn.Linear(4096, 10)</code></p>
</li>
</ul>
<h2 id="%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF%EF%BC%88%E4%B8%80%EF%BC%89" tabindex="-1" id="完整的模型训练套路（一）">完整的模型训练套路（一）</h2>
<p>单独建一个 <code>model.py</code> 文件，用于定义模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 搭建神经网络</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyClass, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.model = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">64</span>),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.model(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    myClass = MyClass()<br>    <span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<br>    output = myClass(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-built_in">print</span>(output.shape)<br></code></pre></td></tr></table></figure>
<p>在 <code>train.py</code> 中，设置损失函数，优化器，训练轮次等训练神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment"># 准备数据集</span><br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../dataset&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br>test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../dataset&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># length 长度</span><br>train_data_size = <span class="hljs-built_in">len</span>(train_data)<br>test_data_size = <span class="hljs-built_in">len</span>(test_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据集的长度为:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(train_data_size))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试数据集的长度为:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(test_data_size))<br><br><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span><br>train_dataloader = DataLoader(train_data, batch_size=<span class="hljs-number">64</span>)<br>test_dataloader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-comment"># 创建网络模型</span><br>myClass = MyClass()<br><br><span class="hljs-comment"># 损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># 定义优化器</span><br>learning_rate = <span class="hljs-number">1e-2</span><br>optimizer = torch.optim.SGD(myClass.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># 设置训练网络的一些参数</span><br>total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练的次数</span><br>total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试的次数</span><br>epoch = <span class="hljs-number">10</span>  <span class="hljs-comment"># 训练的轮数</span><br><br><span class="hljs-comment"># 训练</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;第 &#123;&#125; 轮训练开始&#x27;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br>    <span class="hljs-comment"># 训练步骤开始</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:<br>        imgs, targets = data<br>        outputs = myClass(imgs)<br>        loss = loss_fn(outputs, targets)<br><br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br><br>        total_train_step = total_train_step + <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练次数: &#123;&#125;, Loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(total_train_step, loss.item()))<br></code></pre></td></tr></table></figure>
<h2 id="%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%88%E4%B8%89%EF%BC%89" tabindex="-1" id="完整的模型训练套路（二）（三）">完整的模型训练套路（二）（三）</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment"># 准备数据集</span><br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../dataset&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br>test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;../dataset&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                          download=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># length 长度</span><br>train_data_size = <span class="hljs-built_in">len</span>(train_data)<br>test_data_size = <span class="hljs-built_in">len</span>(test_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据集的长度为:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(train_data_size))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试数据集的长度为:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(test_data_size))<br><br><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span><br>train_dataloader = DataLoader(train_data, batch_size=<span class="hljs-number">64</span>)<br>test_dataloader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-comment"># 创建网络模型</span><br>myClass = MyClass()<br><br><span class="hljs-comment"># 损失函数</span><br>loss_fn = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># 定义优化器</span><br>learning_rate = <span class="hljs-number">1e-2</span><br>optimizer = torch.optim.SGD(myClass.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># 设置训练网络的一些参数</span><br>total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练的次数</span><br>total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试的次数</span><br>epoch = <span class="hljs-number">10</span>  <span class="hljs-comment"># 训练的轮数</span><br><br><span class="hljs-comment"># 添加 tensorboard</span><br>writer = SummaryWriter(<span class="hljs-string">&#x27;../logs_train&#x27;</span>)<br><br><span class="hljs-comment"># 训练</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;第 &#123;&#125; 轮训练开始&#x27;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br>    <span class="hljs-comment"># 训练步骤开始</span><br>    myClass.train()<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:<br>        imgs, targets = data<br>        outputs = myClass(imgs)<br>        loss = loss_fn(outputs, targets)<br><br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br><br>        total_train_step = total_train_step + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练次数: &#123;&#125;, Loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(total_train_step, loss.item()))<br>            writer.add_scalar(<span class="hljs-string">&#x27;train_loss&#x27;</span>, loss.item(), total_train_step)<br><br>    <span class="hljs-comment"># 测试步骤开始</span><br>    myClass.<span class="hljs-built_in">eval</span>()<br>    total_test_loss = <span class="hljs-number">0</span><br>    total_accuracy = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:<br>            imgs, targets = data<br>            outputs = myClass(imgs)<br>            loss = loss_fn(outputs, targets)<br><br>            total_test_loss = total_test_loss + loss<br><br>            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()<br>            total_accuracy += accuracy<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;整体测试集上的 Loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(total_test_loss))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;整体测试集上的正确率: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(total_accuracy / test_data_size))<br>    writer.add_scalar(<span class="hljs-string">&#x27;test_loss&#x27;</span>, total_test_loss, total_test_step)<br>    writer.add_scalar(<span class="hljs-string">&#x27;total_accuracy&#x27;</span>, total_accuracy / test_data_size, total_test_step)<br>    total_test_step += <span class="hljs-number">1</span><br><br>    torch.save(myClass, <span class="hljs-string">&quot;myClass_&#123;&#125;.pth&quot;</span>.<span class="hljs-built_in">format</span>(i))<br>    <span class="hljs-comment"># torch.save(myClass.state_dict(), &quot;myClass_&#123;&#125;.pth&quot;.format(i))</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型已保存&quot;</span>)<br><br>writer.close()<br></code></pre></td></tr></table></figure>
<p>​    将模型调整为 train / eval 模式：<code>myClass.train()</code>、<code>myClass.eval()</code>，该调整对 <code>Dropout</code> 和 <code>BatchNorm</code> 等架构有效。</p>
<p>​    测试步骤（不更新参数，不计算梯度，可以节约内存）：<code> with torch.no_grad():</code></p>
<p>​    输出每轮次的损失函数的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练次数: &#123;&#125;, Loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(total_train_step, loss.item()))<br></code></pre></td></tr></table></figure>
<p>​    计算正确率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()<br>total_accuracy += accuracy<br></code></pre></td></tr></table></figure>
<p>​    使用 <code>SummaryWriter</code> 可视化训练过程：</p>
<ul>
<li><code>writer.add_scalar('train_loss', loss.item(), total_train_step)</code></li>
<li><code>writer.add_scalar('test_loss', total_test_loss, total_test_step)</code></li>
<li><code>writer.add_scalar('total_accuracy', total_accuracy / test_data_size, total_test_step)</code></li>
</ul>
<p><img src="28_1.png" alt="png"></p>
<p>​    保存每轮次训练出的模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(myClass, <span class="hljs-string">&quot;myClass_&#123;&#125;.pth&quot;</span>.<span class="hljs-built_in">format</span>(i))<br><span class="hljs-comment"># torch.save(myClass.state_dict(), &quot;myClass_&#123;&#125;.pth&quot;.format(i))</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型已保存&quot;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="%E5%88%A9%E7%94%A8-gpu-%E8%AE%AD%E7%BB%83%EF%BC%88%E4%B8%80%EF%BC%89" tabindex="-1" id="利用-GPU-训练（一）">利用 GPU 训练（一）</h2>
<p>网络模型可以使用 cuda：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    myClass = MyClass()<br>    myClass = myClass.cuda()  <span class="hljs-comment"># 将网络模型转到 cuda 上</span><br></code></pre></td></tr></table></figure>
<p>损失函数可以使用 cuda：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 损失函数</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    loss_fn = nn.CrossEntropyLoss()<br>    loss_fn = loss_fn.cuda()<br></code></pre></td></tr></table></figure>
<p>优化器不可以。</p>
<p>测试集、数据集数据可以使用 cuda：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:<br>    imgs, targets = data<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        imgs = imgs.cuda()<br>        targets = targets.cuda()<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:<br>    imgs, targets = data<br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        imgs = imgs.cuda()<br>        targets = targets.cuda()<br></code></pre></td></tr></table></figure>
<p><img src="29_1.png" alt="png"></p>
<p><img src="29_2.png" alt="png"></p>
<h2 id="%E5%88%A9%E7%94%A8-gpu-%E8%AE%AD%E7%BB%83%EF%BC%88%E4%BA%8C%EF%BC%89" tabindex="-1" id="利用-GPU-训练（二）">利用 GPU 训练（二）</h2>
<p>使用 <code>torch.device()</code> 设置训练用的设备：<code>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</code></p>
<p>如果有多个 gpu，可以用<code>cuda:0</code> 指定 0 号 gpu 等。</p>
<p>将模型放到相应设备上训练：</p>
<ul>
<li>
<p><code>myClass = myClass.to(device)</code> 模型</p>
</li>
<li>
<p><code>loss_fn = loss_fn.to(device)</code> 损失函数</p>
</li>
<li>
<pre><code class="language-python">for data in train_dataloader:
    imgs, targets = data
    imgs = imgs.to(device)
    targets = targets.to(device)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs plaintext"><br>## 完整的模型验证套路<br><br>利用已经训练好的模型，然后给它提供输入，得到期望的输出。<br><br>```python<br>import torch<br>import torchvision<br>from PIL import Image<br>from torch import nn<br><br>image_path = &#x27;../imgs/dog.png&#x27;<br>image = Image.open(image_path)<br>image = image.convert(&#x27;RGB&#x27;)<br><br>transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),<br>                                            torchvision.transforms.ToTensor()])<br>image = transform(image)<br>print(image.shape)<br><br><br>class MyClass(nn.Module):<br>    def __init__(self):<br>        super(MyClass, self).__init__()<br>        self.model = nn.Sequential(<br>            nn.Conv2d(3, 32, 5, padding=2),<br>            nn.MaxPool2d(2),<br>            nn.Conv2d(32, 32, 5, padding=2),<br>            nn.MaxPool2d(2),<br>            nn.Conv2d(32, 64, 5, padding=2),<br>            nn.MaxPool2d(2),<br>            nn.Flatten(),<br>            nn.Linear(1024, 64),<br>            nn.Linear(64, 10)<br>        )<br><br>    def forward(self, x):<br>        x = self.model(x)<br>        return x<br><br>model = torch.load(&quot;myClass_0.pth&quot;, map_location=torch.device(&#x27;cpu&#x27;))<br>print(model)<br><br>image = torch.reshape(image, (1, 3, 32, 32))<br>model.eval()<br>with torch.no_grad():<br>    output = model(image)<br>print(output)<br>print(output.argmax(1))<br></code></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<p>读入测试图片：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">image_path = <span class="hljs-string">&#x27;../imgs/dog.png&#x27;</span><br>image = Image.<span class="hljs-built_in">open</span>(image_path)<br>image = image.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br><br>transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)),<br>                                            torchvision.transforms.ToTensor()])<br>image = transform(image)<br><span class="hljs-built_in">print</span>(image.shape)<br></code></pre></td></tr></table></figure>
<p>读入已经训练好的模型，<code>map_location=torch.device('cpu')</code>让在 cuda 上训练的模型也可以在 cpu 中测试，否则会报错：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.load(<span class="hljs-string">&quot;myClass_0.pth&quot;</span>, map_location=torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>))<br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>
<p>输出预期结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">image = torch.reshape(image, (<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<br>model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(image)<br><span class="hljs-built_in">print</span>(output)<br><span class="hljs-built_in">print</span>(output.argmax(<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">tensor([[-2.7974, -0.1087,  0.5627,  1.2185,  1.4736,  1.4348,  2.3175,  1.3776,<br>         -3.5540, -0.6126]])<br>tensor([6])<br></code></pre></td></tr></table></figure>
<h2 id="%E7%9C%8B%E7%9C%8B%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE" tabindex="-1" id="看看开源项目">看看开源项目</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">junyanz/pytorch-CycleGAN-and-pix2pix: Image-to-Image Translation in PyTorch (github.com)</a></li>
</ul>
<p>​    看说明文档 <code>README.md</code>，一般 <code>train.py</code> 可以用来训练：</p>
<p>​    训练一般有参数：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/606472791">【Python】Parser 通常用法 - 知乎 (zhihu.com)</a></p>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/Pytorch-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%20YOLOv5%20%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81%E9%A1%B9%E7%9B%AE%E8%B0%83%E8%AF%95%E4%B8%8E%E8%AE%B2%E8%A7%A3%E5%AE%9E%E6%88%98-%E5%B0%8F%E5%9C%9F%E5%A0%86/">
                        上一篇：Pytorch-目标检测 YOLOv5 开源代码项目调试与讲解实战-小土堆
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/Paper-Text%20Recognition%20in%20the%20Wild-A%20Survey/">
                        下一篇：Paper-Text Recognition in the Wild-A Survey
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">121</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">436</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

