<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Homework-看得头晕的整理论文任务 | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="论文,作业,">
<meta name="description" content="整理论文的工作。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/论文"><span>论文</span></a></li>
						
							<li><a href="/tags/作业"><span>作业</span></a></li>
						
					
				</ul>
				
				<h1>Homework-看得头晕的整理论文任务</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>整理论文的工作。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2023/03/19 14:46:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="%E5%89%8D%E8%A8%80" tabindex="-1">前言</h1>
<p>​    3.14 听完师兄师姐汇报导师觉得我们听得一头雾水，于是给了我们看期刊整理论文的任务😐……</p>
<p>​    要求我们四个人整理完《中国计算机学会推荐国际学术会议和期刊目录》人工智能部分期刊和会议近三年的目录并从中总结出研究趋势。</p>
<p>​    这篇博客就胡扯点完成论文干的各种事吧。</p>
<h1 id="%E6%AD%A3%E6%96%87" tabindex="-1">正文</h1>
<p>##《中国计算机学会推荐国际学术会议和期刊目录》</p>


	<div class="row">
    <embed src="pdf.pdf" width="100%" height="550" type="application/pdf">
	</div>



<h2 id="%E7%88%AC%E8%99%AB" tabindex="-1" id="爬虫">爬虫</h2>
<p>​    分完工后还是觉得要整理的论文特别多，于是整了个爬虫代码帮忙爬目录。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://gitee.com/jhhuang_nuaa/zotero_dblp_bibtex">zotero_dblp_bibtex: 通过 python 抓取 dblp 中某一作者、某年会议或期刊的论文 (gitee.com)</a></li>
</ul>
<p>​    然后估计爬的太多了，爬久了就爬不动了 orz 忙活了几乎一天才爬到了一半内容 orz</p>
<p>​    然后就发现 dblp 这个网站本身就可以批量下载目录 orz 除了超过 1000 的和期刊数太多的期刊用爬虫可能更快些。</p>
<p><img src="01.png" alt="png"></p>
<h2 id="%E5%AF%BC%E5%87%BA-excel" tabindex="-1" id="导出-Excel">导出 Excel</h2>
<p><img src="02.png" alt="png"></p>
<p>​    将得到的 bibtex 文件一个一个地导入进 Zotero，然后一个一个地导出成 csv 文件。</p>
<p>​    接下来就是合并表格了，手动操作了几次后觉得太麻烦，整了个 python 代码帮我自动整理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>path = <span class="hljs-string">r&#x27;D:\Study\1st-year-master\论文目录\Conf\A\NeurlPS&#x27;</span><br>save_file = path.split(<span class="hljs-string">&#x27;\\&#x27;</span>)[-<span class="hljs-number">1</span>]<br><br>data = pd.DataFrame(columns=[<span class="hljs-string">&#x27;Publication Year&#x27;</span>, <span class="hljs-string">&#x27;Author&#x27;</span>, <span class="hljs-string">&#x27;Title&#x27;</span>])<br><br><span class="hljs-keyword">for</span> index, file <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(os.listdir(path)):<br>    <span class="hljs-keyword">if</span>(<span class="hljs-string">&#x27;.csv&#x27;</span> <span class="hljs-keyword">in</span> file):<br>        df = pd.read_csv(os.path.join(path,file))<br>        data = data.append(df[[<span class="hljs-string">&#x27;Publication Year&#x27;</span>, <span class="hljs-string">&#x27;Author&#x27;</span>, <span class="hljs-string">&#x27;Title&#x27;</span>]])<br><br>data.head<br>write = pd.ExcelWriter(os.path.join(path,save_file) + <span class="hljs-string">&#x27;.xlsx&#x27;</span>)   <span class="hljs-comment"># 新建 xlsx 文件。</span><br>data.to_excel(write, sheet_name=<span class="hljs-string">&#x27;Sheet&#x27;</span>, index=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 写入文件的 Sheet1</span><br>write.save()  <span class="hljs-comment"># 这里一定要保存</span><br></code></pre></td></tr></table></figure>
<p>​    这样每个期刊/会议近三年的目录就被整成一个 Excel 表格了😎！</p>
<p><img src="03.png" alt="png"></p>
<h2 id="%E7%BB%9F%E8%AE%A1%E8%AF%8D%E9%A2%91" tabindex="-1" id="统计词频">统计词频</h2>
<p>​    想用 python 把这些目录的词频统计出来，这样就分析当作研究趋势了😈！于是又一阵操作猛如虎：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> re<br><br>path = <span class="hljs-string">r&#x27;D:\Study\1st-year-master\论文目录\xlsx&#x27;</span><br>save_path = <span class="hljs-string">r&#x27;D:\Study\1st-year-master\论文目录\freq&#x27;</span><br><br><span class="hljs-keyword">for</span> index, file <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(os.listdir(path)):<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;.xlsx&#x27;</span> <span class="hljs-keyword">in</span> file:<br>        df = pd.read_excel(os.path.join(path,file))<br>        series = df[<span class="hljs-string">&#x27;Title&#x27;</span>].<span class="hljs-built_in">str</span>.split(<span class="hljs-string">&#x27; &#x27;</span>).explode().value_counts()<br>        data = pd.DataFrame(&#123;<span class="hljs-string">&#x27;Word&#x27;</span>: series.index, <span class="hljs-string">&#x27;Frequent&#x27;</span>: series.values&#125;)<br>        write = pd.ExcelWriter(os.path.join(save_path, file) + <span class="hljs-string">&#x27;_frequent.xlsx&#x27;</span>)   <span class="hljs-comment"># 新建 xlsx 文件。</span><br>        data.to_excel(write, sheet_name=<span class="hljs-string">&#x27;Sheet&#x27;</span> + <span class="hljs-built_in">str</span>(index), index=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 写入文件的 Sheet1</span><br>        write.save()  <span class="hljs-comment"># 这里一定要保存</span><br></code></pre></td></tr></table></figure>
<p>​    结果统计出来的全是 “a”、“of”、“from” 之类的，一点参考意义也没有😅……</p>
<p>​    杰杰还搞了一个词频可视化，果然也都是一些没啥用的单词……不过突然感慨他的技术真的好全面……几乎什么都会一点。</p>
<p><img src="04.jpg" alt="png"></p>
<h2 id="%E7%BF%BB%E8%AF%91" tabindex="-1" id="翻译">翻译</h2>
<p>​    统计词频的计划失败后，想想还是手动检索论文吧。英文看的实在太难受，想了想有没有什么可以翻译 Excel 表格的方法……一开始想的很复杂，想先转成 markdown 文件然后传到博客上用浏览器帮忙翻译，在 Excel 表格调用有道的 API 直接翻译结果发现请求次数一上来就不让翻译了 balababala……最后伟哥说谷歌翻译可以直接上转 Excel 表格返回中文文档 orz</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://translate.google.com.hk/?hl=zh-CN&amp;sourceid=cnhp&amp;sl=auto&amp;tl=zh-CN&amp;op=docs">Google 翻译</a></li>
</ul>
<p><img src="05.png" alt="png"></p>
<p>​    最后就得到了中文的论文标题目录！不知道为什么有些英文没有进行翻译。想着文件不多就手动把中英文标题整成一个表格了。</p>
<h2 id="%E6%80%BB%E7%BB%93" tabindex="-1" id="总结">总结</h2>
<p>​    最后大概看了一个晚上 + 一个上午吧……几万篇论文眼睛都快看花了💨，由于是主观判断研究趋势，感觉总结得也不是特别准，然后筛了点自己跟自己研究方向有点关系的论文。</p>
<p><img src="06.png" alt="png"></p>
<h2 id="%E6%9C%80%E7%BB%88%E7%BB%93%E6%9E%9C" tabindex="-1" id="最终结果">最终结果</h2>
<h3 id="jounrnals" tabindex="-1" id="Jounrnals">Jounrnals</h3>
<h4 id="a" tabindex="-1" id="A">A</h4>
<h5 id="ieee-transactions-on-pattern-analysis-and-machine-intelligence" tabindex="-1" id="IEEE-Transactions-on-Pattern-Analysis-and-Machine-Intelligence">IEEE Transactions on Pattern Analysis and Machine Intelligence</h5>
<p>人体姿态估计、人体检测、3D 视觉、CNN、图像修复、点云、GAN、超分辨率、图像分割、视频</p>
<ul>
<li>Baselines extraction from curved document images via slope fields recovery</li>
<li>Mask TextSpotter: An end-to-end trainable neural network for spotting text with arbitrary shapes</li>
<li>Shape-matching GAN++: Scale controllable dynamic artistic text style transfer</li>
<li>Unambiguous text localization, retrieval, and recognition for cluttered scenes</li>
<li>Content and style aware generation of text-line images for handwriting recognition</li>
<li>Towards  end-to-end text spotting in natural scenes</li>
<li>Deep generative modelling: A comparative review of VAEs, GANs, normalizing flows, energy-based and autoregressive models</li>
<li>A  geometrical perspective on image style transfer with adversarial learning</li>
<li>GAN inversion: A survey</li>
<li>Arbitrary shape text detection via segmentation with probability maps</li>
<li>End-to-end  handwritten paragraph text recognition using a vertical attention network</li>
<li>Real-time scene text detection with differentiable binarization and adaptive scale fusion</li>
<li>A survey on vision transformer</li>
</ul>
<h4 id="b" tabindex="-1" id="B">B</h4>
<h5 id="data-%26-knowledge-engineering" tabindex="-1" id="Data-Knowledge-Engineering">Data &amp; Knowledge Engineering</h5>
<p>建模、数据、解决某些实际问题</p>
<h5 id="ieee-transactions-on-cybernetics" tabindex="-1" id="IEEE-Transactions-on-Cybernetics">IEEE Transactions on Cybernetics</h5>
<p>算法、信息安全、传统机器学习方法（马尔科夫链、支持向量机）</p>
<h5 id="international-journal-of-approximate-reasoning" tabindex="-1" id="International-Journal-of-Approximate-Reasoning">International Journal of Approximate Reasoning</h5>
<p>模糊逻辑</p>
<h5 id="machine-learning" tabindex="-1" id="Machine-Learning">Machine Learning</h5>
<p>传统机器学习、强化学习</p>
<h5 id="transactions-of-the-association-for-computational-linguistics" tabindex="-1" id="Transactions-of-the-Association-for-Computational-Linguistics">Transactions of the Association for Computational Linguistics</h5>
<p>自然语言处理、语言学、BERT、Transformer</p>
<h4 id="c" tabindex="-1" id="C">C</h4>
<h5 id="applied-intelligence" tabindex="-1" id="Applied-Intelligence">Applied Intelligence</h5>
<p>解决某些实际问题、超分辨率、模式识别、医学、COVID-19（预测、检测）、3D 视觉、CNN、图神经网络、聚类、分类、情感识别</p>
<ul>
<li>Anchor-free  multi-orientation text detection in natural scene images</li>
</ul>
<h5 id="computer-speech-%26-language" tabindex="-1" id="Computer-Speech-Language">Computer Speech &amp; Language</h5>
<p>语音识别、自然语言处理</p>
<h5 id="expert-systems" tabindex="-1" id="Expert-Systems">Expert Systems</h5>
<p>解决某些实际问题、医学、COVID-19、推荐系统</p>
<h5 id="iet-computer-vision" tabindex="-1" id="IET-Computer-Vision">IET Computer Vision</h5>
<p>人体姿态估计、人脸识别、目标检测、CNN、3D 视觉</p>
<ul>
<li>Stroke controllable style transfer based on dilated convolutions</li>
<li>KText: Arbitrary  shape text detection using modified K-Means</li>
</ul>
<h5 id="international-journal-of-computational-intelligence-and-applications" tabindex="-1" id="International-Journal-of-Computational-Intelligence-and-Applications">International Journal of Computational Intelligence and Applications</h5>
<p>解决某些实际问题</p>
<h5 id="international-journal-of-uncertainty%2C-fuzziness-and-knowledge-based-systems" tabindex="-1" id="International-Journal-of-Uncertainty-Fuzziness-and-Knowledge-Based-Systems">International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems</h5>
<p>模糊逻辑</p>
<h5 id="machine-translation" tabindex="-1" id="Machine-Translation">Machine Translation</h5>
<p>机器翻译</p>
<h5 id="neural-computing-and-applications" tabindex="-1" id="Neural-Computing-and-Applications">Neural Computing and Applications</h5>
<p>解决某些实际问题</p>
<ul>
<li>Hybrid HMM/BLSTM system for multi-script keyword spotting in printed and handwritten documents with identification stage</li>
<li>SPN: short path network for scene text detection</li>
<li>Robustly detect different types of text in videos</li>
<li>Effective offline handwritten text recognition model based on a sequence-to-sequence approach with CNN-RNN networks</li>
<li>Historical document image binarization via style augmentation and atrous convolutions</li>
<li>Character-based handwritten text transcription with attention networks</li>
</ul>
<h5 id="pattern-recognition-letters" tabindex="-1" id="Pattern-Recognition-Letters">Pattern Recognition Letters</h5>
<p>模式识别（文字、医学、人体）、特征提取、GAN</p>
<ul>
<li>Compressing the CNN architecture for in-air handwritten Chinese character recognition</li>
<li>LPR-Net: Recognizing Chinese license plate in complex environments</li>
<li>An attention-based row-column encoder-decoder model for text recognition in Japanese historical documents</li>
<li>Assessing similarity in handwritten texts</li>
<li>Clustering online handwritten mathematical expressions</li>
<li>Beyond visual semantics: Exploring the role of scene text in image understanding</li>
<li>PMMN: Pre-trained multi-Modal network for scene text recognition</li>
<li>RectiNet-v2: A stacked network architecture for document image dewarping</li>
<li>Transformer-based approach for joint handwriting and named entity recognition in historical document</li>
<li>Cross lingual handwritten character recognition using long short term memory network with aid of elephant herding optimization algorithm</li>
<li>CE-text: A context-Aware and embedded text detector in natural scene images</li>
</ul>
<h3 id="conf" tabindex="-1" id="Conf">Conf</h3>
<h4 id="a-1" tabindex="-1" id="A-2">A</h4>
<h5 id="conference-on-neural-information-processing-systems" tabindex="-1" id="Conference-on-Neural-Information-Processing-Systems">Conference on Neural Information Processing Systems</h5>
<p>数据集、图神经网络、算法、GAN、元学习、对比学习、强化学习、3D、Transformer</p>
<ul>
<li>OmniPrint: A configurable printed character synthesizer</li>
<li>Are transformers more robust than CNNs?</li>
<li>Diffusion models beat GANs on image synthesis</li>
</ul>
<h5 id="international-conference-on-machine-learning" tabindex="-1" id="International-Conference-on-Machine-Learning">International Conference on Machine Learning</h5>
<p>模型攻击、算法、游戏、生成模型、元学习、强化学习、Transformer、Wasserstein 距离、强化学习</p>
<h4 id="b-1" tabindex="-1" id="B-2">B</h4>
<h5 id="conference-on-empirical-methods-in-natural-language-processing" tabindex="-1" id="Conference-on-Empirical-Methods-in-Natural-Language-Processing">Conference on Empirical Methods in Natural Language Processing</h5>
<p>NLP、BERT、强化学习、文章生成摘要、文本生成、迁移学习、Transformer、数据集、COVID-19</p>
<ul>
<li>Cleaning dirty books: Post-OCR processing for previously scanned texts</li>
</ul>
<h5 id="international-conference-on-automated-planning-and-scheduling" tabindex="-1" id="International-Conference-on-Automated-Planning-and-Scheduling">International Conference on Automated Planning and Scheduling</h5>
<p>路径规划、强化学习</p>
<h5 id="conference-on-uncertainty-in-artificial-intelligence" tabindex="-1" id="Conference-on-Uncertainty-in-Artificial-Intelligence">Conference on Uncertainty in Artificial Intelligence</h5>
<p>马尔科夫链、贝叶斯、无监督学习、蒙特卡洛、强化学习</p>
<h4 id="c-1" tabindex="-1" id="C-2">C</h4>
<h5 id="asian-conference-on-computer-vision" tabindex="-1" id="Asian-Conference-on-Computer-Vision">Asian Conference on Computer Vision</h5>
<p>贝叶斯、马尔可夫、3D 视觉、人体识别、GAN</p>
<ul>
<li>Accurate arbitrary-shaped scene text detection via iterative polynomial parameter regression</li>
</ul>
<h5 id="conference-on-computational-natural-language-learning" tabindex="-1" id="Conference-on-Computational-Natural-Language-Learning">Conference on Computational Natural Language Learning</h5>
<p>NLP</p>
<h5 id="international-conference-on-algorithmic-learning-theory" tabindex="-1" id="International-Conference-on-Algorithmic-Learning-Theory">International Conference on Algorithmic Learning Theory</h5>
<p>在线学习、强化学习</p>
<h5 id="international-conference-on-inductive-logic-programming" tabindex="-1" id="International-Conference-on-Inductive-Logic-Programming">International Conference on Inductive Logic Programming</h5>
<p>太杂太少太偏了…</p>
<h5 id="international-joint-conference-on-biometrics" tabindex="-1" id="International-Joint-Conference-on-Biometrics">International Joint Conference on Biometrics</h5>
<p>安全、攻击、人脸识别</p>
<h2 id="%E9%A2%86%E5%9F%9F%E6%9C%89%E5%85%B3%E7%9A%84%E8%AE%BA%E6%96%87" tabindex="-1" id="领域有关的论文">领域有关的论文</h2>
<table>
<thead>
<tr>
<th>序号</th>
<th>名称</th>
<th>期刊/会议及其等级</th>
<th>资源</th>
<th>概要</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Baselines extraction from curved document images via slope fields recovery</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8576546">https://ieeexplore.ieee.org/document/8576546</a></td>
<td>提出了一种基于斜率场恢复的方法，用于从手持相机拍摄的失真文档图像中<strong>提取曲线基线</strong>。</td>
</tr>
<tr>
<td>2</td>
<td>Mask TextSpotter: An end-to-end trainable neural network for spotting text with arbitrary shapes</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/mask-textspotter-an-end-to-end-trainable">https://paperswithcode.com/paper/mask-textspotter-an-end-to-end-trainable</a><br/><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/mask-textspotter-an-end-to-end-trainable-2">https://paperswithcode.com/paper/mask-textspotter-an-end-to-end-trainable-2</a></td>
<td>研究了场景文本识别问题，该问题旨在同时<strong>检测和识别</strong>自然图像中的文本。</td>
</tr>
<tr>
<td>3</td>
<td>Shape-matching GAN++: Scale controllable dynamic artistic text style transfer</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9339900">https://ieeexplore.ieee.org/document/9339900</a><br/><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Controllable_Artistic_Text_Style_Transfer_via_Shape-Matching_GAN_ICCV_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Controllable_Artistic_Text_Style_Transfer_via_Shape-Matching_GAN_ICCV_2019_paper.pdf</a></td>
<td>探索了一个具有字形风格度控制的<strong>动态艺术文本风格转移</strong>的新问题。</td>
</tr>
<tr>
<td>4</td>
<td>Unambiguous text localization, retrieval, and recognition for cluttered scenes</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/unambiguous-text-localization-and-retrieval">https://paperswithcode.com/paper/unambiguous-text-localization-and-retrieval</a></td>
<td>将<strong>杂乱场景图像</strong>的中间卷积表示顺序解码为一组不同的文本实例检测。</td>
</tr>
<tr>
<td>5</td>
<td>Content and style aware generation of text-line images for handwriting recognition</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/content-and-style-aware-generation-of-text">https://paperswithcode.com/paper/content-and-style-aware-generation-of-text</a></td>
<td>提出了一种<strong>手写文本行图像的生成</strong>方法，该方法以视觉外观和文本内容为条件。</td>
</tr>
<tr>
<td>6</td>
<td>Towards end-to-end text spotting in natural scenes</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/towards-end-to-end-text-spotting-in-natural">https://paperswithcode.com/paper/towards-end-to-end-text-spotting-in-natural</a></td>
<td><strong>自然场景图像</strong>中的文本识别</td>
</tr>
<tr>
<td>7</td>
<td>Deep generative modelling: A comparative review of VAEs, GANs, normalizing flows, energy-based and autoregressive models</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/deep-generative-modelling-a-comparative">https://paperswithcode.com/paper/deep-generative-modelling-a-comparative</a></td>
<td><strong>生成模型</strong>的<strong>综述</strong>论文</td>
</tr>
<tr>
<td>8</td>
<td>A geometrical perspective on image style transfer with adversarial learning</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/343171440_A_Geometrical_Perspective_on_Image_Style_Transfer_With_Adversarial_Learning">https://www.researchgate.net/publication/343171440_A_Geometrical_Perspective_on_Image_Style_Transfer_With_Adversarial_Learning</a></td>
<td>提出了一个通用框架，用于通过微分几何的视角分析带有<strong>对抗性学习</strong>的<strong>风格迁移</strong>。</td>
</tr>
<tr>
<td>9</td>
<td>GAN inversion: A survey</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/gan-inversion-a-survey">https://paperswithcode.com/paper/gan-inversion-a-survey</a></td>
<td>涵盖了 <strong>GAN 反演</strong>的重要技术及其在<strong>图像恢复</strong>和<strong>图像处理</strong>中的应用。</td>
</tr>
<tr>
<td>10</td>
<td>Arbitrary shape text detection via segmentation with probability maps</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/arbitrary-shape-text-detection-via">https://paperswithcode.com/paper/arbitrary-shape-text-detection-via</a></td>
<td>通过<strong>概率图</strong>提出了一种创新且稳健的基于分割的检测方法，用于准确<strong>检测文本</strong>实例。</td>
</tr>
<tr>
<td>11</td>
<td>End-to-end handwritten paragraph text recognition using a vertical attention network</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/end-to-end-handwritten-paragraph-text">https://paperswithcode.com/paper/end-to-end-handwritten-paragraph-text</a></td>
<td>不受约束的<strong>手写文本识别</strong></td>
</tr>
<tr>
<td>12</td>
<td>Real-time scene text detection with differentiable binarization and adaptive scale fusion</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/real-time-scene-text-detection-with-1">https://paperswithcode.com/paper/real-time-scene-text-detection-with-1</a></td>
<td>基于分割的场景文本检测方法在<strong>场景文本检测</strong>领域。提出了一个<strong>可微分二值化 (DB) 模块</strong>，该模块将二值化过程（后处理过程中最重要的步骤之一）集成到分割网络中</td>
</tr>
<tr>
<td>13</td>
<td>A survey on vision transformer</td>
<td>Journals A</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2012.12556">https://arxiv.org/abs/2012.12556</a></td>
<td><strong>Transformer</strong> 在计算机视觉领域的<strong>综述</strong>论文</td>
</tr>
<tr>
<td>14</td>
<td>Anchor-free  multi-orientation text detection in natural scene images</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10489-020-01742-z">https://link.springer.com/article/10.1007/s10489-020-01742-z</a></td>
<td><strong>自然场景图像</strong>中的<strong>文本检测</strong></td>
</tr>
<tr>
<td>15</td>
<td>Stroke controllable style transfer based on dilated convolutions</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2019.0912">https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/iet-cvi.2019.0912</a><br/><a target="_blank" rel="noopener" href="https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-cvi.2019.0912">https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-cvi.2019.0912</a></td>
<td><strong>风格转换</strong>任务对 <strong>VGG19</strong> 模型进行了特殊优化，作者提出利用<strong>扩张卷积</strong>来提取纹理信息，使网络具有笔画可控性</td>
</tr>
<tr>
<td>16</td>
<td>KText: Arbitrary  shape text detection using modified K-Means</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cvi2.12052">https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cvi2.12052</a><br/><a target="_blank" rel="noopener" href="https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/cvi2.12052">https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/cvi2.12052</a></td>
<td>基于分组字符的<strong>文本检测</strong>方法、K-Means</td>
</tr>
<tr>
<td>17</td>
<td>Hybrid HMM/BLSTM system for multi-script keyword spotting in printed and handwritten documents with identification stage</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/335462030_Hybrid_HMMBLSTM_system_for_multi-script_keyword_spotting_in_printed_and_handwritten_documents_with_identification_stage">https://www.researchgate.net/publication/335462030_Hybrid_HMMBLSTM_system_for_multi-script_keyword_spotting_in_printed_and_handwritten_documents_with_identification_stage</a></td>
<td>提出了一种新的独立于脚本的方法，用于在<strong>印刷和手写的多脚本文档中识别单词</strong></td>
</tr>
<tr>
<td>18</td>
<td>SPN: short path network for scene text detection</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s00521-019-04093-0">https://link.springer.com/article/10.1007/s00521-019-04093-0</a></td>
<td><strong>场景文本检测</strong></td>
</tr>
<tr>
<td>19</td>
<td>Robustly detect different types of text in videos</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s00521-020-04729-6">https://link.springer.com/article/10.1007/s00521-020-04729-6</a></td>
<td><strong>视频文本检测</strong>（叠加文本、分层文本和场景文本）</td>
</tr>
<tr>
<td>20</td>
<td>Effective offline handwritten text recognition model based on a sequence-to-sequence approach with CNN-RNN networks</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s00521-020-05556-5">https://link.springer.com/article/10.1007/s00521-020-05556-5</a></td>
<td><strong>手写文本识别</strong>、使用 <strong>CNN</strong> 提取特征、<strong>RNN-LSTM</strong> 以编码视觉特征和解码手写图像中可用的字母序列。</td>
</tr>
<tr>
<td>21</td>
<td>Historical document image binarization via style augmentation and atrous convolutions</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s00521-020-05382-9">https://link.springer.com/article/10.1007/s00521-020-05382-9</a></td>
<td>使用神经网络方法对历史文献进行<strong>二值化</strong></td>
</tr>
<tr>
<td>22</td>
<td>Character-based handwritten text transcription with attention networks</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/attention-networks-for-image-to-text">https://paperswithcode.com/paper/attention-networks-for-image-to-text</a></td>
<td>使用在字符序列而非单词序列上训练的<strong>注意力编码器-解码器网络</strong>来处理<strong>手写文本识别 (HTR)</strong> 的任务</td>
</tr>
<tr>
<td>23</td>
<td>Compressing the CNN architecture for in-air handwritten Chinese character recognition</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865519303502">https://www.sciencedirect.com/science/article/abs/pii/S0167865519303502</a></td>
<td>提出了一种统一的算法来有效压缩 IAHCCR 的 <strong>CNN</strong>，引入到**空中手写汉字识别（IAHCCR）**中以获得更好的识别性能。</td>
</tr>
<tr>
<td>24</td>
<td>LPR-Net: Recognizing Chinese license plate in complex environments</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865518306998">https://www.sciencedirect.com/science/article/abs/pii/S0167865518306998</a></td>
<td>车牌识别网 (LPR-Net) 的<strong>端到端深度学习架构</strong>直接<strong>识别车牌</strong></td>
</tr>
<tr>
<td>25</td>
<td>An attention-based row-column encoder-decoder model for text recognition in Japanese historical documents</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865520301811">https://www.sciencedirect.com/science/article/abs/pii/S0167865520301811</a></td>
<td><strong>识别</strong>来自<strong>日本历史文档</strong>的多个文本行的输入图像，而无需对行进行显式分割。识别系统具有三个主要部分：特征提取器、行列编码器和解码器。</td>
</tr>
<tr>
<td>26</td>
<td>Assessing similarity in handwritten texts</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865520303093">https://www.sciencedirect.com/science/article/abs/pii/S0167865520303093</a></td>
<td><strong>合成手写风格字体</strong></td>
</tr>
<tr>
<td>27</td>
<td>Clustering online handwritten mathematical expressions</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865521001148">https://www.sciencedirect.com/science/article/abs/pii/S0167865521001148</a></td>
<td><strong>在线手写数学表达式</strong></td>
</tr>
<tr>
<td>28</td>
<td>Beyond visual semantics: Exploring the role of scene text in image understanding</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.10622">https://arxiv.org/abs/1905.10622</a></td>
<td>联合使用场景文本和视觉通道来对图像进行稳健的<strong>语义解释</strong></td>
</tr>
<tr>
<td>29</td>
<td>PMMN: Pre-trained multi-Modal network for scene text recognition</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865521002622">https://www.sciencedirect.com/science/article/abs/pii/S0167865521002622</a></td>
<td>提出了一种<strong>预训练</strong>的<strong>多模态网络</strong> (PMMN)，它利用视觉和语言数据分别预训练视觉模型和语言模型，以学习特定于模态的知识，以进行准确的<strong>场景文本识别</strong></td>
</tr>
<tr>
<td>30</td>
<td>RectiNet-v2: A stacked network architecture for document image dewarping</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2102.01120">https://arxiv.org/abs/2102.01120</a></td>
<td>提出了一种<strong>端到端的 CNN 架构</strong>，该架构可以<strong>从作为输入的扭曲文档中生成无失真的文档图像</strong></td>
</tr>
<tr>
<td>31</td>
<td>Transformer-based approach for joint handwriting and named entity recognition in historical document</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.04189">https://arxiv.org/abs/2112.04189</a></td>
<td>在<strong>手写文档</strong>中提取相关信息</td>
</tr>
<tr>
<td>32</td>
<td>Cross lingual handwritten character recognition using long short term memory network with aid of elephant herding optimization algorithm</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865522001490">https://www.sciencedirect.com/science/article/abs/pii/S0167865522001490</a></td>
<td><strong>手写字符识别</strong></td>
</tr>
<tr>
<td>33</td>
<td>CE-text: A context-Aware and embedded text detector in natural scene images</td>
<td>Journals C</td>
<td><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865522001556">https://www.sciencedirect.com/science/article/abs/pii/S0167865522001556</a></td>
<td>提出了一种名为 CE-Text 的轻量级<strong>上下文感知深度卷积神经网络 (CNN)</strong>，它适当地编码多级通道注意力信息以构建用于准确高效文本检测的判别特征图。</td>
</tr>
<tr>
<td>34</td>
<td>OmniPrint: A configurable printed character synthesizer</td>
<td>Conf A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/omniprint-a-configurable-printed-character">https://paperswithcode.com/paper/omniprint-a-configurable-printed-character</a></td>
<td><strong>独立印刷字符的合成</strong>数据生成器，适用于机器学习研究</td>
</tr>
<tr>
<td>35</td>
<td>Are transformers more robust than CNNs?</td>
<td>Conf A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/are-transformers-more-robust-than-cnns">https://paperswithcode.com/paper/are-transformers-more-robust-than-cnns</a></td>
<td>对 <strong>Transformer</strong> 和 <strong>CNN</strong> 进行公平和深入的比较，重点是稳健性评估。</td>
</tr>
<tr>
<td>36</td>
<td>Diffusion models beat GANs on image synthesis</td>
<td>Conf A</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/diffusion-models-beat-gans-on-image-synthesis">https://paperswithcode.com/paper/diffusion-models-beat-gans-on-image-synthesis</a></td>
<td><strong>扩散模型</strong>可以实现优于当前最先进的生成模型的图像样本质量</td>
</tr>
<tr>
<td>37</td>
<td>Cleaning dirty books: Post-OCR processing for previously scanned texts</td>
<td>Conf B</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/cleaning-dirty-books-post-ocr-processing-for">https://paperswithcode.com/paper/cleaning-dirty-books-post-ocr-processing-for</a></td>
<td><strong>语言模型</strong>的改进现在可以在不考虑扫描图像本身的情况下<strong>检测和纠正 OCR 错误</strong></td>
</tr>
<tr>
<td>38</td>
<td>Accurate arbitrary-shaped scene text detection via iterative polynomial parameter regression</td>
<td>Conf C</td>
<td><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-69535-4_15">https://link.springer.com/chapter/10.1007/978-3-030-69535-4_15</a></td>
<td>针对<strong>任意形状</strong>的文本提出了一种基于参数化形状建模和回归方案的鲁棒<strong>场景文本检测</strong>方法</td>
</tr>
</tbody>
</table>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/ML-%E6%9D%8E%E5%AE%8F%E6%AF%85-Lecture%2010-Attack/">
                        上一篇：ML-李宏毅-Lecture 10-Attack
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/Diary-%E6%84%9A%E8%A0%A2%E7%9A%84%E4%BD%93%E6%A3%80%E3%80%81%E6%B4%BB%E5%8A%9B%E7%9A%84%E4%BF%9D%E5%AE%9A%E8%80%81%E5%A4%B4%E3%80%81%E6%AD%A3%E5%AE%97%E7%9A%84%E6%B2%99%E5%8E%BF%E5%B0%8F%E5%90%83/">
                        下一篇：Diary-愚蠢的体检、活力的保定老头、正宗的沙县小吃
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">121</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">436</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

