<!DOCTYPE html>
<html lang=zh-CN data-theme="light">
	
<script src="/js/plugins/toggleTheme.js"></script>

	<script>
		setTheme();
	</script>
	<head>
		
<title>Paper-第 5 周整理下论文，制定下学习计划 | Zi-Zi's Journey</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/images/icon/favicon.ico">
<link href="/css/plugins/print.css" media="print" rel="stylesheet" />

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="论文,文本检测,YOLO,">
<meta name="description" content="论文阅读。">



<script src="/js/plugins/jquery.min.js"></script>


<script src="/js/plugins/hljs.min.js"></script>


<script src="/js/plugins/init.js"></script>


<script src="/js/plugins/hide.js"></script>


<script src="/js/plugins/tabs.js"></script>



    



    
<script src="/js/plugins/alert-title.js"></script>

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-base.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-dark-class.css">

    
<link rel="stylesheet" href="/css/plugins/github-alerts/github-colors-light.css">






    

	<meta name="generator" content="Hexo 6.1.0"></head>

	<body>
		<header class="sticky-header">
	<nav>
		<div class="nav-left">
			<a href="/" class="logo">
				<img no-lazy src="/images/headers_icon/logo.webp" alt="Quieter">
			</a>
			<ul class="breadcrumb" id="breadcrumb"></ul>
		</div>
		<div class="nav-right">
			<ul>
				
					<li>
						<a href="/">
						  主页
						</a>
					</li>
				
					<li>
						<a href="/categories">
						  类别
						</a>
					</li>
				
					<li>
						<a href="/tags">
						  标签
						</a>
					</li>
				
					<li>
						<a href="/archives">
						  归档
						</a>
					</li>
				
					<li>
						<a href="/galleries">
						  相册
						</a>
					</li>
				
					<li>
						<a href="/links">
						  链接
						</a>
					</li>
				
					<li>
						<a href="/about">
						  关于
						</a>
					</li>
								  
			</ul>
		</div>
		<div class="nav-right-close">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
				<path fill="none" d="M0 0h24v24H0z" />
				<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
			</svg>
		</div>

		<div class="sidebar">
    <div class="topo">
        <p>Zi-Zi's Journey</p>
    </div>
    <ul>
        
        <li>
            <a href="/">
                主页
            </a>
        </li>
        
        <li>
            <a href="/categories">
                类别
            </a>
        </li>
        
        <li>
            <a href="/tags">
                标签
            </a>
        </li>
        
        <li>
            <a href="/archives">
                归档
            </a>
        </li>
        
        <li>
            <a href="/galleries">
                相册
            </a>
        </li>
        
        <li>
            <a href="/links">
                链接
            </a>
        </li>
        
        <li>
            <a href="/about">
                关于
            </a>
        </li>
        
    </ul>
    <div class="sidebar-footer">
        
        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
        </a>
        
        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
        </a>
        
    </div>
</div>
<div class='shelter'>
    <script>
        $(function() {
            $('.nav-right-close > svg').click(function() {
                $('.sidebar').animate({
                    right: "0"
                }, 500);
                $('.shelter').fadeIn("slow");
            
                var element = $('.topo');
                element.addClass('custom-style');
            
                var links = null;
                if ("") {
                    links = "".split(',');
                } else {
                    links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
                }
            
                var randomLink = links[Math.floor(Math.random() * links.length)];
                element.css('background-image', "url('" + randomLink + "')");
            });
          
            $('.shelter').click(function(e) {
                $('.sidebar').animate({
                    right: "-100%"
                }, 500);
                $('.shelter').fadeOut("slow");
            });
        });      
    </script>
</div>
	</nav>

	
		<div class="header-background"></div>
	

	<script>
		const name = 'post';
		const ul = document.querySelectorAll('.nav-right ul')[0];
		const lis = ul.querySelectorAll('li');

		if (name == 'home') {
			lis[0].classList.add('select');
		} else {
			for (let i = 0; i < lis.length; i++) {
				const li = lis[i];
				const a = li.querySelector('a');
				if (name === a.href.split('/')[3]) {
					li.classList.add('select');
				}
			}
		}
	</script>
	
	<script>
		var element = document.querySelector('.header-background');
		if(element) {
			element.classList.add('custom-style');
			var links = null;
			if("")
			{
				links = "".split(',');
			} else
			{
				links = "/images/random_top_img/01.webp,/images/random_top_img/02.webp,/images/random_top_img/03.webp,/images/random_top_img/04.webp,/images/random_top_img/05.webp,/images/random_top_img/06.webp,/images/random_top_img/07.webp,/images/random_top_img/08.webp,/images/random_top_img/09.webp,/images/random_top_img/10.webp,/images/random_top_img/11.webp,/images/random_top_img/12.webp,/images/random_top_img/13.webp,/images/random_top_img/14.webp,/images/random_top_img/15.webp,/images/random_top_img/16.webp,/images/random_top_img/17.webp,/images/random_top_img/18.webp,/images/random_top_img/19.webp,/images/random_top_img/20.webp,/images/random_top_img/21.webp,/images/random_top_img/22.webp,/images/random_top_img/23.webp,/images/random_top_img/24.webp,/images/random_top_img/25.webp,/images/random_top_img/26.webp,/images/random_top_img/27.webp,/images/random_top_img/28.webp,/images/random_top_img/29.webp,/images/random_top_img/30.webp,/images/random_top_img/31.webp,/images/random_top_img/32.webp,/images/random_top_img/33.webp,/images/random_top_img/34.webp,/images/random_top_img/35.webp,/images/random_top_img/36.webp,/images/random_top_img/37.webp,/images/random_top_img/38.webp,/images/random_top_img/39.webp,/images/random_top_img/40.webp,/images/random_top_img/41.webp,/images/random_top_img/42.webp,/images/random_top_img/43.webp,/images/random_top_img/44.webp,/images/random_top_img/45.webp,/images/random_top_img/46.webp,/images/random_top_img/47.webp,/images/random_top_img/48.webp,/images/random_top_img/49.webp,/images/random_top_img/50.webp,/images/random_top_img/51.webp,/images/random_top_img/52.webp,/images/random_top_img/53.webp,/images/random_top_img/54.webp,/images/random_top_img/55.webp,/images/random_top_img/56.webp,/images/random_top_img/57.webp".split(',');
			}
			var randomLink = links[Math.floor(Math.random() * links.length)];
			element.style.backgroundImage = "url('" + randomLink + "')";
		}
	</script>

	
<script src="/js/plugins/breadcrumb.js"></script>

	<script>
		var menus_title = [];
		
			menus_title.push({home: '主页'});
		
			menus_title.push({categories: '类别'});
		
			menus_title.push({tags: '标签'});
		
			menus_title.push({archives: '归档'});
		
			menus_title.push({galleries: '相册'});
		
			menus_title.push({links: '链接'});
		
			menus_title.push({about: '关于'});
		
		
			
				postsBreadcrumb(
					document.getElementById('breadcrumb'),
					"类别",
					"/categories",
					"学习",
					"/categories/学习",
					1
				);
			
		
	</script>
</header>

<div class="main-wrapper">
    <main class="post">
        <header class="main-header">
	
		
			
				
<link rel="stylesheet" href="/css/plugins/fancybox.css">

				
<script src="/js/plugins/fancybox.umd.js"></script>

				
<script src="/js/plugins/fancybox.js"></script>

			
			<div class="post-header-background-content">
				<ul class="post-header-tag">
					
						
							<li><a href="/tags/论文"><span>论文</span></a></li>
						
							<li><a href="/tags/文本检测"><span>文本检测</span></a></li>
						
							<li><a href="/tags/YOLO"><span>YOLO</span></a></li>
						
					
				</ul>
				
				<h1>Paper-第 5 周整理下论文，制定下学习计划</h1>
		
				
					<div class="post-header-desc">
						<svg t="1714702231661" class="icon" viewBox="0 0 1024 1024" version="1.1"
						xmlns="http://www.w3.org/2000/svg" p-id="1154" xmlns:xlink="http://www.w3.org/1999/xlink"
						width="20" height="20">
						<path
							d="M778.24 117.76A46.08 46.08 0 0 1 824.32 163.84v430.08c0 8.4992-4.13696 16.01536-10.50624 20.6848l-0.24576 0.2048L587.5712 846.09024a35.84 35.84 0 0 1-61.48096-25.06752v-220.9792a46.08 46.08 0 0 1 46.08-46.08l200.94976-0.02048V168.96h-522.24v686.08H389.12c13.25056 0 24.1664 10.07616 25.47712 22.97856l0.12288 2.62144c0 14.1312-11.4688 25.6-25.6 25.6h-143.36A46.08 46.08 0 0 1 199.68 860.16V163.84A46.08 46.08 0 0 1 245.76 117.76h532.48z m-26.78784 487.38304h-174.16192v178.176l174.16192-178.176z m-45.19936-169.94304a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z m0-122.88a25.6 25.6 0 0 1 0 51.2H307.2a25.6 25.6 0 0 1 0-51.2h399.0528z"
							fill="#ffffff" p-id="1155"></path>
						</svg>
						<p>论文阅读。</p>
					</div>
				
		
				<div class="post-header-info">
					<svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
					xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
						<path
							d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
							p-id="2902" fill="#ffffff"></path>
					</svg>
					<div class="post-header-info-author">
						<a href="/about">Zi-Zi</a>
					</div>
					
						<div class="post-header-info-categories">
							
								<a href="/categories/学习">学习</a>
							
						</div>
					
					<time>2023/03/24 13:21:00</time>
				</div>
		
				
					<div class="post-header-stat">
						<svg version="1.0" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
						viewBox="0 0 200 200" enable-background="new 0 0 200 200" xml:space="preserve" width="20" height="20">
							<path fill="#FFFFFF" d="M187.2,165.6c0,2.6-2.1,4.7-4.7,4.7H17.5c-2.6,0-4.7-2.1-4.7-4.7s2.1-4.7,4.7-4.7h165.1
								C185.2,160.9,187.2,163,187.2,165.6z"/>
							<path fill="#FFFFFF" d="M17.5,29.7c2.6,0,4.7,2.1,4.7,4.7v131.2c0,2.6-2.1,4.7-4.7,4.7s-4.7-2.1-4.7-4.7V34.4
								C12.8,31.8,14.9,29.7,17.5,29.7z M77.9,91.5c1.8,1.8,1.8,4.8,0,6.6l-39.8,39.8c-1.9,1.8-4.9,1.7-6.6-0.2c-1.7-1.8-1.7-4.6,0-6.4
								l39.8-39.8C73.1,89.6,76,89.6,77.9,91.5z M169.9,70.2c1.6,2.1,1.1,5-0.9,6.5c0,0,0,0,0,0l-64.2,48.2c-2.1,1.5-5,1.1-6.6-0.9
								c-1.6-2.1-1.1-5,0.9-6.5c0,0,0,0,0,0l64.2-48.2C165.4,67.7,168.3,68.1,169.9,70.2L169.9,70.2z"/>
							<path fill="#FFFFFF" d="M104.6,124.5c-1.8,1.8-4.8,1.8-6.6,0L71.6,98.1c-1.8-1.8-1.8-4.8,0-6.6c1.8-1.8,4.8-1.8,6.6,0l26.3,26.3
								C106.4,119.6,106.4,122.6,104.6,124.5C104.6,124.4,104.6,124.4,104.6,124.5z"/>
						</svg>
		
						
							
<script src="/js/plugins/wordCount.js"></script>

							<p class="post-count">文字数：---</p>
						
		
						
							<p id="busuanzi_container_page_pv" style='display:none;'>阅读数：<span id="busuanzi_value_page_pv"></span></p>
						
					</div>
				
			</div>
		
	
</header>
        <div class="post-content article-container">
            <article class="post-content-info">
                <h1 id="%E5%89%8D%E8%A8%80" tabindex="-1">前言</h1>
<p>​    又看了一篇 Text Detection 的论文，然后看了看师兄发的论文，emmm 感觉收获很一般？</p>
<p>​    我决定总结一下看的一些论文，然后制定下学习计划？</p>
<h1 id="%E8%AE%BA%E6%96%87" tabindex="-1">论文</h1>
<h2 id="accurate-arbitrary-shaped-scene-text-detection-via-iterative-polynomial-parameter-regression" tabindex="-1" id="Accurate-arbitrary-shaped-scene-text-detection-via-iterative-polynomial-parameter-regression">Accurate arbitrary-shaped scene text detection via iterative polynomial parameter regression</h2>
<h3 id="%E5%85%A8%E6%96%87" tabindex="-1" id="全文">全文</h3>
<ul>
<li>[<a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/Accurate-Arbitrary-Shaped-Scene-Text-Detection-via-Shi-Chen/59716fa03330552ce88efcdf58786108462db068">PDF] Accurate Arbitrary-Shaped Scene Text Detection via Iterative Polynomial Parameter Regression | Semantic Scholar</a></li>
</ul>
<h3 id="%E5%86%85%E5%AE%B9" tabindex="-1" id="内容">内容</h3>
<p>​    发表于 C 类会议 Asian Conference on Computer Vision，基于迭代<strong>多项式参数回归</strong>的<strong>任意形状场景文本</strong>精确检测。</p>
<p>​    提出了一个新模型：PolyPRNet，设计了一个独特的文本形状参数的迭代回归模块。</p>
<p><img src="01_1.png" alt="png"></p>
<p>​    这个形状模型包含：</p>
<ul>
<li>采样点 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">P_i(x_i,y_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mi>a</mi></msubsup></mrow><annotation encoding="application/x-tex">l^a_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.953104em;vertical-align:-0.258664em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.258664em;margin-left:-0.01968em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">a</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 采样点距离上边界的距离</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>l</mi><mi>i</mi><mi>b</mi></msubsup></mrow><annotation encoding="application/x-tex">l^b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:1.107772em;vertical-align:-0.258664em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.258664em;margin-left:-0.01968em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">b</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 采样点距离下边界的距离</li>
</ul>
<p>​    这个曲线用一个多项式来表示：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>a</mi><mi>n</mi></msub><mo>×</mo><msup><mi>x</mi><mi>n</mi></msup><mo>+</mo><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>×</mo><msup><mi>x</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>a</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y=a_n\times x^n+a_{n-1}\times x^{n-1}+...+a_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.0224389999999999em;vertical-align:-0.208331em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord"><span class="mord mathit">a</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit">a</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">n</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mbin">+</span><span class="mord"><span class="mord mathit">a</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 为中心线上点的坐标。</p>
<p><img src="01_2.png" alt="png"></p>
<p>​    生成的标签。</p>
<p><img src="01_3.png" alt="png"></p>
<p>​    整个网络的结构</p>
<ul>
<li>通过 ResNet+FPN 作为骨干（ResNet50）。</li>
<li>RPN 生成文本区域建议。
<ul>
<li>带有边界框回归分支和分类分支的 R-CNN，级联 R-CNN</li>
</ul>
</li>
<li>生成的 RoIAlign 进入 R-CNN 模块 和 PPR 模块</li>
</ul>
<hr>
<p>​    在对比各种方法：SegLink、EAST、CTD+TLOC、TextSnake…等等，认定这个方法还是好使的。</p>
<h2 id="long-distance-person-detection-based-on-yolov7" tabindex="-1" id="Long-Distance-Person-Detection-Based-on-YOLOv7">Long-Distance Person Detection Based on YOLOv7</h2>
<h2 id="%E5%85%A8%E6%96%87-1" tabindex="-1" id="全文-2">全文</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.mdpi.com/2079-9292/12/6/1502">Electronics | Free Full-Text | Long-Distance Person Detection Based on YOLOv7 (mdpi.com)</a></li>
</ul>
<p>​    导师说这个期刊有点水，有点危险，想让师兄发更好的……但是我和同门看了感觉好牛逼。</p>
<p>​    然后顺藤摸瓜找到了SCI检索中导师账号网址，还有大实验室各个导师账号的网址……就爬到了师兄师姐发的小论文，有空看看。</p>
<ul>
<li>导师：<a target="_blank" rel="noopener" href="https://sciprofiles.com/profile/yangfang">Fang Yang (sciprofiles.com)</a></li>
<li>史老：<a target="_blank" rel="noopener" href="https://sciprofiles.com/profile/2276956">qingxuan shi (sciprofiles.com)</a></li>
<li>老田：<a target="_blank" rel="noopener" href="https://sciprofiles.com/profile/715803">Xuedong Tian (sciprofiles.com)</a></li>
<li>蝈蝈：<a target="_blank" rel="noopener" href="https://sciprofiles.com/profile/wenjieluo">Wenjie Luo (sciprofiles.com)</a></li>
<li>李老的不让看，差评！<a target="_blank" rel="noopener" href="https://sciprofiles.com/profile/2431939">Hidden Profile (sciprofiles.com)</a></li>
</ul>
<h2 id="%E5%86%85%E5%AE%B9-1" tabindex="-1" id="内容-2">内容</h2>
<p>​    由于是基于 YOLOv7 的小目标检测，而我对 YOLOv7 一窍不通，只能随便看看了。</p>
<p>​    师兄说 YOLOv7 对小目标检测不太好使，我对他进行重构，利用递归门卷积模块实现与高阶空间的交互，引入协调注意力机制，增强行人目标信息，弱化背景信息，一波操作后我的新模型比他好使。</p>
<p>​    只使用数据集 TinyPerson。</p>
<p>​    使用了数据增强方法：</p>
<ul>
<li>Mixup</li>
<li>Mosica</li>
</ul>
<p>​    两个数据增强方法都是将两个训练样本及标签按一定比例融合。</p>
<hr>
<p>​    对于目标检测，分为：</p>
<ul>
<li>锚点
<ul>
<li>单阶段：YOLO 各种系列、SSD、RetinaNet</li>
<li>两阶段：在特征图的每个点生成不同大小和比例的锚点，然后通过区域建议网络（RPN）进行过滤
<ul>
<li>Mask R-CNN</li>
<li>Fast R-CNN</li>
<li>Cascade R-CNN</li>
</ul>
</li>
</ul>
</li>
<li>无锚点</li>
</ul>
<hr>
<p>​    然后就是一堆数学公式，不知道是虚张声势还是确实牛逼？师兄用的实验环境：</p>
<ul>
<li>Pytorch 1.10.0</li>
<li>Intel ® Xeon ® Platinum 8255C CPU@2.50GHz</li>
<li>NVIDIA RTX 3090 GPU</li>
</ul>
<p>​    牛逼牛逼！</p>
<h1 id="%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92" tabindex="-1">学习计划</h1>
<ul>
<li>
<p>本来想看师兄的场景文本编辑方面的，查看完目录发现文字风格迁移的论文是真的少……但是场景文本识别的还有一些，接下来应该要看一些<strong>文字风格迁移</strong>的论文？但这类的论文真的很少哇！</p>
</li>
<li>
<p>看了一些<strong>场景文字识别</strong>的论文感觉几篇有那么点共性，考虑看点<strong>综述</strong>：<a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/text-recognition-in-the-wild-a-survey">Text Recognition in the Wild: A Survey | Papers With Code</a>、  [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1811.04256">1811.04256] Scene Text Detection and Recognition: The Deep Learning Era (arxiv.org)</a></p>
</li>
<li>
<p>学学小土堆的 <strong>Pytorch</strong>，同乡推荐的：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1hE411t7RN">PyTorch深度学习快速入门教程（绝对通俗易懂！）【小土堆】_哔哩哔哩_bilibili</a></p>
</li>
<li>
<p>不知道实验室的<strong>服务器</strong>能不能整啊，用自己电脑跑这玩意太伤了。</p>
</li>
<li>
<p>好像该准备准备<strong>六级</strong>了orz</p>
</li>
</ul>
<hr>
<p>​    爬目录上瘾了，又爬了 <strong>International Journal of Computer Vision</strong> 和 <strong>Computer Vision and Pattern Recognition (CVPR)</strong> 的论文，收集了一些可能跟研究方向有关的论文：</p>
<p><strong>International Journal of Computer Vision</strong>：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>名称</th>
<th>资源</th>
<th>ID</th>
<th>概要</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Scene text detection and recognition: The deep learning era</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1811.04256">1811.04256] Scene Text Detection and Recognition: The Deep Learning Era (arxiv.org)</a></td>
<td>arXiv:1811.04256</td>
<td>本次调查旨在总结和分析深度学习时代<strong>场景文本检测和识别</strong>的主要变化和重大进展。</td>
</tr>
<tr>
<td>2</td>
<td>I3CL: Intra- and inter-instance collaborative learning for arbitrary-shaped scene text detection</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2108.01343">2108.01343] I3CL:Intra- and Inter-Instance Collaborative Learning for Arbitrary-shaped Scene Text Detection (arxiv.org)</a></td>
<td>arXiv:2108.01343</td>
<td>提出了一种新的方法，称为实例内和实例间协作学习（I3CL），用于<strong>场景文本检测</strong></td>
</tr>
<tr>
<td>3</td>
<td>PageNet: Towards end-to-end weakly supervised page-level handwritten chinese text recognition</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2207.14807">2207.14807] PageNet: Towards End-to-End Weakly Supervised Page-Level Handwritten Chinese Text Recognition (arxiv.org)</a></td>
<td>arXiv:2207.14807</td>
<td><strong>手写中文文本</strong>检测</td>
</tr>
</tbody>
</table>
<hr>
<p><strong>Computer Vision and Pattern Recognition (CVPR)</strong>：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>名称</th>
<th>资源</th>
<th>ID</th>
<th>概要</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>CLEval: Character-level evaluation for text detection and recognition tasks</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.06244">2006.06244] CLEval: Character-Level Evaluation for Text Detection and Recognition Tasks (arxiv.org)</a></td>
<td>arXiv:2006.06244</td>
<td>提出了一个新的<strong>文本检测评估方法</strong></td>
</tr>
<tr>
<td>2</td>
<td>Font-ProtoNet: Prototypical network based font identification of document images in low data regime</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9150768">https://ieeexplore.ieee.org/document/9150768</a><br/><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w34/Goel_Font-ProtoNet_Prototypical_Network-Based_Font_Identification_of_Document_Images_in_Low_CVPRW_2020_paper.pdf">Font-ProtoNet: Prototypical Network-Based Font Identification of Document Images in Low Data Regime (thecvf.com)</a></td>
<td>DOI:10.1109/CVPRW50498.2020.00286</td>
<td>少量镜头学习技术，如原型网络，在扫描/打印的文档图像中使用来自不同字体的字符图像作为<strong>稀缺数据场景的输入进行字体识别</strong>，并将所提出的方法称为 Font-ProtoNet</td>
</tr>
<tr>
<td>3</td>
<td>Illegible text to readable text: An image-to-image transformation using conditional sliced wasserstein adversarial networks</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.05425">1910.05425] Illegible Text to Readable Text: An Image-to-Image Transformation using Conditional Sliced Wasserstein Adversarial Networks (arxiv.org)</a></td>
<td>arXiv:1910.05425</td>
<td>们通过开发手写到机器打印条件生成对抗性网络**（HW2MP-GAN）<strong>模型来解决这个问题，该模型将</strong>手写识别<strong>公式化为</strong>文本图像到文本图像**的翻译问题，其中给定的图像（通常是难以辨认的形式）被转换为另一个图像，接近其机器打印形式。所提出的模型由三个组件组成，包括生成器、单词级和字符级鉴别器。</td>
</tr>
<tr>
<td>4</td>
<td>On recognizing texts of arbitrary shapes with 2D self-attention</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.04396">1910.04396] On Recognizing Texts of Arbitrary Shapes with 2D Self-Attention (arxiv.org)</a></td>
<td>arXiv:1910.04396</td>
<td>介绍了一种新的<strong>识别任意形状文本</strong>的体系结构，称为自注意文本识别网络（SATRN），其灵感来自Transformer。SATRN利用自注意机制来描述场景文本图像中字符的二维（2D）空间相关性。SATRN利用自注意的全图传播，可以识别任意排列和大字符间距的文本。</td>
</tr>
<tr>
<td>5</td>
<td>An accurate segmentation-based scene text detector with context attention and repulsive text border</td>
<td><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w34/Liu_An_Accurate_Segmentation-Based_Scene_Text_Detector_With_Context_Attention_and_CVPRW_2020_paper.html">CVPR 2020 Open Access Repository (thecvf.com)</a></td>
<td>DOI:10.1109/CVPRW50498.2020.00283</td>
<td>对于<strong>场景文本检测</strong>，提出了一种基于精确分割的检测器，该检测器配备了上下文注意和排斥文本边界。</td>
</tr>
<tr>
<td>6</td>
<td>Visual parsing with query-driven global graph attention (QD-GGA): Preliminary results for handwritten math formula recognition</td>
<td><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w34/Mahdavi_Visual_Parsing_With_Query-Driven_Global_Graph_Attention_QD-GGA_Preliminary_Results_CVPRW_2020_paper.pdf">Visual Parsing With Query-Driven Global Graph Attention (QD-GGA): Preliminary Results for Handwritten Math Formula Recognition (thecvf.com)</a></td>
<td>DOI:10.1109/CVPRW50498.2020.00293</td>
<td>基于<strong>进化神经网络的手写数学公式可视化解析</strong>方法。</td>
</tr>
<tr>
<td>7</td>
<td>A method for detecting text of arbitrary shapes in natural scenes that improves text spotting</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.07046">1911.07046] A method for detecting text of arbitrary shapes in natural scenes that improves text spotting (arxiv.org)</a></td>
<td>arXiv:1911.07046</td>
<td>介绍了一种基于流水线的文本识别框架，该框架可以检测和识别具有复杂背景的<strong>自然场景图像</strong>中各种字体、形状和方向的文本。我们工作的主要贡献是文本检测组件，我们称之为UHT，是<strong>UNet、Heatmap和Textfill</strong>的缩写。</td>
</tr>
<tr>
<td>8</td>
<td>ScrabbleGAN: Semi-supervised varying length handwritten text generation</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.10557">2003.10557] ScrabbleGAN: Semi-Supervised Varying Length Handwritten Text Generation (arxiv.org)</a></td>
<td>arXiv:2003.10557</td>
<td>提出了ScrabbleGAN，这是一种<strong>半监督的合成手写文本图像</strong>的方法，在风格和词汇上都是通用的。ScrabbleGAN依赖于一种新的生成模型，该模型可以生成任意长度的单词图像。</td>
</tr>
<tr>
<td>9</td>
<td>SCATTER: Selective context attentional scene text recognizer</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.11288">2003.11288] SCATTER: Selective Context Attentional Scene Text Recognizer (arxiv.org)</a></td>
<td>arXiv:2003.11288</td>
<td><strong>场景文本识别（STR）<strong>是在复杂图像背景下识别文本的任务，是一个活跃的研究领域。目前最先进的（SOTA）方法仍然难以识别以</strong>任意形状书写</strong>的文本。在本文中，我们介绍了一种新的STR架构，称为选择性上下文注意力文本识别器（SCATTER）。</td>
</tr>
<tr>
<td>10</td>
<td>Diverse image generation via self-conditioned GANs</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.10728">2006.10728] Diverse Image Generation via Self-Conditioned GANs (arxiv.org)</a></td>
<td>arXiv:2006.10728</td>
<td>一种简单但有效的<strong>无监督方法</strong>，用于<strong>生成</strong>逼真且多样化的图像。我们在不使用手动注释的类标签的情况下训练类<strong>条件GAN模型</strong>。</td>
</tr>
<tr>
<td>11</td>
<td>ABCNet: Real-time scene text spotting with adaptive bezier-curve network</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.10200">2002.10200] ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network (arxiv.org)</a></td>
<td>arXiv:2002.10200</td>
<td>通过提出自适应贝塞尔曲线网络（ABCNet）来解决<strong>场景文本识别</strong>问题。</td>
</tr>
<tr>
<td>12</td>
<td>STEFANN: Scene text editor using font adaptive neural network</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.01192">1903.01192] STEFANN: Scene Text Editor using Font Adaptive Neural Network (arxiv.org)</a></td>
<td>arXiv:1903.01192</td>
<td><strong>捕获场景中的文本信息</strong>在场景解释和决策中起着重要作用。尽管有一些方法可以成功地检测和解释场景中存在的复杂文本区域，但据我们所知，目前还没有旨在<strong>修改图像中文本信息</strong>的重要工作。直接在图像上编辑文本的能力具有几个优点，包括纠错、文本恢复和图像可重用性。在本文中，我们提出了一种在字符级别修改图像中文本的方法。</td>
</tr>
<tr>
<td>13</td>
<td>Semantic pyramid for image generation</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.06221">2003.06221] Semantic Pyramid for Image Generation (arxiv.org)</a></td>
<td>arXiv:2003.06221</td>
<td>我们提出了一种新的基于<strong>GAN</strong>的模型，该模型利用了通过预训练的分类模型学习的深度特征空间</td>
</tr>
<tr>
<td>14</td>
<td>RSCA: Real-time segmentation-based context-aware scene text detection</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.12789">2105.12789] RSCA: Real-time Segmentation-based Context-Aware Scene Text Detection (arxiv.org)</a></td>
<td>arXiv:2105.12789</td>
<td>RSCA：一种用于任意形状<strong>场景文本检测</strong>的基于实时<strong>分割</strong>的上下文感知模型</td>
</tr>
<tr>
<td>15</td>
<td>Transformer-based text detection in the wild</td>
<td>[Transformer-Based Text Detection in the Wild (<a target="_blank" rel="noopener" href="http://thecvf.com">thecvf.com</a>)](<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021W/VOCVALC/papers/Raisi_Transformer-Based_Text_Detection_in_the_Wild_CVPRW_2021_paper.pdf#:~:text=In">https://openaccess.thecvf.com/content/CVPR2021W/VOCVALC/papers/Raisi_Transformer-Based_Text_Detection_in_the_Wild_CVPRW_2021_paper.pdf#:~:text=In</a> this work%2C we tackle the problem of,to the rotated text detection problem that leverages)</td>
<td>DOI:10.1109/CVPRW53098.2021.00353</td>
<td>提出了一种基于<strong>Transformer</strong>的架构，该架构天生能够处理图像中的<strong>多方向文本</strong></td>
</tr>
<tr>
<td>16</td>
<td>Sequence-to-sequence contrastive learning for text recognition</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2012.10873">2012.10873] Sequence-to-Sequence Contrastive Learning for Text Recognition (arxiv.org)</a></td>
<td>arXiv:2012.10873</td>
<td><strong>标准手写文本识别基准</strong></td>
</tr>
<tr>
<td>17</td>
<td>MetaHTR: Towards writer-adaptive handwritten text recognition</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.01876">2104.01876] MetaHTR: Towards Writer-Adaptive Handwritten Text Recognition (arxiv.org)</a></td>
<td>arXiv:2104.01876</td>
<td><strong>元学习</strong>框架，多种风格的<strong>手写文字识别</strong></td>
</tr>
<tr>
<td>18</td>
<td>Adaptive convolutions for structure-aware style transfer</td>
<td><a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/adaptive-convolutions-for-structure-aware">https://paperswithcode.com/paper/adaptive-convolutions-for-structure-aware</a><br/><a target="_blank" rel="noopener" href="https://cgl.ethz.ch/publications/papers/paperPra21a.php">CGL @ ETHZ - Adaptive Convolutions for Structure-Aware Style Transfer</a></td>
<td>DOI:10.1109/CVPR46437.2021.00788</td>
<td>风格图像中的局部几何结构在传输过程中经常被忽略。我们提出了<strong>自适应卷积（AdaConv）</strong>，这是AdaIN的一个通用扩展，允许实时同时传输统计和结构风格。</td>
</tr>
<tr>
<td>19</td>
<td>Deep texture recognition via exploiting cross-layer statistical self-similarity</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9577662">https://ieeexplore.ieee.org/document/9577662</a></td>
<td>DOI:10.1109/CVPR46437.2021.00519</td>
<td>开发了CLASSNet，这是一种有效的<strong>纹理识别深度模型</strong></td>
</tr>
<tr>
<td>20</td>
<td>Scene text telescope: Text-focused scene image super-resolution</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.03341">2005.03341] Scene Text Image Super-Resolution in the Wild (arxiv.org)</a></td>
<td>arXiv:2005.03341</td>
<td><strong>真实场景</strong>的文本SR<strong>数据集</strong>，称为TextZoom。它包含成对的真实低分辨率和高分辨率图像，这些图像由野外不同焦距的相机拍摄</td>
</tr>
<tr>
<td>21</td>
<td>Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.06495">2103.06495] Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition (arxiv.org)</a></td>
<td>arXiv:2103.06495</td>
<td><strong>语言知识</strong>应用于<strong>场景文本识别</strong>的有效方法——ABINet</td>
</tr>
<tr>
<td>22</td>
<td>Semantic-aware video text detection</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9578447">https://ieeexplore.ieee.org/document/9578447</a></td>
<td>DOI:10.1109/CVPR46437.2021.00174</td>
<td>提出了一种基于<strong>语义特征跟踪</strong>文本的端到端可训练<strong>视频文本检测器</strong></td>
</tr>
<tr>
<td>23</td>
<td>MOST: A multi-oriented scene text detector with localization refinement</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.01070">2104.01070] MOST: A Multi-Oriented Scene Text Detector with Localization Refinement (arxiv.org)</a></td>
<td>arXiv:2104.01070</td>
<td>一种新的<strong>场景文本检测</strong>算法，该算法提出了一套策略来显著提高文本定位的质量</td>
</tr>
<tr>
<td>24</td>
<td>Rethinking style transfer: From pixels to parameterized brushstrokes</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.17185">2103.17185] Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes (arxiv.org)</a></td>
<td>arXiv:2103.17185</td>
<td>风格化过程仅限于像素域。然而，我们认为这种表现是不自然的，因为绘画通常由笔触而不是像素组成。我们提出了一种通过<strong>优化参数化笔触</strong>而不是像素来风格化图像的方法，并进一步引入了一种简单的可微分绘制机制。</td>
</tr>
<tr>
<td>25</td>
<td>On feature normalization and data augmentation</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.11102">2002.11102] On Feature Normalization and Data Augmentation (arxiv.org)</a></td>
<td>arXiv:2002.11102</td>
<td>提出了<strong>矩交换</strong>，这是一种隐式数据增强方法，鼓励模型也将矩信息用于<strong>识别模型</strong></td>
</tr>
<tr>
<td>26</td>
<td>Learning to warp for style transfer</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9577906">https://ieeexplore.ieee.org/document/9577906</a></td>
<td>DOI:10.1109/CVPR46437.2021.00370</td>
<td>提出了一种神经网络，该网络独特地学习从特征间距离的4D阵列到非参数2D扭曲场的映射。</td>
</tr>
<tr>
<td>27</td>
<td>Dictionary-guided scene text recognition</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9577624">https://ieeexplore.ieee.org/document/9577624</a></td>
<td>DOI:10.1109/CVPR46437.2021.00730</td>
<td>我们提出了一种新的方法，将<strong>字典</strong>纳入<strong>场景文本识别</strong>系统的训练和推理阶段。我们使用字典生成一个可能结果的列表，并找到最符合文本视觉外观的结果。<br/>贡献了VinText，这是一个具有挑战性的越南语场景文本<strong>数据集</strong>，其中一些字符由于重音符号而在视觉形式上模棱两可。该数据集将成为衡量场景文本检测和识别算法的适用性和稳健性的一个具有挑战性的基准。</td>
</tr>
<tr>
<td>28</td>
<td>HyperStyle: StyleGAN inversion with HyperNetworks for real image editing</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.15666">2111.15666] HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing (arxiv.org)</a></td>
<td>arXiv:2111.15666</td>
<td>将真实图像反演到StyleGAN的潜在空间。提出了HyperStyle，这是一种超网络，它学习调制StyleGAN的权重，以在潜在空间的可编辑区域中忠实地表达给定的图像。</td>
</tr>
<tr>
<td>29</td>
<td>AUV-Net: Learning aligned UV maps for texture transfer and synthesis</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2204.03105">2204.03105] AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis (arxiv.org)</a></td>
<td>arXiv:2204.03105</td>
<td>AUV-Net，它通过将不同3D形状的对应语义部分映射到UV空间中的相同位置，学习将3D表面嵌入到2D对齐的UV空间中。</td>
</tr>
<tr>
<td>30</td>
<td>PCA-Based knowledge distillation towards lightweight and content-style balanced photorealistic style transfer models</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.13452">2203.13452] PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models (arxiv.org)</a></td>
<td>arXiv:2203.13452</td>
<td>我们引入了基于主成分分析的知识提取来提取轻量级模型，并表明它是受理论驱动的。据我们所知，这是第一种用于<strong>真实感风格转换</strong>的知识提取方法。</td>
</tr>
<tr>
<td>31</td>
<td>StyTr(²): Image style transfer with transformers</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.14576">2105.14576] StyTr<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>: Image Style Transfer with Transformers (arxiv.org)</a></td>
<td>arXiv:2105.14576</td>
<td>提出了一种称为StyTr2的基于变换器的方法，将输入图像的长程依赖性考虑到图像风格转移。与其他视觉任务的视觉转换器不同，StyTr2包含两个不同的转换器编码器，分别为<strong>内容和风格生成</strong>特定于领域的序列。在编码器之后，采用多层转换器解码器根据样式序列对内容序列进行样式化。</td>
</tr>
<tr>
<td>32</td>
<td>SwinTextSpotter: Scene text spotting via better synergy between text detection and text recognition</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.10209">2203.10209] SwinTextSpotter: Scene Text Spotting via Better Synergy between Text Detection and Text Recognition (arxiv.org)</a></td>
<td>arXiv:2203.10209</td>
<td>SwinTextSpotter。使用具有动态头的转换器编码器作为检测器，我们用一种新的识别转换机制将这两项任务统一起来，以明确地通过识别损失来指导文本定位。直接的设计产生了一个简洁的框架，既不需要额外的校正模块，也不需要对<strong>任意形状的文本</strong>进行字符级注释。</td>
</tr>
<tr>
<td>33</td>
<td>Revisiting document image dewarping by grid regularization</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.16850">2203.16850] Revisiting Document Image Dewarping by Grid Regularization (arxiv.org)</a></td>
<td>arXiv:2203.16850</td>
<td>本文解决了文档图像去水印问题，旨在<strong>消除文档图像中的几何失真</strong>，实现文档数字化。</td>
</tr>
<tr>
<td>34</td>
<td>A style-aware discriminator for controllable image translation</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.15375">2203.15375] A Style-aware Discriminator for Controllable Image Translation (arxiv.org)</a></td>
<td>arXiv:2203.15375</td>
<td>提出了一种<strong>风格感知鉴别器</strong>，它既可以作为评论家，也可以作为风格编码器来提供条件。</td>
</tr>
<tr>
<td>35</td>
<td>Look closer to supervise better: One-shot font generation via component-based discriminator</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.00146">2205.00146] Look Closer to Supervise Better: One-Shot Font Generation via Component-Based Discriminator (arxiv.org)</a></td>
<td>arXiv:2205.00146</td>
<td>由于大量具有复杂结构的字符，<strong>自动字体生成</strong>仍然是一个具有挑战性的研究问题。通常，只有少数样本可以作为风格/内容参考（称为少数镜头学习），这进一步增加了保存局部风格模式或详细字形结构的难度。我们调查了先前研究的缺点，发现粗粒度鉴别器不足以监督字体生成器。为此，我们提出了一种新的组件感知模块（CAM），它监督生成器在更细粒度的级别（即组件级别）解耦内容和样式。</td>
</tr>
<tr>
<td>36</td>
<td>Beyond a pre-trained object detector: Cross-modal textual and visual context for image captioning</td>
<td>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.04363">2205.04363] Beyond a Pre-Trained Object Detector: Cross-Modal Textual and Visual Context for Image Captioning (arxiv.org)</a></td>
<td>arXiv:2205.04363</td>
<td>建议（并证明这一点很重要）使用**多模态预训练模型（CLIP）**来检索此类上下文描述</td>
</tr>
<tr>
<td>37</td>
<td>Wearable ImageNet: Synthesizing tileable textures via dataset distillation</td>
<td><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9857092">https://ieeexplore.ieee.org/document/9857092</a></td>
<td>DOI:10.1109/CVPRW56347.2022.00252</td>
<td>描述了一种简单的方法，通过从合成像素的环形画布中采样随机作物来<strong>生成可平铺的提取纹理</strong>，同时强制所有这些作物都作为有效的提取训练数据。</td>
</tr>
</tbody>
</table>

            </article>
            
	<div class="rightside">
	
		<div class="rightside-button" id="js-aside">
			<span>
				<img no-lazy src="/images/icon/aside.png" class="rightside-button-icon" alt="Icon">
			</span>
		</div>
		<script>
			$("#js-aside").click(function () {
				onShowAsideButton();
			});
		</script>
	
	<div class="rightside-button" id="js-toggle_theme">
		<span>
			<img no-lazy src="/images/icon/toggle_theme.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	
<script src="/js/plugins/goto_position.js"></script>

	
	<div class="rightside-button" id="js-go_top">
		<span>
			<img no-lazy src="/images/icon/go_top.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>
	<div class="rightside-button" id="js-go_bottom">
		<span>
			<img no-lazy src="/images/icon/go_bottom.png" class="rightside-button-icon" alt="Icon">
		</span>
	</div>

	<script>
		setToggleThemeButtonListener();
	</script>
	<script>
		$('#js-go_top')
		.gotoPosition( {
			speed: 300,
			target: 'top',
		} );
		$('#js-go_bottom')
		.gotoPosition( {
			speed: 300,
			target: 'bottom',
		} );
	</script>
</div>


<div class="post-bottom">
    
        <div class="post-paging">     
            <div class="post-paging-last">
                
                    <a href="/posts/Paper-Text%20Recognition%20in%20the%20Wild-A%20Survey/">
                        上一篇：Paper-Text Recognition in the Wild-A Survey
                    </a>
                
            </div>
            <div class="post-paging-next">
                
                    <a href="/posts/Diary-%E7%AC%AC%205%20%E5%91%A8%E9%A9%AC%E4%B8%8A%E7%BB%93%E6%9D%9F%E4%BA%86%EF%BC%81/">
                        下一篇：Diary-第 5 周马上结束了！
                    </a>
                
            </div>
        </div>
    
    
    
        
            <div class="giscus comments"></div>
            <script>
                var scriptElement = document.createElement('script');
                scriptElement.src = 'https://giscus.app/client.js';
                scriptElement.setAttribute('data-repo', 'GZ-Metal-Cell/GZ-Metal-Cell.github.io');
                scriptElement.setAttribute('data-repo-id', 'R_kgDOIHLEOQ');
                scriptElement.setAttribute('data-category', 'Announcements');
                scriptElement.setAttribute('data-category-id', 'DIC_kwDOIHLEOc4CcVwP');
                scriptElement.setAttribute('data-mapping', 'title');
                scriptElement.setAttribute('data-strict', '1');
                scriptElement.setAttribute('data-reactions-enabled', '');
                scriptElement.setAttribute('data-emit-metadata', '0');
                scriptElement.setAttribute('data-input-position', 'bottom');
                scriptElement.setAttribute('data-theme', localStorage.getItem('theme') === 'light' ? 'light' : 'dark_high_contrast');
                scriptElement.setAttribute('data-lang', 'zh-CN');
                
                scriptElement.setAttribute('crossorigin', 'anonymous');
                scriptElement.async = true;
                document.head.appendChild(scriptElement);
            </script>
        
    
</div>
        </div>
    </main>
    
        <aside class="main-aside">
    
<script src="/js/widgets/aside.js"></script>

    <script>
        showAside();
    </script>

    <div class="aside-top">
        <div class="aside-top-about aside-card">
            <a href="/about" class="aside-top-about-portrait">
                <img no-lazy src="/about/portrait.png" alt="Q">
            </a>
            <div class="aside-top-about-info">
                <span class="author"> Zi-Zi</span>
                <span class="description">不以物喜，不以己悲。</span>
            </div>              
            <div class="aside-top-about-site">
                <a href="/categories" class="aside-top-about-site-item">
                    <span class="title">类别</span>
                    <span class="count">5</span>
                </a>
                <a href="/tags" class="aside-top-about-site-item">
                    <span class="title">标签</span>
                    <span class="count">122</span>
                </a>
                <a href="/archives" class="aside-top-about-site-item">
                    <span class="title">归档</span>
                    <span class="count">438</span>
                </a>
            </div>
            <div class="aside-top-about-contact">
                
                    
                        <a target="_blank" rel="noopener" href="https://weibo.com/u/5020307235">
                            <img no-lazy src="/images/bottom_icon/Weibo.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://tieba.baidu.com/home/main?id=tb.1.ff6d2775.vFH7wrdW2ZjPCmyBHJcjnA">
                            <img no-lazy src="/images/bottom_icon/Tieba.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://space.bilibili.com/11547880">
                            <img no-lazy src="/images/bottom_icon/Bilibili.webp" alt="Quieter">
                        </a>
                    
                        <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell">
                            <img no-lazy src="/images/bottom_icon/github.webp" alt="Quieter">
                        </a>
                    
                
            </div>
        </div> 

        
    </div>

    <div class="aside-bottom">
        
            <script>
                
                    const tocCollapsed = true;
                
                
                    const tocDepth = 6;
                
                var headerString = '';
                for (let i = 1; i <= tocDepth; i++) {
                    if (i === 1) {
                        headerString += 'h1';
                    } else {
                        headerString += ', h' + i;
                    }
                }
                hbeToc();
            </script>
            <div class="aside-bottom-toc aside-card">
                <div class="aside-bottom-toc-title">
                    <h1>目录</h1>
                    <span class="toc-percentage"></span>
                </div>
                <ol class="aside-bottom-toc-content"></ol>
            </div>
        
    </div>
</aside>
    
</div>
		<footer>
	<div class="content">
		
			<span>©2022-2025&nbsp;By&nbsp;<a href="/about">Zi-Zi</a>.</span>
		
		<span><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> theme by <a target="_blank" rel="noopener" href="https://github.com/GZ-Metal-Cell/hexo-theme-quieter">Quieter</a>.</span>
		
			<span style="display: flex;">
				<img no-lazy alt="icp" src="/images/icp_icon.png" style="width: 16px; height: 16px;">
				<a href="https://icp.gov.moe/?keyword=20241647" target="_blank">萌 ICP 备 20241647 号</a>
			</span>
		
	</div>

	
<script src="/js/plugins/ref.js"></script>

	
<script src="/js/plugins/highlight_tools.js"></script>

	<script>
		const  COPY_ICON = "/images/icon/copy.png";
		const CLOSE_CODE_BLOCK_ICON = "/images/icon/close_code_block.png";
		const HIGHLIGHT_SHRINK = "";
		const HIGHLIGHT_HEIGHT_LIMIT = "";
	</script>

	
	
	<!-- Analytics -->

    
        <!-- Busuanzi Analytics -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
        <!-- Baidu Analytics -->
        <script defer>
            var _hmt = _hmt || [];
            (function () {
                var hm = document.createElement("script");
                hm.src = "https://hm.baidu.com/hm.js?e57cf62289f84322ebff116e8b3d343e";
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(hm, s);
            })();
        </script>
    


	

	
		
			
				<link rel="stylesheet" href="/css/plugins/katex/katex.min.css">
				<script src="/js/plugins/copy-tex.js"></script>
			
		
	

    
		
<link rel="stylesheet" href="/css/plugins/textIndent.css">

		
<script src="/js/plugins/textIndent.js"></script>

	

	
	
	
		<script>
			if (typeof init === 'function') {
				init();
			}
		</script>
	

	
		
	

	

	<!--
		
<script src="/js/plugins/jquery.pjax.min.js"></script>

		<script>
			$(document).pjax('a[target!=_blank]', 'main', {
				fragment: 'main',
				timeout: 8000
			});

			$(document).on('pjax:complete', function() {
			});
		</script> 
	-->
	<script>
		console.log('\n %c Hexo-Quieter 主题 %c https://github.com/GZ-Metal-Cell/hexo-theme-quieter \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
	</script>
</footer>
	</body>

	<!-- Hexo-Quieter 主题  https://github.com/GZ-Metal-Cell/hexo-theme-quieter -->
</html>

